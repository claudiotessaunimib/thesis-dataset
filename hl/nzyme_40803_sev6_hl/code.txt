package app.nzyme.core.tables.tcp;
import app.nzyme.core.NzymeNode;
import app.nzyme.core.ethernet.EthernetRegistryKeys;
import app.nzyme.core.ethernet.tcp.TcpSessionState;
import app.nzyme.core.ethernet.tcp.db.TcpSessionEntry;
import app.nzyme.core.integrations.geoip.GeoIpLookupResult;
import app.nzyme.core.integrations.geoip.GeoIpService;
import app.nzyme.core.rest.resources.taps.reports.tables.tcp.TcpSessionReport;
import app.nzyme.core.rest.resources.taps.reports.tables.tcp.TcpSessionsReport;
import app.nzyme.core.tables.DataTable;
import app.nzyme.core.tables.TablesService;
import app.nzyme.core.util.MetricNames;
import app.nzyme.core.util.Tools;
import com.codahale.metrics.Timer;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.joda.time.DateTime;
import java.net.InetAddress;
import java.util.Optional;
import java.util.UUID;
import java.util.concurrent.CountDownLatch;
import static app.nzyme.core.util.Tools.stringtoInetAddress;
public class TCPTable implements DataTable {
    private static final Logger LOG = LogManager.getLogger(TCPTable.class);
    private final TablesService tablesService;
    private final Timer totalReportTimer;
    private final Timer sessionsReportTimer;
    private final Timer sessionDiscoveryTimer;
    private final GeoIpService geoIp;
    public TCPTable(TablesService tablesService) {
        this.tablesService = tablesService;
        this.geoIp = tablesService.getNzyme().getGeoIpService();
        this.totalReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.TCP_TOTAL_REPORT_PROCESSING_TIMER);
        this.sessionsReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.TCP_SESSIONS_REPORT_PROCESSING_TIMER);
        this.sessionDiscoveryTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.TCP_SESSION_DISCOVERY_QUERY_TIMER);
    }
    public void handleReport(UUID tapUuid, DateTime timestamp, TcpSessionsReport report) {
        try (Timer.Context ignored = totalReportTimer.time()) {
            try (Timer.Context ignored2 = sessionsReportTimer.time()) {
                CountDownLatch latch = new CountDownLatch(report.sessions().size());
                for (TcpSessionReport session : report.sessions()) {
                    tablesService.getProcessorPool().submit(() -> {
                        writeSession(tapUuid, timestamp, session);
                        latch.countDown();
                    });
                }
                try {
                    latch.await();
                } catch (InterruptedException e) {
                    LOG.error("TCP sessions writer process interrupted.", e);
                }
            }
        }
    }
    private void writeSession(UUID tapUuid, DateTime timestamp, TcpSessionReport session) {
        try {
            String sessionKey = Tools.buildTcpSessionKey(
                    session.startTime(),
                    session.sourceAddress(),
                    session.destinationAddress(),
                    session.sourcePort(),
                    session.destinationPort()
            );
            InetAddress sourceAddress = stringtoInetAddress(session.sourceAddress());
            InetAddress destinationAddress = stringtoInetAddress(session.destinationAddress());
            Optional<GeoIpLookupResult> sourceGeo = geoIp.lookup(sourceAddress);
            Optional<GeoIpLookupResult> destinationGeo = geoIp.lookup(destinationAddress);
            tablesService.getNzyme().getDatabase().useHandle(handle -> {
                Optional<TcpSessionEntry> existingSession;
                try (Timer.Context ignored = sessionDiscoveryTimer.time()) {
                    existingSession = handle.createQuery("SELECT * FROM l4_sessions " +
                                    "WHERE session_key = :session_key AND end_time IS NULL AND tap_uuid = :tap_uuid")
                            .bind("session_key", sessionKey)
                            .bind("tap_uuid", tapUuid)
                            .mapTo(TcpSessionEntry.class)
                            .findOne();
                }
                if (existingSession.isPresent()) {
                    // Existing session. Update.
                    handle.createUpdate("UPDATE l4_sessions SET state = :state, " +
                                    "bytes_count = :bytes_count, segments_count = :segments_count, " +
                                    "end_time = :end_time, most_recent_segment_time = :most_recent_segment_time " +
                                    "WHERE id = :id")
                            .bind("state", TcpSessionState.valueOf(session.state().toUpperCase()))
                            .bind("bytes_count", session.bytesCount())
                            .bind("segments_count", session.segmentsCount())
                            .bind("end_time", session.endTime())
                            .bind("most_recent_segment_time", session.mostRecentSegmentTime())
                            .bind("id", existingSession.get().id())
                            .execute();
                } else {
                    // This is a new session.
                    handle.createUpdate("INSERT INTO l4_sessions(tap_uuid, l4_type, session_key, " +
                                    "source_mac, source_address, source_address_is_site_local, " +
                                    "source_address_is_loopback, source_address_is_multicast, source_port, " +
                                    "destination_mac, destination_address, destination_address_is_site_local, " +
                                    "destination_address_is_loopback, destination_address_is_multicast," +
                                    " destination_port, bytes_count, segments_count, " +
                                    "start_time, end_time, most_recent_segment_time, state, " +
                                    "source_address_geo_asn_number, source_address_geo_asn_name, " +
                                    "source_address_geo_asn_domain, source_address_geo_city, " +
                                    "source_address_geo_country_code, " +
                                    "source_address_geo_latitude, source_address_geo_longitude, " +
                                    "destination_address_geo_asn_number, destination_address_geo_asn_name, " +
                                    "destination_address_geo_asn_domain, destination_address_geo_city, " +
                                    "destination_address_geo_country_code, " +
                                    "destination_address_geo_latitude, destination_address_geo_longitude, " +
                                    "created_at) VALUES(:tap_uuid, :l4_type, :session_key, :source_mac, " +
                                    ":source_address::inet, " +
                                    ":source_address_is_site_local, :source_address_is_loopback, " +
                                    ":source_address_is_multicast, :source_port, :destination_mac, " +
                                    ":destination_address::inet, :destination_address_is_site_local, " +
                                    ":destination_address_is_loopback, :destination_address_is_multicast, " +
                                    ":destination_port, :bytes_count, :segments_count, :start_time, " +
                                    ":end_time, :most_recent_segment_time, :state, " +
                                    ":source_address_geo_asn_number, :source_address_geo_asn_name, " +
                                    ":source_address_geo_asn_domain, :source_address_geo_city, " +
                                    ":source_address_geo_country_code, " +
                                    ":source_address_geo_latitude, :source_address_geo_longitude, " +
                                    ":destination_address_geo_asn_number, :destination_address_geo_asn_name, " +
                                    ":destination_address_geo_asn_domain, :destination_address_geo_city, " +
                                    ":destination_address_geo_country_code, " +
                                    ":destination_address_geo_latitude, :destination_address_geo_longitude, " +
                                    ":created_at)")
                            .bind("tap_uuid", tapUuid)
                            .bind("l4_type", "TCP")
                            .bind("session_key", sessionKey)
                            .bind("source_mac", session.sourceMac())
                            .bind("source_address", session.sourceAddress())
                            .bind("source_address_is_site_local", sourceAddress.isSiteLocalAddress())
                            .bind("source_address_is_loopback", sourceAddress.isLoopbackAddress())
                            .bind("source_address_is_multicast", sourceAddress.isMulticastAddress())
                            .bind("source_port", session.sourcePort())
                            .bind("destination_mac", session.destinationMac())
                            .bind("destination_address", session.destinationAddress())
                            .bind("destination_address_is_site_local", destinationAddress.isSiteLocalAddress())
                            .bind("destination_address_is_loopback", destinationAddress.isLoopbackAddress())
                            .bind("destination_address_is_multicast", destinationAddress.isMulticastAddress())
                            .bind("destination_port", session.destinationPort())
                            .bind("bytes_count", session.bytesCount())
                            .bind("segments_count", session.segmentsCount())
                            .bind("start_time", session.startTime())
                            .bind("end_time", session.endTime())
                            .bind("most_recent_segment_time", session.mostRecentSegmentTime())
                            .bind("state", TcpSessionState.valueOf(session.state().toUpperCase()))
                            .bind("source_address_geo_asn_number", sourceGeo.map(g -> g.asn().number()).orElse(null))
                            .bind("source_address_geo_asn_name", sourceGeo.map(g -> g.asn().name()).orElse(null))
                            .bind("source_address_geo_asn_domain", sourceGeo.map(g -> g.asn().domain()).orElse(null))
                            .bind("source_address_geo_city", sourceGeo.map(g -> g.geo().city()).orElse(null))
                            .bind("source_address_geo_country_code", sourceGeo.map(g -> g.geo().countryCode()).orElse(null))
                            .bind("source_address_geo_latitude", sourceGeo.map(g -> g.geo().latitude()).orElse(null))
                            .bind("source_address_geo_longitude", sourceGeo.map(g -> g.geo().longitude()).orElse(null))
                            .bind("destination_address_geo_asn_number", destinationGeo.map(g -> g.asn().number()).orElse(null))
                            .bind("destination_address_geo_asn_name", destinationGeo.map(g -> g.asn().name()).orElse(null))
                            .bind("destination_address_geo_asn_domain", destinationGeo.map(g -> g.asn().domain()).orElse(null))
                            .bind("destination_address_geo_city", destinationGeo.map(g -> g.geo().city()).orElse(null))
                            .bind("destination_address_geo_country_code", destinationGeo.map(g -> g.geo().countryCode()).orElse(null))
                            .bind("destination_address_geo_latitude", destinationGeo.map(g -> g.geo().latitude()).orElse(null))
                            .bind("destination_address_geo_longitude", destinationGeo.map(g -> g.geo().longitude()).orElse(null))
                            .bind("created_at", timestamp)
                            .execute();
                }
            });
        } catch(Exception e) {
            LOG.error("Could not write TCP session.", e);
        }
    }
    @Override
    public void retentionClean() {
        NzymeNode nzyme = tablesService.getNzyme();
        int l4RetentionDays = Integer.parseInt(nzyme.getDatabaseCoreRegistry()
                .getValue(EthernetRegistryKeys.L4_RETENTION_TIME_DAYS.key())
                .orElse(EthernetRegistryKeys.L4_RETENTION_TIME_DAYS.defaultValue().orElse("MISSING"))
        );
        DateTime l4CutOff = DateTime.now().minusDays(l4RetentionDays);
        LOG.info("Ethernet/L4 data retention: <{}> days / Delete data older than <{}>.",
                l4RetentionDays, l4CutOff);
        nzyme.getDatabase().useHandle(handle -> {
            handle.createUpdate("DELETE FROM l4_sessions WHERE most_recent_segment_time < :cutoff")
                    .bind("cutoff", l4CutOff)
                    .execute();
        });
    }
}
package app.nzyme.core.integrations.geoip;
import app.nzyme.core.NzymeNode;
import app.nzyme.core.connect.ConnectRegistryKeys;
import app.nzyme.core.integrations.geoip.ipinfo.IpInfoFreeCountryAsnLookupResult;
import app.nzyme.core.util.MetricNames;
import com.codahale.metrics.Gauge;
import com.codahale.metrics.MetricRegistry;
import com.codahale.metrics.Timer;
import com.google.common.cache.CacheBuilder;
import com.google.common.cache.CacheLoader;
import com.google.common.cache.LoadingCache;
import com.google.common.net.HttpHeaders;
import com.google.common.util.concurrent.ThreadFactoryBuilder;
import com.maxmind.db.Reader;
import okhttp3.HttpUrl;
import okhttp3.OkHttpClient;
import okhttp3.Request;
import okhttp3.Response;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.jetbrains.annotations.NotNull;
import java.io.ByteArrayInputStream;
import java.io.IOException;
import java.net.InetAddress;
import java.util.Optional;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.ReentrantLock;
public class GeoIpService {
    private static final Logger LOG = LogManager.getLogger(GeoIpService.class);
    private final NzymeNode nzyme;
    private final Timer lookupTimerUncached;
    private final LoadingCache<InetAddress, Optional<GeoIpLookupResult>> cache;
    private final ReentrantLock lock = new ReentrantLock();
    private Reader mmdb = null;
    private final ScheduledExecutorService refresher;
    // Can be disabled if Connect is not set up or GeoIp data source is not enabled in Connect.
    private boolean isEnabled = false;
    public GeoIpService(NzymeNode nzyme) {
        this.nzyme = nzyme;
        this.cache = CacheBuilder.newBuilder() // TODO Configurable
                .maximumSize(10000)
                .expireAfterWrite(10, TimeUnit.MINUTES)
                .build(new CacheLoader<>() {
                    @Override
                    public Optional<GeoIpLookupResult> load(@NotNull InetAddress address) {
                        return mmdbLookup(address);
                    }
                });
        this.lookupTimerUncached = nzyme.getMetrics().timer(
                MetricRegistry.name(MetricNames.GEOIP_LOOKUP_TIMING_UNCACHED)
        );
        nzyme.getMetrics().register(MetricNames.GEOIP_CACHE_SIZE, new Gauge<Long>() {
            @Override
            public Long getValue() {
                return cache.size();
            }
        });
        // Reload on configuration change.
        nzyme.getRegistryChangeMonitor()
                .onChange("core", ConnectRegistryKeys.CONNECT_API_KEY.key(), this::reload);
        nzyme.getRegistryChangeMonitor()
                .onChange("core", ConnectRegistryKeys.CONNECT_ENABLED.key(), this::reload);
        // Reload if provided services by Connect change.
        nzyme.getRegistryChangeMonitor()
                .onChange("core", ConnectRegistryKeys.PROVIDED_SERVICES.key(), this::reload);
        refresher = Executors.newSingleThreadScheduledExecutor(
                new ThreadFactoryBuilder()
                        .setDaemon(true)
                        .setNameFormat("geoip-refresher-%d")
                        .build()
        );
        refresher.scheduleAtFixedRate(this::reload, 1, 1, TimeUnit.HOURS);
    }
    private void reload() {
        // Reload with new registry settings.
        initialize();
        // Clear cache.
        cache.invalidateAll();
    }
    public void initialize() {
        // IMPORTANT: This method will also be called on configuration changes.
        // Update connect status.
        this.isEnabled = nzyme.getConnect().isEnabled();
        if (!this.isEnabled) {
            return;
        }
        lock.lock();
        try {
            // Load MMDB from connect.
            Optional<byte[]> bytes = fetchMmdbFromConnect();
            // Check if GeoIP data was disabled in Connect for this cluster.
            if (bytes.isEmpty()) {
                this.isEnabled = false;
                return;
            }
            // We have (new) data. Close current reader in preparation for switch.
            if (this.mmdb != null) {
                this.mmdb.close();
            }
            // Create new reader with (new) data.
            this.mmdb = new Reader(new ByteArrayInputStream(bytes.get()));
            this.isEnabled = true;
        } catch (Exception e) {
            LOG.error("Could not create MMDB reader.", e);
            this.isEnabled = false;
            throw new RuntimeException(e);
        } finally {
            lock.unlock();
        }
    }
    public Optional<GeoIpLookupResult> lookup(InetAddress address) {
        if (!isEnabled) {
            return Optional.empty();
        }
        return cache.getUnchecked(address);
    }
    private Optional<GeoIpLookupResult> mmdbLookup(InetAddress address) {
        try (Timer.Context ignored = lookupTimerUncached.time()) {
            lock.lock();
            try {
                IpInfoFreeCountryAsnLookupResult lookup = mmdb.get(address, IpInfoFreeCountryAsnLookupResult.class);
                if (lookup == null) {
                    return Optional.empty();
                }
                GeoIpGeoInformation geo = GeoIpGeoInformation.create(
                        null,
                        lookup.getCountryCode(),
                        lookup.getCountryName(),
                        null,
                        null
                );
                Long asNumber;
                if (lookup.getAsNumber() != null) {
                    String[] parts = lookup.getAsNumber().split("^AS");
                    if (parts.length > 1) {
                        asNumber = Long.parseLong(parts[1]);
                    } else {
                        asNumber = null;
                    }
                } else {
                    asNumber = null;
                }
                GeoIpAsnInformation asn = GeoIpAsnInformation.create(
                        asNumber,
                        lookup.getAsName(),
                        lookup.getAsDomain()
                );
                return Optional.of(GeoIpLookupResult.create(asn, geo));
            } catch (Exception e) {
                LOG.info("Could not look up IP address [{}].", address, e);
                return Optional.empty();
            } finally {
                lock.unlock();
            }
        }
    }
    private Optional<byte[]> fetchMmdbFromConnect() {
        LOG.debug("Loading new GeoIP data from Connect.");
        try {
            OkHttpClient c = new OkHttpClient.Builder()
                    .connectTimeout(60, TimeUnit.SECONDS)
                    .writeTimeout(15, TimeUnit.SECONDS)
                    .readTimeout(5, TimeUnit.MINUTES)
                    .followRedirects(true)
                    .build();
            HttpUrl url = HttpUrl.get(nzyme.getConnect().getApiUri())
                    .newBuilder()
                    .addPathSegment("data")
                    .addPathSegment("geoip")
                    .addPathSegment("ip")
                    .build();
            Response response = c.newCall(new Request.Builder()
                            .addHeader("User-Agent", "nzyme")
                            .get()
                            .url(url)
                            .addHeader(HttpHeaders.AUTHORIZATION, "Bearer " + nzyme.getConnect().getApiKey())
                            .addHeader("Content-Type", "application/octet-stream")
                            .addHeader(HttpHeaders.USER_AGENT, "nzyme-node")
                            .build()
                    ).execute();
            try (response) {
                if (!response.isSuccessful()) {
                    if (response.code() == 403) {
                        // GeoIP data disabled in Connect for this cluster.
                        return Optional.empty();
                    }
                    throw new RuntimeException("Expected HTTP 200 or 403 but got HTTP " + response.code());
                }
                if (response.body() == null) {
                    throw new RuntimeException("Empty response.");
                }
                LOG.info("GeoIP data download from Connect complete.");
                return Optional.of(response.body().bytes());
            }
        }catch (Exception e) {
            LOG.error("Could not download GeoIP data from Connect.", e);
            return Optional.empty();
        }
    }
}
/*
 * This file is part of nzyme.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the Server Side Public License, version 1,
 * as published by MongoDB, Inc.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * Server Side Public License for more details.
 *
 * You should have received a copy of the Server Side Public License
 * along with this program. If not, see
 * <http://www.mongodb.com/licensing/server-side-public-license>.
 */
package app.nzyme.core.tables.dns;
import app.nzyme.core.ethernet.EthernetRegistryKeys;
import app.nzyme.core.integrations.geoip.GeoIpLookupResult;
import app.nzyme.core.rest.resources.taps.reports.tables.dns.DnsEntropyLogReport;
import app.nzyme.core.rest.resources.taps.reports.tables.dns.DnsIpStatisticsReport;
import app.nzyme.core.rest.resources.taps.reports.tables.dns.DnsLogReport;
import app.nzyme.core.rest.resources.taps.reports.tables.dns.DnsTablesReport;
import app.nzyme.core.tables.DataTable;
import app.nzyme.core.tables.TablesService;
import app.nzyme.core.util.MetricNames;
import com.codahale.metrics.Timer;
import com.google.common.collect.Maps;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.jdbi.v3.core.Handle;
import org.jdbi.v3.core.statement.PreparedBatch;
import org.joda.time.DateTime;
import java.net.InetAddress;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.UUID;
import static app.nzyme.core.util.Tools.stringtoInetAddress;
public class DNSTable implements DataTable {
    private static final Logger LOG = LogManager.getLogger(DNSTable.class);
    private final TablesService tablesService;
    private final Timer totalReportTimer;
    private final Timer statisticsReportTimer;
    private final Timer pairsReportTimer;
    private final Timer logReportTimer;
    private final Timer entropyReportTimer;
    public DNSTable(TablesService tablesService) {
        this.tablesService = tablesService;
        this.totalReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.DNS_TOTAL_REPORT_PROCESSING_TIMER);
        this.statisticsReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.DNS_STATISTICS_REPORT_PROCESSING_TIMER);
        this.pairsReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.DNS_PAIRS_REPORT_PROCESSING_TIMER);
        this.logReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.DNS_LOG_REPORT_PROCESSING_TIMER);
        this.entropyReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.DNS_ENTROPY_REPORT_PROCESSING_TIMER);
    }
    public void handleReport(UUID tapUuid, DateTime timestamp, DnsTablesReport report) {
        try (Timer.Context ignored = totalReportTimer.time()) {
            tablesService.getNzyme().getDatabase().useHandle(handle -> {
                try (Timer.Context ignored2 = statisticsReportTimer.time()) {
                    registerStatistics(handle, tapUuid, report.ips(), timestamp);
                }
                try (Timer.Context ignored2 = pairsReportTimer.time()) {
                    registerPairs(handle, tapUuid, report.queryLog(), timestamp);
                }
                try (Timer.Context ignored2 = logReportTimer.time()) {
                    registerLogs(handle, tapUuid, report.queryLog(), report.responseLog());
                }
                try (Timer.Context ignored2 = entropyReportTimer.time()) {
                    registerEntropyLogs(handle, tapUuid, report.entropyLog());
                }
            });
        }
    }
    private void registerStatistics(Handle handle,
                                    UUID tapUuid,
                                    Map<String, DnsIpStatisticsReport> m,
                                    DateTime timestamp) {
        PreparedBatch batch = handle.prepareBatch("INSERT INTO dns_statistics(tap_uuid, ip, request_count, " +
                "request_bytes, response_count, response_bytes, nxdomain_count, created_at) VALUES(:tap_uuid, " +
                ":ip::inet, :request_count, :request_bytes, :response_count, :response_bytes, :nxdomain_count, " +
                ":created_at)");
        for (Map.Entry<String, DnsIpStatisticsReport> x : m.entrySet()) {
            String ip = x.getKey();
            DnsIpStatisticsReport stats = x.getValue();
            batch.bind("tap_uuid", tapUuid)
                    .bind("ip", ip)
                    .bind("request_count", stats.requestCount())
                    .bind("request_bytes", stats.requestBytes())
                    .bind("response_count", stats.responseCount())
                    .bind("response_bytes", stats.responseBytes())
                    .bind("nxdomain_count", stats.nxDomainCount())
                    .bind("created_at", timestamp)
                    .add();
        }
        batch.execute();
    }
    private void registerPairs(Handle handle, UUID tapUuid, List<DnsLogReport> logs, DateTime timestamp) {
        // Build pairs.
        Map<String, Map<Integer, Map<String, Long>>> pairs = Maps.newHashMap();
        for (DnsLogReport log : logs) {
            if (!pairs.containsKey(log.clientAddress())) {
                pairs.put(log.clientAddress(), Maps.newHashMap());
            }
            Map<Integer, Map<String, Long>> server = pairs.get(log.clientAddress());
            if (!server.containsKey(log.serverPort())) {
                server.put(log.serverPort(), Maps.newHashMap());
            }
            Map<String, Long> port = server.get(log.serverPort());
            if (!port.containsKey(log.serverAddress())) {
                port.put(log.serverAddress(), 1L);
            } else {
                port.compute(log.serverAddress(), (k, oldCount) -> oldCount + 1);
            }
        }
        PreparedBatch batch = handle.prepareBatch("INSERT INTO dns_pairs(tap_uuid, client_address, " +
                "server_address, server_port, server_address_geo_asn_number, server_address_geo_asn_name, " +
                "server_address_geo_asn_domain, server_address_geo_city, server_address_geo_country_code, " +
                "server_address_geo_latitude, server_address_geo_longitude, server_address_is_site_local, " +
                "server_address_is_multicast, server_address_is_loopback, count, " +
                "created_at) VALUES(:tap_uuid, :client_address::inet, :server_address::inet, :server_port, " +
                ":server_address_geo_asn_number, :server_address_geo_asn_name, :server_address_geo_asn_domain, " +
                ":server_address_geo_city, :server_address_geo_country_code, :server_address_geo_latitude, " +
                ":server_address_geo_longitude, :server_address_is_site_local, :server_address_is_multicast, " +
                ":server_address_is_loopback, :count, :timestamp)");
        for (Map.Entry<String, Map<Integer, Map<String, Long>>> pair : pairs.entrySet()) {
            for (Map.Entry<Integer, Map<String, Long>> server : pair.getValue().entrySet()) {
                for (Map.Entry<String, Long> port : server.getValue().entrySet()) {
                    InetAddress serverAddress = stringtoInetAddress(port.getKey());
                    Optional<GeoIpLookupResult> geo = tablesService.getNzyme().getGeoIpService().lookup(serverAddress);
                    batch.bind("tap_uuid", tapUuid)
                            .bind("client_address", pair.getKey())
                            .bind("server_address", port.getKey())
                            .bind("server_port", server.getKey())
                            .bind("server_address_geo_asn_number", geo.map(g -> g.asn().number()).orElse(null))
                            .bind("server_address_geo_asn_name", geo.map(g -> g.asn().name()).orElse(null))
                            .bind("server_address_geo_asn_domain", geo.map(g -> g.asn().domain()).orElse(null))
                            .bind("server_address_geo_city", geo.map(g -> g.geo().city()).orElse(null))
                            .bind("server_address_geo_country_code", geo.map(g -> g.geo().countryCode()).orElse(null))
                            .bind("server_address_geo_latitude", geo.map(g -> g.geo().latitude()).orElse(null))
                            .bind("server_address_geo_longitude", geo.map(g -> g.geo().longitude()).orElse(null))
                            .bind("server_address_is_site_local", serverAddress.isSiteLocalAddress())
                            .bind("server_address_is_multicast", serverAddress.isMulticastAddress())
                            .bind("server_address_is_loopback", serverAddress.isLoopbackAddress())
                            .bind("count", port.getValue())
                            .bind("timestamp", timestamp)
                            .add();
                }
            }
        }
        batch.execute();
    }
    /*
     */
    private void registerLogs(Handle handle,
                              UUID tapUuid,
                              List<DnsLogReport> queries,
                              List<DnsLogReport> responses) {
        PreparedBatch batch = handle.prepareBatch("INSERT INTO dns_log(uuid, tap_uuid, transaction_id, " +
                "dns_type, client_address, client_port, client_mac, client_address_geo_asn_number, " +
                "client_address_geo_asn_name, client_address_geo_asn_domain, client_address_geo_city, " +
                "client_address_geo_country_code, client_address_geo_latitude, client_address_geo_longitude, " +
                "client_address_is_site_local, client_address_is_multicast, client_address_is_loopback, " +
                "server_address, server_port, server_mac, server_address_geo_asn_number, " +
                "server_address_geo_asn_name, server_address_geo_asn_domain, server_address_geo_city, " +
                "server_address_geo_country_code, server_address_geo_latitude, server_address_geo_longitude, " +
                "server_address_is_site_local, server_address_is_multicast, server_address_is_loopback, " +
                "data_value, data_value_etld, data_type, timestamp, created_at) VALUES(:uuid, :tap_uuid, " +
                ":transaction_id, :dns_type, :client_address::inet, :client_port, :client_mac, " +
                ":client_address_geo_asn_number, :client_address_geo_asn_name, :client_address_geo_asn_domain, " +
                ":client_address_geo_city, :client_address_geo_country_code, :client_address_geo_latitude, " +
                ":client_address_geo_longitude, :client_address_is_site_local, :client_address_is_multicast, " +
                ":client_address_is_loopback, :server_address::inet, :server_port, :server_mac, " +
                ":server_address_geo_asn_number, :server_address_geo_asn_name, :server_address_geo_asn_domain, " +
                ":server_address_geo_city, :server_address_geo_country_code, :server_address_geo_latitude, " +
                ":server_address_geo_longitude, :server_address_is_site_local, :server_address_is_multicast, " +
                ":server_address_is_loopback, :data_value, :data_value_etld, :data_type, :timestamp, NOW())");
        for (DnsLogReport d : queries) {
            InetAddress serverAddress = stringtoInetAddress(d.serverAddress());
            Optional<GeoIpLookupResult> serverGeo = tablesService.getNzyme().getGeoIpService().lookup(serverAddress);
            InetAddress clientAddress = stringtoInetAddress(d.clientAddress());
            Optional<GeoIpLookupResult> clientGeo = tablesService.getNzyme().getGeoIpService().lookup(clientAddress);
            batch
                    .bind("uuid", UUID.randomUUID())
                    .bind("tap_uuid", tapUuid)
                    .bind("transaction_id", d.transactionId())
                    .bind("dns_type", "query")
                    .bind("client_address", d.clientAddress())
                    .bind("client_port", d.clientPort())
                    .bind("client_mac", d.clientMac())
                    .bind("client_address_geo_asn_number", clientGeo.map(g -> g.asn().number()).orElse(null))
                    .bind("client_address_geo_asn_name", clientGeo.map(g -> g.asn().name()).orElse(null))
                    .bind("client_address_geo_asn_domain", clientGeo.map(g -> g.asn().domain()).orElse(null))
                    .bind("client_address_geo_city", clientGeo.map(g -> g.geo().city()).orElse(null))
                    .bind("client_address_geo_country_code", clientGeo.map(g -> g.geo().countryCode()).orElse(null))
                    .bind("client_address_geo_latitude", clientGeo.map(g -> g.geo().latitude()).orElse(null))
                    .bind("client_address_geo_longitude", clientGeo.map(g -> g.geo().longitude()).orElse(null))
                    .bind("client_address_is_site_local", clientAddress.isSiteLocalAddress())
                    .bind("client_address_is_multicast", clientAddress.isMulticastAddress())
                    .bind("client_address_is_loopback", clientAddress.isLoopbackAddress())
                    .bind("server_address", d.serverAddress())
                    .bind("server_port", d.serverPort())
                    .bind("server_mac", d.serverMac())
                    .bind("server_address_geo_asn_number", serverGeo.map(g -> g.asn().number()).orElse(null))
                    .bind("server_address_geo_asn_name", serverGeo.map(g -> g.asn().name()).orElse(null))
                    .bind("server_address_geo_asn_domain", serverGeo.map(g -> g.asn().domain()).orElse(null))
                    .bind("server_address_geo_city", serverGeo.map(g -> g.geo().city()).orElse(null))
                    .bind("server_address_geo_country_code", serverGeo.map(g -> g.geo().countryCode()).orElse(null))
                    .bind("server_address_geo_latitude", serverGeo.map(g -> g.geo().latitude()).orElse(null))
                    .bind("server_address_geo_longitude", serverGeo.map(g -> g.geo().longitude()).orElse(null))
                    .bind("server_address_is_site_local", serverAddress.isSiteLocalAddress())
                    .bind("server_address_is_multicast", serverAddress.isMulticastAddress())
                    .bind("server_address_is_loopback", serverAddress.isLoopbackAddress())
                    .bind("data_value", d.dataValue())
                    .bind("data_value_etld", d.dataValueEtld())
                    .bind("data_type", d.dataType())
                    .bind("timestamp", d.timestamp())
                    .add();
        }
        for (DnsLogReport d : responses) {
            InetAddress serverAddress = stringtoInetAddress(d.serverAddress());
            Optional<GeoIpLookupResult> serverGeo = tablesService.getNzyme().getGeoIpService().lookup(serverAddress);
            InetAddress clientAddress = stringtoInetAddress(d.clientAddress());
            Optional<GeoIpLookupResult> clientGeo = tablesService.getNzyme().getGeoIpService().lookup(clientAddress);
            batch
                    .bind("uuid", UUID.randomUUID())
                    .bind("tap_uuid", tapUuid)
                    .bind("transaction_id", d.transactionId())
                    .bind("dns_type", "response")
                    .bind("client_address", d.clientAddress())
                    .bind("client_port", d.clientPort())
                    .bind("client_mac", d.clientMac())
                    .bind("client_address_geo_asn_number", clientGeo.map(g -> g.asn().number()).orElse(null))
                    .bind("client_address_geo_asn_name", clientGeo.map(g -> g.asn().name()).orElse(null))
                    .bind("client_address_geo_asn_domain", clientGeo.map(g -> g.asn().domain()).orElse(null))
                    .bind("client_address_geo_city", clientGeo.map(g -> g.geo().city()).orElse(null))
                    .bind("client_address_geo_country_code", clientGeo.map(g -> g.geo().countryCode()).orElse(null))
                    .bind("client_address_geo_latitude", clientGeo.map(g -> g.geo().latitude()).orElse(null))
                    .bind("client_address_geo_longitude", clientGeo.map(g -> g.geo().longitude()).orElse(null))
                    .bind("client_address_is_site_local", clientAddress.isSiteLocalAddress())
                    .bind("client_address_is_multicast", clientAddress.isMulticastAddress())
                    .bind("client_address_is_loopback", clientAddress.isLoopbackAddress())
                    .bind("server_address", d.serverAddress())
                    .bind("server_port", d.serverPort())
                    .bind("server_mac", d.serverMac())
                    .bind("server_address_geo_asn_number", serverGeo.map(g -> g.asn().number()).orElse(null))
                    .bind("server_address_geo_asn_name", serverGeo.map(g -> g.asn().name()).orElse(null))
                    .bind("server_address_geo_asn_domain", serverGeo.map(g -> g.asn().domain()).orElse(null))
                    .bind("server_address_geo_city", serverGeo.map(g -> g.geo().city()).orElse(null))
                    .bind("server_address_geo_country_code", serverGeo.map(g -> g.geo().countryCode()).orElse(null))
                    .bind("server_address_geo_latitude", serverGeo.map(g -> g.geo().latitude()).orElse(null))
                    .bind("server_address_geo_longitude", serverGeo.map(g -> g.geo().longitude()).orElse(null))
                    .bind("server_address_is_site_local", serverAddress.isSiteLocalAddress())
                    .bind("server_address_is_multicast", serverAddress.isMulticastAddress())
                    .bind("server_address_is_loopback", serverAddress.isLoopbackAddress())
                    .bind("data_value", d.dataValue())
                    .bind("data_value_etld", d.dataValueEtld())
                    .bind("data_type", d.dataType())
                    .bind("timestamp", d.timestamp())
                    .add();
        }
        batch.execute();
    }
    public void registerEntropyLogs(Handle handle,
                                    UUID tapUuid,
                                    List<DnsEntropyLogReport> logs) {
        PreparedBatch batch = handle.prepareBatch("INSERT INTO dns_entropy_log(tap_uuid, transaction_id, " +
                "entropy, entropy_mean, zscore, timestamp, created_at) VALUES(:tap_uuid, :transaction_id, " +
                ":entropy, :entropy_mean, :zscore, :timestamp, NOW())");
        for (DnsEntropyLogReport log : logs) {
            batch
                    .bind("tap_uuid", tapUuid)
                    .bind("transaction_id", log.transactionId())
                    .bind("entropy", log.entropy())
                    .bind("entropy_mean", log.entropyMean())
                    .bind("zscore", log.zScore())
                    .bind("timestamp", log.timestamp())
                    .add();
        }
        batch.execute();
    }
    @Override
    public void retentionClean() {
        int retentionTimeDays = Integer.parseInt(tablesService.getNzyme().getDatabaseCoreRegistry()
                .getValue(EthernetRegistryKeys.DNS_RETENTION_TIME_DAYS.key())
                .orElse(EthernetRegistryKeys.DNS_RETENTION_TIME_DAYS.defaultValue().orElse("MISSING"))
        );
    }
}
/*
 * This file is part of nzyme.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the Server Side Public License, version 1,
 * as published by MongoDB, Inc.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * Server Side Public License for more details.
 *
 * You should have received a copy of the Server Side Public License
 * along with this program. If not, see
 * <http://www.mongodb.com/licensing/server-side-public-license>.
 */
package app.nzyme.core.util;
import app.nzyme.core.bluetooth.sig.BluetoothSigService;
import app.nzyme.core.context.ContextService;
import app.nzyme.core.crypto.Crypto;
import app.nzyme.core.database.DatabaseImpl;
import app.nzyme.core.integrations.geoip.GeoIpService;
import app.nzyme.core.ouis.OuiService;
import app.nzyme.core.rest.interceptors.TapTableSizeInterceptor;
import app.nzyme.core.security.authentication.PasswordHasher;
import app.nzyme.core.tables.bluetooth.BluetoothTable;
import app.nzyme.core.tables.dns.DNSTable;
import app.nzyme.core.tables.dot11.Dot11Table;
import app.nzyme.core.tables.socks.SOCKSTable;
import app.nzyme.core.tables.ssh.SSHTable;
import app.nzyme.core.tables.tcp.TCPTable;
import static com.codahale.metrics.MetricRegistry.name;
public class MetricNames {
    public static final String OUI_LOOKUP_TIMING = name(OuiService.class, "lookup-timing");
    public static final String BTSIG_CID_LOOKUP_TIMING = name(BluetoothSigService.class, "company-id-lookup-timing");
    public static final String BTSIG_SUUID_LOOKUP_TIMING = name(BluetoothSigService.class, "service-uuid-lookup-timing");
    public static final String DATABASE_SIZE = name(DatabaseImpl.class, "size");
    public static final String GEOIP_CACHE_SIZE = name(GeoIpService.class, "cache-size");
    public static final String GEOIP_LOOKUP_TIMING_UNCACHED = name(GeoIpService.class, "lookup-timing-uncached");
    public static final String PGP_ENCRYPTION_TIMING = name(Crypto.class, "encryption-timing");
    public static final String PGP_DECRYPTION_TIMING = name(Crypto.class, "decryption-timing");
    public static final String PASSWORD_HASHING_TIMER = name(PasswordHasher.class, "hashing-timer");
    public static final String TAP_TABLE_REQUEST_SIZES = name(TapTableSizeInterceptor.class, "request_size");
    public static final String CONTEXT_MAC_CACHE_SIZE = name(ContextService.class, "mac-cache-size");
    public static final String CONTEXT_MAC_LOOKUP_TIMING = name(ContextService.class, "mac-lookup-timing");
    public static final String DOT11_TOTAL_REPORT_PROCESSING_TIMER = name(Dot11Table.class, "total-report-processing-timing");
    public static final String DOT11_BSSID_REPORT_PROCESSING_TIMER = name(Dot11Table.class, "bssid-report-processing-timing");
    public static final String DOT11_CLIENTS_REPORT_PROCESSING_TIMER = name(Dot11Table.class, "clients-report-processing-timing");
    public static final String DOT11_DISCO_REPORT_PROCESSING_TIMER = name(Dot11Table.class, "disco-report-processing-timing");
    public static final String DOT11_ALERT_PROCESSING_TIMER = name(Dot11Table.class, "alert-processing-timing");
    public static final String BLUETOOTH_TOTAL_REPORT_PROCESSING_TIMER = name(BluetoothTable.class, "total-report-processing-timing");
    public static final String DNS_TOTAL_REPORT_PROCESSING_TIMER = name(DNSTable.class, "total-report-processing-timing");
    public static final String DNS_STATISTICS_REPORT_PROCESSING_TIMER = name(DNSTable.class, "statistics-report-processing-timing");
    public static final String DNS_PAIRS_REPORT_PROCESSING_TIMER = name(DNSTable.class, "pairs-report-processing-timing");
    public static final String DNS_LOG_REPORT_PROCESSING_TIMER = name(DNSTable.class, "log-report-processing-timing");
    public static final String DNS_ENTROPY_REPORT_PROCESSING_TIMER = name(DNSTable.class, "entropy-report-processing-timing");
    public static final String TCP_TOTAL_REPORT_PROCESSING_TIMER = name(TCPTable.class, "total-report-processing-timing");
    public static final String TCP_SESSIONS_REPORT_PROCESSING_TIMER = name(TCPTable.class, "sessions-report-processing-timing");
    public static final String TCP_SESSION_DISCOVERY_QUERY_TIMER = name(TCPTable.class, "session-discovery-query-timing");
    public static final String SOCKS_TOTAL_REPORT_PROCESSING_TIMER = name(SOCKSTable.class, "total-report-processing-timing");
    public static final String SSH_TOTAL_REPORT_PROCESSING_TIMER = name(SSHTable.class, "total-report-processing-timing");
}
package app.nzyme.core.security.authentication;
import app.nzyme.core.util.MetricNames;
import com.codahale.metrics.MetricRegistry;
import com.codahale.metrics.Timer;
import com.google.auto.value.AutoValue;
import com.google.common.io.BaseEncoding;
import org.bouncycastle.crypto.generators.Argon2BytesGenerator;
import org.bouncycastle.crypto.params.Argon2Parameters;
import java.nio.charset.StandardCharsets;
import java.security.SecureRandom;
import java.util.Arrays;
public class PasswordHasher {
    private final Timer hashingTimer;
    public PasswordHasher(MetricRegistry metrics) {
        this.hashingTimer = metrics.timer(MetricNames.PASSWORD_HASHING_TIMER);
    }
    public GeneratedHashAndSalt createHash(String password) {
        if (!runPasswordPreconditions(password)) {
            throw new RuntimeException("Password preconditions not met.");
        }
        // Generate 128 bit salt.
        byte[] salt = new byte[128];
        new SecureRandom().nextBytes(salt);
        byte[] hash = generateHash(password, salt);
        return GeneratedHashAndSalt.create(
                BaseEncoding.base64().encode(hash),
                BaseEncoding.base64().encode(salt)
        );
    }
    public boolean runPasswordPreconditions(String password) {
        if (password == null || password.isEmpty()) {
            return false;
        }
        if (password.length() > 128) {
            return false;
        }
        if (password.length() < 12) {
            return false;
        }
        return true;
    }
    public boolean compareHash(String password, String hash, String salt) {
        if (!runPasswordPreconditions(password)) {
            throw new RuntimeException("Password preconditions not met.");
        }
        if (salt == null || salt.isEmpty()) {
            throw new RuntimeException("NULL or empty salt provided.");
        }
        byte[] saltBytes = BaseEncoding.base64().decode(salt);
        if (saltBytes.length != 128) {
            throw new RuntimeException("Incorrect salt length: " + saltBytes.length);
        }
        byte[] compareHash = generateHash(password, saltBytes);
        return constantTimeArrayEquals(compareHash, BaseEncoding.base64().decode(hash));
    }
    private byte[] generateHash(String password, byte[] salt) {
        Timer.Context timer = hashingTimer.time();
        Argon2BytesGenerator generator = new Argon2BytesGenerator();
        // We pick very expensive parameters here because there will not be a lot of parallel hashing operations in nzyme.
        int iterations = 20;
        int memLimitKilobyte = 47104; // 46 MB
        int outputLength = 256;
        int parallelism = 1;
        generator.init(
                new Argon2Parameters.Builder(Argon2Parameters.ARGON2_id)
                        .withVersion(Argon2Parameters.ARGON2_VERSION_13)
                        .withIterations(iterations)
                        .withMemoryAsKB(memLimitKilobyte)
                        .withParallelism(parallelism)
                        .withSalt(salt)
                        .build()
        );
        byte[] hash = new byte[outputLength];
        generator.generateBytes(password.getBytes(StandardCharsets.UTF_8), hash, 0, hash.length);
        timer.stop();
        return hash;
    }
    /*
     * From Spring Security, licensed under Apache 2:
     *
     * https://github.com/spring-projects/spring-security/blob/a44e91d0440f4d613ccd64d1c648ab0af89601c2/crypto/src/main/java/org/springframework/security/crypto/argon2/Argon2PasswordEncoder.java#L160
     */
    private static boolean constantTimeArrayEquals(byte[] expected, byte[] actual) {
        if (expected.length != actual.length) {
            return false;
        }
        int result = 0;
        for (int i = 0; i < expected.length; i++) {
            result |= expected[i] ^ actual[i];
        }
        return result == 0;
    }
    @AutoValue
    public static abstract class GeneratedHashAndSalt {
        public abstract String hash();
        public abstract String salt();
        public static GeneratedHashAndSalt create(String hash, String salt) {
            return builder()
                    .hash(hash)
                    .salt(salt)
                    .build();
        }
        public static Builder builder() {
            return new AutoValue_PasswordHasher_GeneratedHashAndSalt.Builder();
        }
        @AutoValue.Builder
        public abstract static class Builder {
            public abstract Builder hash(String hash);
            public abstract Builder salt(String salt);
            public abstract GeneratedHashAndSalt build();
        }
    }
}
/*
 * This file is part of nzyme.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the Server Side Public License, version 1,
 * as published by MongoDB, Inc.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * Server Side Public License for more details.
 *
 * You should have received a copy of the Server Side Public License
 * along with this program. If not, see
 * <http://www.mongodb.com/licensing/server-side-public-license>.
 */
package app.nzyme.core;
import app.nzyme.core.bluetooth.Bluetooth;
import app.nzyme.core.bluetooth.sig.BluetoothSigService;
import app.nzyme.core.cache.CacheManager;
import app.nzyme.core.connect.ConnectService;
import app.nzyme.core.context.ContextService;
import app.nzyme.core.database.DataCategory;
import app.nzyme.core.database.DataTableInformation;
import app.nzyme.core.database.tasks.handlers.GlobalPurgeCategoryTaskHandler;
import app.nzyme.core.database.tasks.handlers.OrganizationPurgeCategoryTaskHandler;
import app.nzyme.core.database.tasks.handlers.TenantPurgeCategoryTaskHandler;
import app.nzyme.core.detection.alerts.DetectionAlertService;
import app.nzyme.core.distributed.ClusterManager;
import app.nzyme.core.distributed.NodeManager;
import app.nzyme.core.distributed.messaging.postgres.PostgresMessageBusImpl;
import app.nzyme.core.distributed.tasksqueue.postgres.PostgresTasksQueueImpl;
import app.nzyme.core.dot11.Dot11;
import app.nzyme.core.dot11.monitoring.Dot11SignalTrackMonitor;
import app.nzyme.core.dot11.monitoring.clients.KnownClientMonitor;
import app.nzyme.core.dot11.monitoring.disco.Dot11DiscoMonitor;
import app.nzyme.core.dot11.monitoring.ssids.KnownSSIDMonitor;
import app.nzyme.core.ethernet.EthernetConnectionCleaner;
import app.nzyme.core.events.EventEngine;
import app.nzyme.core.events.EventEngineImpl;
import app.nzyme.core.integrations.geoip.GeoIpService;
import app.nzyme.core.monitoring.health.HealthMonitor;
import app.nzyme.core.ouis.OuiService;
import app.nzyme.core.periodicals.connect.ConnectStatusReporter;
import app.nzyme.core.context.ContextCleaner;
import app.nzyme.core.periodicals.distributed.NodeUpdater;
import app.nzyme.core.registry.RegistryChangeMonitorImpl;
import app.nzyme.core.rest.server.NzymeHttpServer;
import app.nzyme.core.security.authentication.AuthenticationService;
import app.nzyme.core.subsystems.Subsystems;
import app.nzyme.plugin.*;
import app.nzyme.plugin.distributed.messaging.MessageBus;
import app.nzyme.plugin.distributed.tasksqueue.*;
import app.nzyme.plugin.retro.RetroService;
import com.codahale.metrics.Gauge;
import com.codahale.metrics.MetricRegistry;
import com.codahale.metrics.jmx.JmxReporter;
import com.codahale.metrics.jvm.*;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.google.common.collect.Lists;
import app.nzyme.core.configuration.base.BaseConfiguration;
import app.nzyme.core.configuration.node.NodeConfiguration;
import app.nzyme.core.crypto.Crypto;
import app.nzyme.core.database.DatabaseImpl;
import app.nzyme.core.ethernet.Ethernet;
import app.nzyme.core.periodicals.PeriodicalManager;
import app.nzyme.core.periodicals.versioncheck.VersioncheckThread;
import app.nzyme.core.plugin.loading.PluginLoader;
import app.nzyme.core.registry.RegistryImpl;
import app.nzyme.core.tables.TablesService;
import app.nzyme.core.taps.TapManager;
import app.nzyme.core.util.MetricNames;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.jetbrains.annotations.Nullable;
import java.io.File;
import java.nio.file.Path;
import java.util.List;
import java.util.Optional;
import java.util.concurrent.TimeUnit;
import java.util.logging.Level;
public class NzymeNodeImpl implements NzymeNode {
    private static final Logger LOG = LogManager.getLogger(NzymeNodeImpl.class);
    private final Version version;
    private final NodeIdentification nodeIdentification;
    private final NodeConfiguration configuration;
    private final BaseConfiguration baseConfiguration;
    private final Path dataDirectory;
    private final DatabaseImpl database;
    private final AuthenticationService authenticationService;
    private final RegistryImpl registry;
    private final RegistryChangeMonitor registryChangeMonitor;
    private final Subsystems subsystems;
    private final NodeManager nodeManager;
    private final ClusterManager clusterManager;
    private final NzymeHttpServer httpServer;
    private final MetricRegistry metrics;
    private final TapManager tapManager;
    private final MessageBus messageBus;
    private final TasksQueue tasksQueue;
    private final GeoIpService geoIpService;
    private final OuiService ouiService;
    private final BluetoothSigService bluetoothSigService;
    private final ContextService contextService;
    private final Ethernet ethernet;
    private final Dot11 dot11;
    private final Bluetooth bluetooth;
    private final TablesService tablesService;
    private final ObjectMapper objectMapper;
    private final DetectionAlertService detectionAlertService;
    private final EventEngine eventEngine;
    private final ConnectService connect;
    private final HealthMonitor healthMonitor;
    private List<String> plugins;
    private Optional<RetroService> retroService = Optional.empty();
    private final Crypto crypto;
    private final List<Object> pluginRestResources;
    public NzymeNodeImpl(BaseConfiguration baseConfiguration, NodeConfiguration configuration, DatabaseImpl database) {
        this.baseConfiguration = baseConfiguration;
        this.version = new Version();
        this.dataDirectory = Path.of(baseConfiguration.dataDirectory());
        this.metrics = new MetricRegistry();
        this.database = database;
        this.configuration = configuration;
        this.registry = new RegistryImpl(this, "core");
        this.registryChangeMonitor = new RegistryChangeMonitorImpl(this);
        this.authenticationService = new AuthenticationService(this);
        this.subsystems = new Subsystems(this);
        this.nodeManager = new NodeManager(this);
        try {
            this.nodeManager.initialize();
            this.nodeIdentification = NodeIdentification.create(nodeManager.getLocalNodeId(), baseConfiguration.name());
            this.nodeManager.registerSelf();
        } catch (NodeManager.NodeInitializationException e) {
            throw new RuntimeException("Could not initialize distributed subsystem.", e);
        }
        this.clusterManager = new ClusterManager(this);
        this.messageBus = new PostgresMessageBusImpl(this);
        this.tasksQueue = new PostgresTasksQueueImpl(this);
        this.geoIpService = new GeoIpService(this);
        this.ouiService = new OuiService(this);
        this.bluetoothSigService = new BluetoothSigService(this);
        this.contextService = new ContextService(this);
        this.pluginRestResources = Lists.newArrayList();
        this.plugins = Lists.newArrayList();
        this.httpServer = new NzymeHttpServer(this, this.pluginRestResources);
        this.ethernet = new Ethernet(this);
        this.dot11 = new Dot11(this);
        this.bluetooth = new Bluetooth(this);
        this.tapManager = new TapManager(this);
        this.crypto = new Crypto(this);
        this.objectMapper = new ObjectMapper();
        this.connect = new ConnectService(this);
        this.healthMonitor = new HealthMonitor(this);
        // Register JVM metrics.
        this.metrics.register("gc", new GarbageCollectorMetricSet());
        this.metrics.register("classes", new ClassLoadingGaugeSet());
        this.metrics.register("fds", new FileDescriptorRatioGauge());
        this.metrics.register("jvm", new JvmAttributeGaugeSet());
        this.metrics.register("mem", new MemoryUsageGaugeSet());
        this.metrics.register("threadstates", new ThreadStatesGaugeSet());
        this.detectionAlertService = new DetectionAlertService(this);
        this.eventEngine = new EventEngineImpl(this);
        this.tablesService = new TablesService(this);
    }
    @Override
    public void initialize() {
        LOG.info("Initializing nzyme version: {}.", version.getVersionString());
        LOG.info("Initializing cluster manager...");
        this.clusterManager.initialize();
        LOG.info("Done.");
        LOG.info("Initializing message bus [{}] ...", this.messageBus.getClass().getCanonicalName());
        this.messageBus.initialize();
        LOG.info("Done.");
        LOG.info("Initializing tasks queue [{}] ...", this.tasksQueue.getClass().getCanonicalName());
        this.tasksQueue.initialize();
        LOG.info("Done.");
        // Register task handlers. (There are others registered in other parts of the system.)
        this.tasksQueue.onMessageReceived(
                TaskType.PURGE_DATA_CATEGORY_GLOBAL,
                new GlobalPurgeCategoryTaskHandler(this)
        );
        this.tasksQueue.onMessageReceived(
                TaskType.PURGE_DATA_CATEGORY_ORGANIZATION,
                new OrganizationPurgeCategoryTaskHandler(this)
        );
        this.tasksQueue.onMessageReceived(
                TaskType.PURGE_DATA_CATEGORY_TENANT,
                new TenantPurgeCategoryTaskHandler(this)
        );
        try {
            this.crypto.initialize();
        } catch (Crypto.CryptoInitializationException e) {
            throw new RuntimeException("Could not load cryptographic subsystem.", e);
        }
        if (configuration.connectSkip()) {
            // Connect is disabled in config file. None of the Connect tasks will run. (checked in ConnectService)
            LOG.warn("Connect has been disabled in configuration file. Not connecting.");
        }
        LOG.info("Initializing Geo IP service...");
        this.geoIpService.initialize();
        LOG.info("Done.");
        LOG.info("Initializing OUI service...");
        this.ouiService.initialize();
        LOG.info("Done.");
        LOG.info("Initializing Bluetooth SIG service...");
        this.bluetoothSigService.initialize();
        LOG.info("Done.");
        LOG.info("Initializing authentication service...");
        this.authenticationService.initialize();
        LOG.info("Done.");
        // Metrics JMX reporter.
        final JmxReporter reporter = JmxReporter.forRegistry(metrics).build();
        reporter.start();
        // Database metrics.
        metrics.register(MetricNames.DATABASE_SIZE, (Gauge<Long>) database::getTotalSize);
        // Periodicals. (TODO: Replace with scheduler service)
        PeriodicalManager periodicalManager = new PeriodicalManager();
        periodicalManager.scheduleAtFixedRate(new NodeUpdater(this), 0, 5, TimeUnit.SECONDS);
        periodicalManager.scheduleAtFixedRate(new ConnectStatusReporter(this), 0, 1, TimeUnit.MINUTES);
        periodicalManager.scheduleAtFixedRate(new EthernetConnectionCleaner(this), 0, 1, TimeUnit.MINUTES);
        periodicalManager.scheduleAtFixedRate(new Dot11SignalTrackMonitor(this), 1, 1, TimeUnit.MINUTES);
        periodicalManager.scheduleAtFixedRate(new Dot11DiscoMonitor(this), 1, 1, TimeUnit.MINUTES);
        periodicalManager.scheduleAtFixedRate(new ContextCleaner(getContextService()), 0, 1, TimeUnit.MINUTES);
        periodicalManager.scheduleAtFixedRate(new KnownSSIDMonitor(this), 1, 1, TimeUnit.MINUTES);
        periodicalManager.scheduleAtFixedRate(new KnownClientMonitor(this), 1, 1, TimeUnit.MINUTES);
        if (configuration.versionchecksEnabled()) {
            periodicalManager.scheduleAtFixedRate(new VersioncheckThread(version, this), 0, 60, TimeUnit.MINUTES);
        } else {
            LOG.info("Versionchecks are disabled.");
        }
        healthMonitor.initialize();
        // Load plugins.
        PluginLoader pl = new PluginLoader(new File(configuration.pluginDirectory())); // TODO make path configurable
        for (Plugin plugin : pl.loadPlugins()) {
            // Initialize plugin
            LOG.info("Initializing plugin of type [{}]: [{}] ...", plugin.getClass().getCanonicalName(), plugin.getName());
            try {
                plugin.initialize(this, getDatabaseRegistry(plugin.getId()), this, this);
            } catch(Exception e) {
                LOG.error("Could not load plugin. Skipping.", e);
                continue;
            }
            this.plugins.add(plugin.getId());
            LOG.info("Done.");
        }
        CacheManager cacheManager = new CacheManager(this);
        cacheManager.initialize();
        // Spin up REST API and web interface.
        java.util.logging.Logger.getLogger("org.glassfish.grizzly").setLevel(Level.SEVERE);
        java.util.logging.Logger.getLogger("org.glassfish.jersey.internal.inject.Providers").setLevel(Level.SEVERE);
        this.httpServer.initialize();
    }
    public void shutdown() {
        LOG.info("Shutting down.");
        // Shutdown REST API.
        if (httpServer != null) {
            LOG.info("Stopping REST API.");
            httpServer.shutdownNow();
        }
        LOG.info("Shutdown complete.");
    }
    @Override
    public NodeManager getNodeManager() {
        return nodeManager;
    }
    @Override
    public ClusterManager getClusterManager() {
        return clusterManager;
    }
    @Override
    public MessageBus getMessageBus() {
        return messageBus;
    }
    @Override
    public TasksQueue getTasksQueue() {
        return tasksQueue;
    }
    @Override
    public AuthenticationService getAuthenticationService() {
        return authenticationService;
    }
    @Override
    public Subsystems getSubsystems() {
        return subsystems;
    }
    @Override
    public HealthMonitor getHealthMonitor() {
        return healthMonitor;
    }
    @Override
    public Ethernet getEthernet() {
        return ethernet;
    }
    @Override
    public Dot11 getDot11() {
        return dot11;
    }
    @Override
    public Bluetooth getBluetooth() {
        return bluetooth;
    }
    @Override
    public GeoIpService getGeoIpService() {
        return geoIpService;
    }
    @Override
    public OuiService getOuiService() {
        return ouiService;
    }
    @Override
    public BluetoothSigService getBluetoothSigService() {
        return bluetoothSigService;
    }
    @Override
    public ContextService getContextService() {
        return contextService;
    }
    @Override
    public EventEngine getEventEngine() {
        return eventEngine;
    }
    @Override
    public TapManager getTapManager() {
        return tapManager;
    }
    @Override
    public TablesService getTablesService() {
        return tablesService;
    }
    @Override
    public List<String> getInitializedPlugins() {
        return plugins;
    }
    @Nullable
    @Override
    public Optional<RetroService> retroService() {
        return retroService;
    }
    @Override
    public Crypto getCrypto() {
        return crypto;
    }
    @Override
    public ObjectMapper getObjectMapper() {
        return objectMapper;
    }
    @Override
    public NodeConfiguration getConfiguration() {
        return configuration;
    }
    @Override
    public BaseConfiguration getBaseConfiguration() {
        return baseConfiguration;
    }
    @Override
    public Path getDataDirectory() {
        return dataDirectory;
    }
    @Override
    public MetricRegistry getMetrics() {
        return metrics;
    }
    @Override
    public Database getDatabase() {
        return database;
    }
    @Override
    public Version getVersion() {
        return version;
    }
    @Override
    public NzymeHttpServer getHttpServer() {
        return httpServer;
    }
    @Override
    public void registerRetroService(RetroService service) {
        if (this.retroService.isPresent()) {
            LOG.error("Attempt to register a new RetroService but one already exists. Aborting.");
            return;
        }
        this.retroService = Optional.of(service);
    }
    @Override
    public void registerRestResource(Object resource) {
        this.pluginRestResources.add(resource);
    }
    public Registry getDatabaseRegistry(String namespace) {
        return new RegistryImpl(this, namespace);
    }
    @Override
    public Registry getDatabaseCoreRegistry() {
        return registry;
    }
    @Override
    public RegistryChangeMonitor getRegistryChangeMonitor() {
        return registryChangeMonitor;
    }
    @Override
    public DetectionAlertService getDetectionAlertService() {
        return detectionAlertService;
    }
    @Override
    public ConnectService getConnect() {
        return connect;
    }
    @Override
    public NodeIdentification getNodeInformation() {
        return nodeIdentification;
    }
}
package app.nzyme.core.distributed;
import app.nzyme.core.NzymeNode;
import app.nzyme.core.crypto.pgp.PGPKeys;
import app.nzyme.core.distributed.database.NodeEntry;
import app.nzyme.core.distributed.database.metrics.GaugeHistogramBucket;
import app.nzyme.core.logging.CountingAppender;
import app.nzyme.core.monitoring.TimerEntry;
import app.nzyme.core.taps.db.metrics.BucketSize;
import app.nzyme.core.util.MetricNames;
import com.codahale.metrics.Gauge;
import com.codahale.metrics.MetricRegistry;
import com.codahale.metrics.Snapshot;
import com.codahale.metrics.Timer;
import com.google.common.base.Charsets;
import com.google.common.cache.CacheBuilder;
import com.google.common.cache.CacheLoader;
import com.google.common.cache.LoadingCache;
import com.google.common.collect.Lists;
import com.google.common.collect.Maps;
import com.google.common.io.BaseEncoding;
import com.google.common.util.concurrent.ThreadFactoryBuilder;
import jakarta.annotation.Nullable;
import jakarta.validation.constraints.NotNull;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.jdbi.v3.core.Handle;
import org.joda.time.DateTime;
import org.joda.time.Period;
import org.joda.time.PeriodType;
import java.io.IOException;
import java.net.URI;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.StandardOpenOption;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.UUID;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;
public class NodeManager {
    private static final Logger LOG = LogManager.getLogger(NodeManager.class);
    private final NzymeNode nzyme;
    private UUID localNodeId;
    private long localCycle;
    private final AtomicLong tapReportSize;
    private final LoadingCache<UUID, String> nodeNameCache;
    public NodeManager(NzymeNode nzyme) {
        this.nzyme = nzyme;
        this.tapReportSize = new AtomicLong(0);
        this.nodeNameCache = CacheBuilder.newBuilder().
                expireAfterAccess(10, TimeUnit.SECONDS)
                .build(new CacheLoader<>() {
                    @Override
                    public String load(@NotNull UUID nodeId) {
                        String nodeName = nzyme.getDatabase().withHandle(handle ->
                            handle.createQuery("SELECT name FROM nodes WHERE uuid = :uuid")
                                    .bind("uuid", nodeId)
                                    .mapTo(String.class)
                                    .one()
                        );
                        if (nodeName == null) {
                            return "[invalid node]";
                        }
                        return nodeName;
                    }
                });
    }
    public void initialize() throws NodeInitializationException {
        // Read local node id.
        Path nodeIdFile = Path.of(nzyme.getDataDirectory().toString(), "node_id");
        if (Files.exists(nodeIdFile)) {
            try {
                LOG.debug("Node ID file exists at [{}]", nodeIdFile.toAbsolutePath());
                localNodeId = UUID.fromString(Files.readString(nodeIdFile));
            } catch (IOException e) {
                throw new NodeInitializationException("Could not read node ID file at [" + nodeIdFile.toAbsolutePath() + "]", e);
            }
        } else {
            LOG.debug("Node ID file does not exist at [{}]. Creating.", nodeIdFile.toAbsolutePath());
            UUID newNodeId = UUID.randomUUID();
            try {
                Files.writeString(nodeIdFile, newNodeId.toString(), Charsets.UTF_8, StandardOpenOption.CREATE);
            } catch (IOException e) {
                throw new NodeInitializationException("Could not write node ID file at [" + nodeIdFile.toAbsolutePath() + "]", e);
            }
            localNodeId = newNodeId;
            LOG.info("Created node ID: [{}]", localNodeId);
        }
        // Check if a node with same name but different ID already exists. Not allowed.
        for (Node node : getNodes()) {
            if (node.uuid().equals(localNodeId)) {
                // Don't look at our own node if it's already registered.
                continue;
            }
            if (node.name().trim().equals(nzyme.getBaseConfiguration().name().trim())) {
                throw new NodeInitializationException("Node with same name already exists. Please choose another name.");
            }
        }
        // Increment cycle counter.
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("UPDATE nodes SET cycle = cycle+1 WHERE uuid = :node_id")
                        .bind("node_id", localNodeId)
                        .execute()
        );
        // Get current cycle.
        localCycle = getCycleOfNode(localNodeId);
        Executors.newSingleThreadScheduledExecutor(
                new ThreadFactoryBuilder()
                        .setNameFormat("node-metrics-updater-%d")
                        .setDaemon(true)
                        .build()
        ).scheduleAtFixedRate(this::runMetrics, 0, 1, TimeUnit.MINUTES);
        LOG.info("Node ID: [{}]", localNodeId);
    }
    public void registerSelf() {
        if (localNodeId == null) {
            throw new RuntimeException("Not initialized. Cannot register myself.");
        }
        registerSelf(localNodeId);
    }
    // The custom UUID is for testing.
    public void registerSelf(UUID uuid) {
        NodeInformation.Info ni = new NodeInformation().collect();
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("INSERT INTO nodes(uuid, name, http_listen_uri, http_external_uri, version, " +
                                " last_seen, memory_bytes_total, memory_bytes_available, memory_bytes_used, " +
                                "heap_bytes_total, heap_bytes_available, heap_bytes_used, cpu_system_load, " +
                                "cpu_thread_count, process_start_time, process_virtual_size, process_arguments, " +
                                "os_information, clock, deleted) VALUES(:uuid, :name, :http_listen_uri, " +
                                ":http_external_uri, :version, NOW(), :memory_bytes_total, :memory_bytes_available, " +
                                ":memory_bytes_used, :heap_bytes_total, :heap_bytes_available, " +
                                ":heap_bytes_used, :cpu_system_load, :cpu_thread_count, :process_start_time, " +
                                ":process_virtual_size, :process_arguments, :os_information, :clock, false) " +
                                "ON CONFLICT(uuid) DO UPDATE SET name = :name, http_external_uri = :http_external_uri, " +
                                "http_listen_uri = :http_listen_uri, version = :version, last_seen = NOW()," +
                                "memory_bytes_total = :memory_bytes_total, " +
                                "memory_bytes_available = :memory_bytes_available, memory_bytes_used = :memory_bytes_used, " +
                                "heap_bytes_total = :heap_bytes_total, heap_bytes_available = :heap_bytes_available, " +
                                "heap_bytes_used = :heap_bytes_used, cpu_system_load = :cpu_system_load, " +
                                "cpu_thread_count = :cpu_thread_count, process_start_time = :process_start_time, " +
                                "process_virtual_size = :process_virtual_size, process_arguments = :process_arguments, " +
                                "os_information = :os_information, clock = :clock, deleted = false")
                        .bind("uuid", uuid)
                        .bind("name", nzyme.getNodeInformation().name())
                        .bind("http_listen_uri", nzyme.getConfiguration().restListenUri().toString())
                        .bind("http_external_uri", nzyme.getConfiguration().httpExternalUri().toString())
                        .bind("version", nzyme.getVersion().getVersion().toString())
                        .bind("memory_bytes_total", ni.memoryTotal())
                        .bind("memory_bytes_available", ni.memoryAvailable())
                        .bind("memory_bytes_used", ni.memoryUsed())
                        .bind("heap_bytes_total", ni.heapTotal())
                        .bind("heap_bytes_available", ni.heapAvailable())
                        .bind("heap_bytes_used", ni.heapUsed())
                        .bind("cpu_system_load", ni.cpuSystemLoad())
                        .bind("cpu_thread_count", ni.cpuThreadCount())
                        .bind("process_start_time", ni.processStartTime())
                        .bind("process_virtual_size", ni.processVirtualSize())
                        .bind("process_arguments", ni.processArguments())
                        .bind("os_information", ni.osInformation())
                        .bind("clock", DateTime.now())
                        .execute()
        );
    }
    public List<Node> getNodes() {
        List<NodeEntry> dbEntries = nzyme.getDatabase().withHandle(handle ->
                handle.createQuery("SELECT * FROM nodes WHERE last_seen > :timeout ORDER BY name DESC")
                        .bind("timeout", DateTime.now().minusHours(24))
                        .mapTo(NodeEntry.class)
                        .list()
        );
        List<Node> nodes = Lists.newArrayList();
        for (NodeEntry dbEntry : dbEntries) {
            try {
                URI listenUri = URI.create(dbEntry.httpListenUri());
                URI httpExternalUri = URI.create(dbEntry.httpExternalUri());
                nodes.add(Node.create(
                        dbEntry.uuid(),
                        dbEntry.name(),
                        listenUri,
                        httpExternalUri,
                        dbEntry.memoryBytesTotal(),
                        dbEntry.memoryBytesAvailable(),
                        dbEntry.memoryBytesUsed(),
                        dbEntry.heapBytesTotal(),
                        dbEntry.heapBytesAvailable(),
                        dbEntry.heapBytesUsed(),
                        dbEntry.cpuSystemLoad(),
                        dbEntry.cpuThreadCount(),
                        dbEntry.processStartTime(),
                        dbEntry.processVirtualSize(),
                        dbEntry.processArguments(),
                        dbEntry.osInformation(),
                        dbEntry.version(),
                        dbEntry.lastSeen(),
                        dbEntry.clock(),
                        (long) new Period(dbEntry.lastSeen(), dbEntry.clock(), PeriodType.millis()).getMillis(),
                        isNodeEphemeral(dbEntry),
                        dbEntry.deleted(),
                        dbEntry.cycle()
                ));
            } catch (Exception e) {
                LOG.error("Could not create node from database entry. Skipping.", e);
            }
        }
        return nodes;
    }
    public Optional<Node> getNode(UUID nodeId) {
        Optional<NodeEntry> result = nzyme.getDatabase().withHandle(handle ->
                handle.createQuery("SELECT * FROM nodes WHERE uuid = :uuid")
                        .bind("uuid", nodeId)
                        .mapTo(NodeEntry.class)
                        .findFirst()
        );
        if (result.isPresent()) {
            NodeEntry ne = result.get();
            try {
                URI httpListenUri = URI.create(ne.httpListenUri());
                URI httpExternalUri = URI.create(ne.httpExternalUri());
                return Optional.of(Node.create(
                        ne.uuid(),
                        ne.name(),
                        httpListenUri,
                        httpExternalUri,
                        ne.memoryBytesTotal(),
                        ne.memoryBytesAvailable(),
                        ne.memoryBytesUsed(),
                        ne.heapBytesTotal(),
                        ne.heapBytesAvailable(),
                        ne.heapBytesUsed(),
                        ne.cpuSystemLoad(),
                        ne.cpuThreadCount(),
                        ne.processStartTime(),
                        ne.processVirtualSize(),
                        ne.processArguments(),
                        ne.osInformation(),
                        ne.version(),
                        ne.lastSeen(),
                        ne.clock(),
                        (long) new Period(ne.lastSeen(), ne.clock(), PeriodType.millis()).getMillis(),
                        isNodeEphemeral(ne),
                        ne.deleted(),
                        ne.cycle()
                ));
            } catch (Exception e) {
                throw new RuntimeException("Could not create node from database entry.", e);
            }
        } else {
            return Optional.empty();
        }
    }
    public void deleteNode(UUID nodeId) {
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("UPDATE nodes SET deleted = true WHERE uuid = :node_id")
                        .bind("node_id", nodeId)
                        .execute()
        );
    }
    private void runMetrics() {
        try {
            MetricRegistry metrics = nzyme.getMetrics();
            long tapReportSize = this.tapReportSize.getAndSet(0);
            NodeInformation.Info ni = new NodeInformation().collect();
            Map<String, Long> logCounts = CountingAppender.getCounts();
            writeGauge(MetricExternalName.MEMORY_BYTES_TOTAL.database_label, ni.memoryTotal());
            writeGauge(MetricExternalName.MEMORY_BYTES_AVAILABLE.database_label, ni.memoryAvailable());
            writeGauge(MetricExternalName.MEMORY_BYTES_USED.database_label, ni.memoryUsed());
            writeGauge(MetricExternalName.HEAP_BYTES_TOTAL.database_label, ni.heapTotal());
            writeGauge(MetricExternalName.HEAP_BYTES_AVAILABLE.database_label, ni.heapAvailable());
            writeGauge(MetricExternalName.HEAP_BYTES_USED.database_label, ni.heapUsed());
            writeGauge(MetricExternalName.CPU_SYSTEM_LOAD.database_label, ni.cpuSystemLoad());
            writeGauge(MetricExternalName.PROCESS_VIRTUAL_SIZE.database_label, ni.processVirtualSize());
            writeGauge(MetricExternalName.TAP_REPORT_SIZE.database_label, tapReportSize);
            writeGauge(MetricExternalName.LOG_COUNTS_TRACE.database_label, logCounts.getOrDefault("TRACE", 0L));
            writeGauge(MetricExternalName.LOG_COUNTS_DEBUG.database_label, logCounts.getOrDefault("DEBUG", 0L));
            writeGauge(MetricExternalName.LOG_COUNTS_INFO.database_label, logCounts.getOrDefault("INFO", 0L));
            writeGauge(MetricExternalName.LOG_COUNTS_WARN.database_label, logCounts.getOrDefault("WARN", 0L));
            writeGauge(MetricExternalName.LOG_COUNTS_ERROR.database_label, logCounts.getOrDefault("ERROR", 0L));
            writeGauge(MetricExternalName.LOG_COUNTS_FATAL.database_label, logCounts.getOrDefault("FATAL", 0L));
            writeGauge(MetricExternalName.GEOIP_CACHE_SIZE.database_label, getLocalMetricsGaugeValue(metrics, MetricNames.GEOIP_CACHE_SIZE));
            writeGauge(MetricExternalName.CONTEXT_MAC_CACHE_SIZE.database_label, getLocalMetricsGaugeValue(metrics, MetricNames.CONTEXT_MAC_CACHE_SIZE));
            writeTimer(MetricExternalName.PGP_ENCRYPTION_TIMER.database_label,
                    metrics.getTimers().get(MetricNames.PGP_ENCRYPTION_TIMING));
            writeTimer(MetricExternalName.PGP_DECRYPTION_TIMER.database_label,
                    metrics.getTimers().get(MetricNames.PGP_DECRYPTION_TIMING));
            writeTimer(MetricExternalName.PASSWORD_HASHING_TIMER.database_label,
                    metrics.getTimers().get(MetricNames.PASSWORD_HASHING_TIMER));
            writeTimer(MetricExternalName.CONTEXT_MAC_LOOKUP_TIMER.database_label,
                    metrics.getTimers().get(MetricNames.CONTEXT_MAC_LOOKUP_TIMING));
            writeTimer(MetricExternalName.REPORT_PROCESSING_DOT11_TIMER.database_label,
                    metrics.getTimers().get(MetricNames.DOT11_TOTAL_REPORT_PROCESSING_TIMER));
            writeTimer(MetricExternalName.REPORT_PROCESSING_TCP_TIMER.database_label,
                    metrics.getTimers().get(MetricNames.TCP_TOTAL_REPORT_PROCESSING_TIMER));
            writeTimer(MetricExternalName.REPORT_PROCESSING_DNS_TIMER.database_label,
                    metrics.getTimers().get(MetricNames.DNS_TOTAL_REPORT_PROCESSING_TIMER));
            writeTimer(MetricExternalName.REPORT_PROCESSING_SSH_TIMER.database_label,
                    metrics.getTimers().get(MetricNames.SSH_TOTAL_REPORT_PROCESSING_TIMER));
            writeTimer(MetricExternalName.REPORT_PROCESSING_SOCKS_TIMER.database_label,
                    metrics.getTimers().get(MetricNames.SOCKS_TOTAL_REPORT_PROCESSING_TIMER));
        } catch(Exception e) {
            LOG.error("Could not write node metrics.", e);
        } finally {
            CountingAppender.resetCounts();
        }
        // Retention clean old metrics.
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("DELETE FROM node_metrics_gauges WHERE created_at < :created_at")
                        .bind("created_at", DateTime.now().minusHours(24))
                        .execute());
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("DELETE FROM node_metrics_timers WHERE created_at < :created_at")
                        .bind("created_at", DateTime.now().minusHours(24))
                        .execute());
    }
    private double getLocalMetricsGaugeValue(MetricRegistry metrics, String metricName) {
        Gauge gauge = metrics.getGauges().get(metricName);
        /*
         * The gauge *should* always exist because it's tied to a metric name that we defined, but this may
         * be called before the gauge is initialized.
         */
        if (gauge == null) {
            return 0;
        }
        Object value = gauge.getValue();
        if (value == null) {
            return 0;
        }
        if (value instanceof Long) {
            return ((Long) value).doubleValue();
        } else if (value instanceof Double) {
            return (double) value;
        } else {
            LOG.error("Unknown value type [{}] in gauge [{}]",
                    value.getClass().getCanonicalName(), metricName);
            return 0;
        }
    }
    private void writeGauge(String metricName, double metricValue) {
        nzyme.getDatabase().withHandle(handle -> handle.createUpdate("INSERT INTO node_metrics_gauges(node_id, " +
                        "metric_name, metric_value, created_at) VALUES(:node_id, :metric_name, :metric_value, " +
                        ":created_at)")
                .bind("node_id", nzyme.getNodeInformation().id())
                .bind("metric_name", metricName)
                .bind("metric_value", metricValue)
                .bind("created_at", DateTime.now())
                .execute()
        );
    }
    private void writeTimer(String metricName, @Nullable Timer timer) {
        if (timer == null) {
            return;
        }
        Snapshot s = timer.getSnapshot();
        writeTimer(
                metricName,
                TimeUnit.MICROSECONDS.convert(s.getMax(), TimeUnit.NANOSECONDS),
                TimeUnit.MICROSECONDS.convert(s.getMin(), TimeUnit.NANOSECONDS),
                TimeUnit.MICROSECONDS.convert((long) s.getMean(), TimeUnit.NANOSECONDS),
                TimeUnit.MICROSECONDS.convert((long) s.get99thPercentile(), TimeUnit.NANOSECONDS),
                TimeUnit.MICROSECONDS.convert((long) s.getStdDev(), TimeUnit.NANOSECONDS),
                timer.getCount()
        );
    }
    private void writeTimer(String metricName, long max, long min, long mean, long p99, long stddev, long counter) {
        nzyme.getDatabase().withHandle(handle -> handle.createUpdate("INSERT INTO node_metrics_timers(node_id, " +
                        "metric_name, metric_max, metric_min, metric_mean, metric_p99, metric_stddev, metric_counter, " +
                        "created_at) VALUES(:node_id, :metric_name, :metric_max, :metric_min, :metric_mean, " +
                        ":metric_p99, :metric_stddev, :metric_counter, :created_at)")
                .bind("node_id", nzyme.getNodeInformation().id())
                .bind("metric_name", metricName)
                .bind("metric_max", max)
                .bind("metric_min", min)
                .bind("metric_mean", mean)
                .bind("metric_p99", p99)
                .bind("metric_stddev", stddev)
                .bind("metric_counter", counter)
                .bind("created_at", DateTime.now())
                .execute()
        );
    }
    public Optional<Map<DateTime, GaugeHistogramBucket>> findMetricsHistogram(UUID nodeId, String metricName, int hours, BucketSize bucketSize) {
        Map<DateTime, GaugeHistogramBucket> result = Maps.newHashMap();
        List<GaugeHistogramBucket> agg = nzyme.getDatabase().withHandle(handle ->
                handle.createQuery("SELECT AVG(metric_value) AS average, MAX(metric_value) AS maximum, " +
                                "MIN(metric_value) AS minimum, SUM(metric_value) AS sum, " +
                                "date_trunc(:bucket_size, created_at) AS bucket " +
                                "FROM node_metrics_gauges WHERE node_id = :node_id AND metric_name = :metric_name " +
                                "AND created_at > :created_at GROUP BY bucket ORDER BY bucket DESC")
                        .bind("bucket_size", bucketSize.toString().toLowerCase())
                        .bind("node_id", nodeId)
                        .bind("metric_name", metricName)
                        .bind("created_at", DateTime.now().minusHours(hours))
                        .mapTo(GaugeHistogramBucket.class)
                        .list()
        );
        if (agg == null || agg.isEmpty()) {
            return Optional.empty();
        }
        for (GaugeHistogramBucket x : agg) {
            result.put(x.bucket(), x);
        }
        return Optional.of(result);
    }
    public Optional<TimerEntry> findLatestActiveMetricsTimerValue(UUID nodeId,
                                                                  String metricName,
                                                                  Handle handle) {
        return handle.createQuery("SELECT * FROM node_metrics_timers " +
                        "WHERE node_id = :node_id AND metric_name = :metric_name AND created_at > :created_at " +
                        "ORDER BY created_at DESC " +
                        "LIMIT 1")
                .bind("node_id", nodeId)
                .bind("metric_name", metricName)
                .bind("created_at", DateTime.now().minusMinutes(2))
                .mapTo(TimerEntry.class)
                .findOne();
    }
    public Optional<Double> findLatestActiveMetricsGaugeValue(UUID nodeId,
                                                            String metricName,
                                                            Handle handle) {
        return handle.createQuery("SELECT metric_value FROM node_metrics_gauges " +
                        "WHERE node_id = :node_id AND metric_name = :metric_name " +
                        "AND created_at > :created_at " +
                        "ORDER BY created_at DESC " +
                        "LIMIT 1")
                .bind("node_id", nodeId)
                .bind("metric_name", metricName)
                .bind("created_at", DateTime.now().minusMinutes(2))
                .mapTo(Double.class)
                .findOne();
    }
    private boolean isNodeEphemeral(NodeEntry node) {
        return nzyme.getDatabaseCoreRegistry()
                .getValue(NodeRegistryKeys.EPHEMERAL_NODES_REGEX.key())
                .filter(r -> node.name().matches(r))
                .isPresent();
    }
    public UUID getLocalNodeId() {
        return localNodeId;
    }
    public void recordTapReportSize(long size) {
        this.tapReportSize.addAndGet(size);
    }
    public String findNameOfNode(UUID nodeId) {
        try {
            return nodeNameCache.get(nodeId);
        } catch (ExecutionException e) {
            throw new RuntimeException(e);
        }
    }
    public long getCycleOfNode(UUID nodeId) {
        return nzyme.getDatabase().withHandle(handle ->
                handle.createQuery("SELECT cycle FROM nodes WHERE uuid = :node_id")
                        .bind("node_id", nodeId)
                        .mapTo(Long.class)
                        .findOne()
        ).orElse(1L); // 1 if this is a brand-new node that hasn't registered yet. (happens in init once)
    }
    public long getLocalCycle() {
        return localCycle;
    }
    public void setLocalPGPPublicKey(PGPKeys keys) {
        String key = BaseEncoding.base64().encode(keys.publicKey());
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("UPDATE nodes SET public_key = :key WHERE uuid = :node_id")
                        .bind("key", key)
                        .bind("node_id", localNodeId)
                        .execute()
        );
    }
    public byte[] getPGPPublicKeyOfNode(UUID nodeId) {
        String b64 = nzyme.getDatabase().withHandle(handle ->
                handle.createQuery("SELECT public_key FROM nodes WHERE uuid = :node_id")
                        .bind("node_id", nodeId)
                        .mapTo(String.class)
                        .one()
        );
        return BaseEncoding.base64().decode(b64);
    }
    public static final class NodeInitializationException extends Throwable {
        public NodeInitializationException(String msg) {
            super(msg);
        }
        public NodeInitializationException(String msg, Throwable e) {
            super(msg, e);
        }
    }
}
package app.nzyme.core.ouis;
import app.nzyme.core.NzymeNode;
import app.nzyme.core.connect.ConnectRegistryKeys;
import app.nzyme.core.util.MetricNames;
import com.codahale.metrics.MetricRegistry;
import com.codahale.metrics.Timer;
import com.fasterxml.jackson.databind.DeserializationFeature;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.google.common.net.HttpHeaders;
import com.google.common.util.concurrent.ThreadFactoryBuilder;
import okhttp3.HttpUrl;
import okhttp3.OkHttpClient;
import okhttp3.Request;
import okhttp3.Response;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import java.util.Map;
import java.util.Optional;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.ReentrantLock;
public class OuiService {
    private static final Logger LOG = LogManager.getLogger(OuiService.class);
    private final NzymeNode nzyme;
    private final Timer lookupTimer;
    private final ScheduledExecutorService refresher;
    private final ReentrantLock lock = new ReentrantLock();
    private Map<String, String> ouis;
    // Can be disabled if Connect is not set up or OUI data source is not enabled in Connect.
    private boolean isEnabled = false;
    public OuiService(NzymeNode nzyme) {
        this.nzyme = nzyme;
        this.lookupTimer = nzyme.getMetrics().timer(MetricRegistry.name(MetricNames.OUI_LOOKUP_TIMING));
        // Reload on configuration change.
        nzyme.getRegistryChangeMonitor()
                .onChange("core", ConnectRegistryKeys.CONNECT_API_KEY.key(), this::reload);
        nzyme.getRegistryChangeMonitor()
                .onChange("core", ConnectRegistryKeys.CONNECT_ENABLED.key(), this::reload);
        // Reload if provided services by Connect change.
        nzyme.getRegistryChangeMonitor()
                .onChange("core", ConnectRegistryKeys.PROVIDED_SERVICES.key(), this::reload);
        refresher = Executors.newSingleThreadScheduledExecutor(
                new ThreadFactoryBuilder()
                        .setDaemon(true)
                        .setNameFormat("oui-refresher-%d")
                        .build()
        );
        refresher.scheduleAtFixedRate(this::reload, 1, 1, TimeUnit.HOURS);
    }
    private void reload() {
        // Reload with new registry settings.
        initialize();
    }
    public void initialize() {
        // IMPORTANT: This method will also be called on configuration changes.
        this.isEnabled = nzyme.getConnect().isEnabled();
        if (!this.isEnabled) {
            return;
        }
        lock.lock();
        try {
            Optional<Map<String, String>> data = fetchOuisFromConnect();
            // Check if OUI data was disabled in Connect for this cluster.
            if (data.isEmpty()) {
                this.isEnabled = false;
                return;
            }
            this.ouis = data.get();
            this.isEnabled = true;
        } catch (Exception e) {
            LOG.error("Could not download OUI data from Connect.", e);
            this.isEnabled = false;
        } finally {
            lock.unlock();
        }
    }
    public Optional<String> lookup(String mac) {
        if (!isEnabled || mac == null || mac.trim().isEmpty()) {
            return Optional.empty();
        }
        if (mac.length() != 17) {
            LOG.warn("Passed invalid MAC address [{}]", mac);
            return Optional.empty();
        }
        try(Timer.Context ignored = lookupTimer.time()) {
            lock.lock();
            try {
                String oui = ouis.get(mac.toUpperCase().substring(0, 8).replace(":", ""));
                return oui == null ? Optional.empty() : Optional.of(oui);
            } finally {
                lock.unlock();
            }
        }
    }
    private Optional<Map<String, String>> fetchOuisFromConnect() {
        LOG.debug("Loading new OUIs from Connect.");
        try {
            OkHttpClient c = new OkHttpClient.Builder()
                    .connectTimeout(60, TimeUnit.SECONDS)
                    .writeTimeout(15, TimeUnit.SECONDS)
                    .readTimeout(5, TimeUnit.MINUTES)
                    .followRedirects(true)
                    .build();
            HttpUrl url = HttpUrl.get(nzyme.getConnect().getApiUri())
                    .newBuilder()
                    .addPathSegment("data")
                    .addPathSegment("oui")
                    .addPathSegment("all")
                    .build();
            Response response = c.newCall(new Request.Builder()
                    .addHeader("User-Agent", "nzyme")
                    .get()
                    .url(url)
                    .addHeader(HttpHeaders.AUTHORIZATION, "Bearer " + nzyme.getConnect().getApiKey())
                    .addHeader("Content-Type", "application/json")
                    .addHeader(HttpHeaders.USER_AGENT, "nzyme-node")
                    .build()
            ).execute();
            try (response) {
                if (!response.isSuccessful()) {
                    if (response.code() == 403) {
                        // OUI data disabled in Connect for this cluster.
                        return Optional.empty();
                    }
                    throw new RuntimeException("Expected HTTP 200 or 403 but got HTTP " + response.code());
                }
                if (response.body() == null) {
                    throw new RuntimeException("Empty response.");
                }
                LOG.info("OUI data download from Connect complete.");
                ObjectMapper om = new ObjectMapper();
                om.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
                om.configure(DeserializationFeature.FAIL_ON_IGNORED_PROPERTIES, false);
                ConnectOuiResponse data = om.readValue(response.body().bytes(), ConnectOuiResponse.class);
                return Optional.of(data.ouis());
            }
        } catch (Exception e) {
            LOG.error("Could not download OUI data from Connect.", e);
            return Optional.empty();
        }
    }
}
package app.nzyme.core.context;
import app.nzyme.core.NzymeNode;
import app.nzyme.core.context.db.MacAddressContextEntry;
import app.nzyme.core.context.db.MacAddressTransparentContextEntry;
import app.nzyme.core.util.MetricNames;
import com.codahale.metrics.Gauge;
import com.codahale.metrics.Timer;
import com.google.common.cache.CacheBuilder;
import com.google.common.cache.CacheLoader;
import com.google.common.cache.LoadingCache;
import jakarta.annotation.Nullable;
import org.jdbi.v3.core.Handle;
import org.jetbrains.annotations.NotNull;
import org.joda.time.DateTime;
import java.net.InetAddress;
import java.util.List;
import java.util.Optional;
import java.util.UUID;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.TimeUnit;
public class ContextService {
    public enum TransparentDataType {
        IP_ADDRESS,
        HOSTNAME
    }
    private final NzymeNode nzyme;
    private final Timer macLookupTimer;
    private final LoadingCache<MacAddressContextCacheKey, Optional<MacAddressContextEntry>> macAddressContextCache;
    public ContextService(NzymeNode nzyme) {
        this.nzyme = nzyme;
        this.macAddressContextCache = CacheBuilder.newBuilder()
                .maximumSize(2500)
                .expireAfterWrite(10, TimeUnit.MINUTES)
                .build(new CacheLoader<>() {
                    @NotNull
                    @Override
                    public Optional<MacAddressContextEntry> load(@NotNull MacAddressContextCacheKey key) {
                        return findMacAddressContextNoCache(key.macAddress(), key.organizationId(), key.tenantId());
                    }
                });
        nzyme.getMetrics().register(MetricNames.CONTEXT_MAC_CACHE_SIZE, new Gauge<Long>() {
            @Override
            public Long getValue() {
                return macAddressContextCache.size();
            }
        });
        this.macLookupTimer = nzyme.getMetrics().timer(MetricNames.CONTEXT_MAC_LOOKUP_TIMING);
    }
    public void invalidateMacAddressCache() {
        macAddressContextCache.invalidateAll();
    }
    public long createMacAddressContext(String macAddress,
                                        String name,
                                        @Nullable String description,
                                        @Nullable String notes,
                                        UUID organizationId,
                                        UUID tenantId) {
        return nzyme.getDatabase().withHandle(handle ->
            handle.createQuery("INSERT INTO context_mac_addresses(mac_address, uuid, name, description, " +
                            "notes, organization_id, tenant_id, created_at, updated_at) VALUES(:mac_address, " +
                            ":uuid, :name, :description, :notes, :organization_id, :tenant_id, NOW(), NOW()) " +
                            "RETURNING id")
                    .bind("mac_address", macAddress.toUpperCase())
                    .bind("uuid", UUID.randomUUID())
                    .bind("name", name)
                    .bind("description", description)
                    .bind("notes", notes)
                    .bind("organization_id", organizationId)
                    .bind("tenant_id", tenantId)
                    .mapTo(Long.class)
                    .one()
        );
    }
    public List<MacAddressContextEntry> findAllMacAddressContext(UUID organizationId,
                                                                 UUID tenantId,
                                                                 String addressFilter,
                                                                 int limit,
                                                                 int offset) {
        return nzyme.getDatabase().withHandle(handle ->
                handle.createQuery("SELECT * FROM context_mac_addresses " +
                                "WHERE organization_id = :organization_id AND tenant_id = :tenant_id " +
                                "AND mac_address LIKE :address_filter " +
                                "ORDER BY mac_address ASC LIMIT :limit OFFSET :offset")
                        .bind("organization_id", organizationId)
                        .bind("tenant_id", tenantId)
                        .bind("address_filter", addressFilter)
                        .bind("limit", limit)
                        .bind("offset", offset)
                        .mapTo(MacAddressContextEntry.class)
                        .list()
        );
    }
    public Optional<MacAddressContextEntry> findMacAddressContext(String mac,
                                                                  @Nullable UUID organizationId,
                                                                  @Nullable UUID tenantId) {
        try {
            return macAddressContextCache.get(MacAddressContextCacheKey.create(mac, organizationId, tenantId));
        } catch(ExecutionException e) {
            throw new RuntimeException("Could not MAC address context from cache.", e);
        }
    }
    public Optional<MacAddressContextEntry> findMacAddressContextNoCache(String mac,
                                                                          @Nullable UUID organizationId,
                                                                          @Nullable UUID tenantId) {
        try(Timer.Context ignored = macLookupTimer.time()) {
            if (organizationId != null && tenantId != null) {
                // Tenant data.
                return nzyme.getDatabase().withHandle(handle ->
                        handle.createQuery("SELECT * FROM context_mac_addresses " +
                                        "WHERE organization_id = :organization_id AND tenant_id = :tenant_id " +
                                        "AND mac_address = :mac_address")
                                .bind("organization_id", organizationId)
                                .bind("tenant_id", tenantId)
                                .bind("mac_address", mac)
                                .mapTo(MacAddressContextEntry.class)
                                .findOne()
                );
            }
            if (organizationId != null) {
                // Organization data.
                return nzyme.getDatabase().withHandle(handle ->
                        handle.createQuery("SELECT * FROM context_mac_addresses " +
                                        "WHERE organization_id = :organization_id " +
                                        "AND mac_address = :mac_address")
                                .bind("organization_id", organizationId)
                                .bind("mac_address", mac)
                                .mapTo(MacAddressContextEntry.class)
                                .findOne()
                );
            }
            // Any data.
            return nzyme.getDatabase().withHandle(handle ->
                    handle.createQuery("SELECT * FROM context_mac_addresses " +
                                    "WHERE mac_address = :mac_address")
                            .bind("mac_address", mac)
                            .mapTo(MacAddressContextEntry.class)
                            .findOne()
            );
        }
    }
    public Optional<MacAddressContextEntry> findMacAddressContext(UUID uuid, UUID organizationId, UUID tenantId) {
        return nzyme.getDatabase().withHandle(handle ->
                handle.createQuery("SELECT * FROM context_mac_addresses " +
                                "WHERE organization_id = :organization_id AND tenant_id = :tenant_id " +
                                "AND uuid = :uuid")
                        .bind("organization_id", organizationId)
                        .bind("tenant_id", tenantId)
                        .bind("uuid", uuid)
                        .mapTo(MacAddressContextEntry.class)
                        .findOne()
        );
    }
    public Long countMacAddressContext(UUID organizationId, UUID tenantId) {
        return nzyme.getDatabase().withHandle(handle ->
                handle.createQuery("SELECT COUNT(*) FROM context_mac_addresses " +
                                "WHERE organization_id = :organization_id AND tenant_id = :tenant_id")
                        .bind("organization_id", organizationId)
                        .bind("tenant_id", tenantId)
                        .mapTo(Long.class)
                        .one()
        );
    }
    public void updateMacAddressContext(UUID uuid,
                                        UUID organizationId,
                                        UUID tenantId,
                                        String name,
                                        String description,
                                        String notes) {
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("UPDATE context_mac_addresses SET name = :name, description = :description, " +
                                "notes = :notes, updated_at = NOW() WHERE uuid = :uuid " +
                                "AND organization_id = :organization_id AND tenant_id = :tenant_id")
                        .bind("name", name)
                        .bind("description", description)
                        .bind("notes", notes)
                        .bind("uuid", uuid)
                        .bind("organization_id", organizationId)
                        .bind("tenant_id", tenantId)
                        .execute()
        );
    }
    public void deleteMacAddressContext(UUID uuid, UUID organizationId, UUID tenantId) {
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("DELETE FROM context_mac_addresses " +
                                "WHERE organization_id = :organization_id AND tenant_id = :tenant_id " +
                                "AND uuid = :uuid")
                        .bind("organization_id", organizationId)
                        .bind("tenant_id", tenantId)
                        .bind("uuid", uuid)
                        .execute()
        );
    }
    public List<MacAddressTransparentContextEntry> findTransparentMacAddressContext(long contextId) {
        return nzyme.getDatabase().withHandle(handle ->
                findTransparentMacAddressContext(handle, contextId)
        );
    }
    public List<MacAddressTransparentContextEntry> findTransparentMacAddressContext(Handle handle, long contextId) {
        return handle.createQuery("SELECT * FROM context_mac_addresses_transparent " +
                        "WHERE context_id = :context_id ORDER BY last_seen DESC")
                .bind("context_id", contextId)
                .mapTo(MacAddressTransparentContextEntry.class)
                .list();
    }
    public void registerTransparentMacAddressHostname(Handle handle,
                                                      long contextId,
                                                      UUID tapId,
                                                      String source,
                                                      String hostname,
                                                      DateTime lastSeen) {
        handle.createUpdate("INSERT INTO context_mac_addresses_transparent(context_id, tap_uuid, " +
                        "type, hostname, source, last_seen, created_at) VALUES(:context_id, :tap_uuid, :type, " +
                        ":hostname, :source, :last_seen, :last_seen)")
                .bind("context_id", contextId)
                .bind("tap_uuid", tapId)
                .bind("type", TransparentDataType.HOSTNAME)
                .bind("hostname", hostname)
                .bind("source", source)
                .bind("last_seen", lastSeen)
                .execute();
    }
    public void registerTransparentMacAddressIpAddress(Handle handle,
                                                       long contextId,
                                                       UUID tapId,
                                                       String source,
                                                       InetAddress ipAddress,
                                                       DateTime lastSeen) {
        handle.createUpdate("INSERT INTO context_mac_addresses_transparent(context_id, tap_uuid, " +
                        "type, ip_address, source, last_seen, created_at) VALUES(:context_id, :tap_uuid, :type, " +
                        ":ip_address::inet, :source, :last_seen, :last_seen)")
                .bind("context_id", contextId)
                .bind("tap_uuid", tapId)
                .bind("type", TransparentDataType.IP_ADDRESS)
                .bind("ip_address", ipAddress)
                .bind("source", source)
                .bind("last_seen", lastSeen)
                .execute();
    }
    public void touchTransparentMacAddressIpAddress(Handle handle,
                                                    long contextId,
                                                    UUID tapId,
                                                    String source,
                                                    InetAddress ipAddress,
                                                    DateTime lastSeen) {
        handle.createUpdate("UPDATE context_mac_addresses_transparent SET last_seen = :last_seen " +
                        "WHERE context_id = :context_id AND tap_uuid = :tap_uuid AND type = :type " +
                        "AND ip_address = :ip_address AND source = :source")
                .bind("context_id", contextId)
                .bind("tap_uuid", tapId)
                .bind("type", TransparentDataType.IP_ADDRESS)
                .bind("ip_address", ipAddress)
                .bind("source", source)
                .bind("last_seen", lastSeen)
                .execute();
    }
    public void touchTransparentMacAddressHostname(Handle handle,
                                                   long contextId,
                                                   UUID tapId,
                                                   String source,
                                                   String hostname,
                                                   DateTime lastSeen) {
        handle.createUpdate("UPDATE context_mac_addresses_transparent SET last_seen = :last_seen " +
                        "WHERE context_id = :context_id AND tap_uuid = :tap_uuid AND type = :type " +
                        "AND hostname = :hostname AND source = :source")
                .bind("context_id", contextId)
                .bind("tap_uuid", tapId)
                .bind("type", TransparentDataType.HOSTNAME)
                .bind("hostname", hostname)
                .bind("source", source)
                .bind("last_seen", lastSeen)
                .execute();
    }
    public void retentionCleanTransparentMacContext(DateTime cutoff) {
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("DELETE FROM context_mac_addresses_transparent WHERE last_seen < :cutoff")
                        .bind("cutoff", cutoff)
                        .execute()
        );
    }
}
package app.nzyme.core.rest.interceptors;
import app.nzyme.core.NzymeNode;
import app.nzyme.core.util.MetricNames;
import jakarta.ws.rs.WebApplicationException;
import jakarta.ws.rs.core.Context;
import jakarta.ws.rs.core.UriInfo;
import jakarta.ws.rs.ext.ReaderInterceptor;
import jakarta.ws.rs.ext.ReaderInterceptorContext;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.IOException;
public class TapTableSizeInterceptor implements ReaderInterceptor {
    private static final Logger LOG = LogManager.getLogger(TapTableSizeInterceptor.class);
    @Context
    private UriInfo uriInfo;
    private NzymeNode nzyme;
    public TapTableSizeInterceptor(NzymeNode nzyme) {
        this.nzyme = nzyme;
    }
    @Override
    public Object aroundReadFrom(ReaderInterceptorContext context) throws IOException, WebApplicationException {
        if (uriInfo.getPath().contains("api/taps/tables")) {
            // We do not want to consume the InputStream because we need it later in the resource of course. Copy it.
            ByteArrayOutputStream cloner = new ByteArrayOutputStream();
            context.getInputStream().transferTo(cloner);
            int size = cloner.toByteArray().length;
            LOG.debug("Tap table report size: {}", size);
            nzyme.getMetrics().histogram(MetricNames.TAP_TABLE_REQUEST_SIZES).update(size);
            nzyme.getNodeManager().recordTapReportSize(size);
            // Stick another clone right back into the request context.
            context.setInputStream(new ByteArrayInputStream(cloner.toByteArray()));
        }
        return context.proceed();
    }
}

package app.nzyme.core.crypto;
import app.nzyme.core.crypto.database.TLSKeyAndCertificateEntry;
import app.nzyme.core.crypto.pgp.PGPKeyMessageBusReceiver;
import app.nzyme.core.crypto.pgp.PGPKeyProviderTaskHandler;
import app.nzyme.core.crypto.pgp.PGPKeys;
import app.nzyme.core.crypto.tls.*;
import app.nzyme.core.crypto.database.TLSWildcardKeyAndCertificateEntry;
import app.nzyme.core.distributed.Node;
import app.nzyme.plugin.Database;
import app.nzyme.plugin.distributed.messaging.MessageType;
import app.nzyme.plugin.distributed.tasksqueue.Task;
import app.nzyme.plugin.distributed.tasksqueue.TaskType;
import com.codahale.metrics.Timer;
import app.nzyme.core.NzymeNode;
import app.nzyme.core.util.MetricNames;
import com.google.common.collect.Lists;
import com.google.common.collect.Sets;
import com.google.common.io.BaseEncoding;
import com.google.common.io.Files;
import com.google.common.util.concurrent.ThreadFactoryBuilder;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.bouncycastle.asn1.ASN1ObjectIdentifier;
import org.bouncycastle.asn1.x500.X500Name;
import org.bouncycastle.asn1.x509.BasicConstraints;
import org.bouncycastle.bcpg.HashAlgorithmTags;
import org.bouncycastle.cert.CertIOException;
import org.bouncycastle.cert.jcajce.JcaX509CertificateConverter;
import org.bouncycastle.cert.jcajce.JcaX509v3CertificateBuilder;
import org.bouncycastle.jce.provider.BouncyCastleProvider;
import org.bouncycastle.openpgp.*;
import org.bouncycastle.openpgp.jcajce.JcaPGPObjectFactory;
import org.bouncycastle.openpgp.operator.PGPDigestCalculator;
import org.bouncycastle.openpgp.operator.jcajce.*;
import org.bouncycastle.operator.ContentSigner;
import org.bouncycastle.operator.OperatorCreationException;
import org.bouncycastle.operator.jcajce.JcaContentSignerBuilder;
import org.bouncycastle.util.io.Streams;
import org.joda.time.DateTime;
import java.io.*;
import java.math.BigInteger;
import java.nio.file.Paths;
import java.security.*;
import java.security.cert.*;
import java.security.cert.Certificate;
import java.security.spec.InvalidKeySpecException;
import java.util.*;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
/*
 * The readPublicKey and findPrivateKey methods are Copyright (c) 2000-2021 The Legion of the Bouncy Castle Inc.
 * (https://www.bouncycastle.org) and were copied under the terms of the MIT license:
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
 * documentation files (the "Software"), to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
 * and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 * The above copyright notice and this permission notice shall be included in all copies or substantial portions
 * of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
 * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 *
 * /////
 *
 * Certain other code in this file is derived from similar Bouncy Castle example code, originally published
 * under the same license.
 *
 * https://github.com/bcgit/bc-java/tree/master/pg/src/main/java/org/bouncycastle/openpgp/examples
 *
 */
public class Crypto {
    private static final Logger LOG = LogManager.getLogger(Crypto.class);
    private enum KeyType {
        PGP
    }
    public static final String DEFAULT_TLS_SUBJECT_DN = "CN=nzyme";
    public static final String PGP_PRIVATE_KEY_FILE_NAME = "pgp_private.pgp";
    public static final String PGP_PUBLIC_KEY_FILE_NAME = "pgp_public.pgp";
    public static final String TLS_CERTIFICATE_FILE_NAME = "tls.cert";
    public static final String TLS_KEY_FILE_NAME = "tls.key";
    private final File cryptoDirectoryConfig;
    private final Database database;
    private final String nodeName;
    private final UUID nodeId;
    private final Timer encryptionTimer;
    private final Timer decryptionTimer;
    private final NzymeNode nzyme;
    private final BouncyCastleProvider bcProvider;
    private PGPKeys nodeLocalPGPKeys = null;
    public Crypto(NzymeNode nzyme) {
        this.nzyme = nzyme;
        this.cryptoDirectoryConfig = new File(nzyme.getConfiguration().cryptoDirectory());
        this.database = nzyme.getDatabase();
        this.nodeName = nzyme.getNodeInformation().name();
        this.nodeId = nzyme.getNodeInformation().id();
        this.encryptionTimer = nzyme.getMetrics().timer(MetricNames.PGP_ENCRYPTION_TIMING);
        this.decryptionTimer = nzyme.getMetrics().timer(MetricNames.PGP_DECRYPTION_TIMING);
        this.bcProvider = new BouncyCastleProvider();
        Security.addProvider(this.bcProvider);
    }
    public void initialize() throws CryptoInitializationException {
        this.initialize(true);
    }
    public void initialize(boolean withRetentionCleaning) throws CryptoInitializationException {
        File privateKeyLocation = Paths.get(cryptoDirectoryConfig.toString(), PGP_PRIVATE_KEY_FILE_NAME).toFile();
        File publicKeyLocation = Paths.get(cryptoDirectoryConfig.toString(), PGP_PUBLIC_KEY_FILE_NAME).toFile();
        // Create node-local PGP key.
        try {
            nodeLocalPGPKeys = generatePGPKeys();
            nzyme.getNodeManager().setLocalPGPPublicKey(nodeLocalPGPKeys);
        } catch (PGPException | NoSuchProviderException | NoSuchAlgorithmException | IOException e) {
            throw new CryptoInitializationException("Could not generate node-local PGP key.", e);
        }
        if (!privateKeyLocation.exists() || !publicKeyLocation.exists()) {
            if (nzyme.getClusterManager().joinedExistingCluster()) {
                if (!isPGPKeySyncEnabled()) {
                    throw new CryptoInitializationException("Joining existing cluster but no PGP keys found and PGP key " +
                            "sync was disabled. Please transfer keys manually.");
                }
                LOG.info("PGP private or public key missing but not a new cluster. Requesting keys from other nodes...");
                // Register handler for received PGP keys.
                nzyme.getMessageBus().onMessageReceived(
                        MessageType.CLUSTER_PGP_KEYS_PROVIDED,
                        new PGPKeyMessageBusReceiver(cryptoDirectoryConfig, this)
                );
                // Request PGP keys.
                nzyme.getTasksQueue().publish(Task.create(
                        TaskType.PROVIDE_PGP_KEYS,
                        false,
                        Collections.emptyMap(),
                        true
                ));
                LOG.info("Keys requested.");
                // Spin until PGP keys have been written by the message bus handler. TODO
                while (true) {
                    if (privateKeyLocation.exists() && publicKeyLocation.exists()) {
                        LOG.info("PGP keys received. Continuing crypto initialization.");
                        break;
                    }
                    LOG.info("Waiting for keys...");
                    try {
                        Thread.sleep(5000);
                    } catch (InterruptedException ignored) {}
                }
            } else {
                // New cluster. Generate keys.
                LOG.warn("PGP private or public key missing and automatic fetching disabled. Re-generating pair. This will " +
                        "make existing encrypted registry values unreadable. Please consult the nzyme documentation.");
                try {
                    PGPKeys keys = generatePGPKeys();
                    Files.write(keys.privateKey(), privateKeyLocation);
                    Files.write(keys.publicKey(), publicKeyLocation);
                } catch (NoSuchAlgorithmException | NoSuchProviderException | PGPException e) {
                    throw new CryptoInitializationException("Unexpected crypto provider exception when trying " +
                            "to create key.", e);
                } catch (IOException e) {
                    throw new CryptoInitializationException("Could not write key file.", e);
                }
            }
        }
        // Load Keys. Build fingerprint.
        String keySignature;
        DateTime keyDate;
        try {
            PGPPublicKey pk = readPublicKey(publicKeyLocation);
            keySignature = String.format("%016X", pk.getKeyID());
            keyDate = new DateTime(pk.getCreationTime());
        } catch (IOException e) {
            throw new CryptoInitializationException("Could not read key file.", e);
        } catch (PGPException e) {
            throw new CryptoInitializationException("Unexpected crypto provider exception when trying " +
                    "to read existing key.", e);
        }
        // Does this node have keys in the database?
        List<String> signatures = database.withHandle(handle ->
                handle.createQuery("SELECT key_signature FROM crypto_keys " +
                        "WHERE node_id = :node_id AND key_type = :key_type")
                        .bind("node_id", nodeId)
                        .bind("key_type", KeyType.PGP)
                        .mapTo(String.class)
                        .list()
        );
        if (signatures.size() == 1) {
            /*
             * This node already has a key in the database. Check if it's another key than the one on disk.
             * If so, someone re-generated it, and we have to update it. If it's the same key, we can leave it
             * alone because nothing changed.
             */
            if (!signatures.contains(keySignature)) {
                database.useHandle(handle ->
                        handle.createUpdate("UPDATE crypto_keys SET key_signature = :key_signature, " +
                                        "created_at = :created_at WHERE key_type = :key_type AND node_id = :node_id")
                                .bind("node_id", nodeId)
                                .bind("key_type", KeyType.PGP)
                                .bind("key_signature", keySignature)
                                .bind("created_at", keyDate)
                                .execute()
                );
            }
        } else if(signatures.size() == 0) {
            database.useHandle(handle ->
                    handle.createUpdate("INSERT INTO crypto_keys(node_id, node_name, key_type, key_signature, created_at) " +
                                    "VALUES(:node_id, :node_name, :key_type, :key_signature, :created_at)")
                            .bind("node_id", nodeId)
                            .bind("node_name", nodeName)
                            .bind("key_type", KeyType.PGP)
                            .bind("key_signature", keySignature)
                            .bind("created_at", keyDate)
                            .execute()
            );
        } else {
            throw new CryptoInitializationException("Unexpected number of PGP keys for this node in database. Cannot continue.");
        }
        // Register taks handler to send PGP keys to other nodes.
        nzyme.getTasksQueue().onMessageReceived(TaskType.PROVIDE_PGP_KEYS,
                new PGPKeyProviderTaskHandler(
                        cryptoDirectoryConfig,
                        nzyme.getMessageBus(),
                        nzyme.getNodeManager(),
                        nzyme.getCrypto()
                )
        );
        // Generate TLS certificate and key if none exist.
        if (findTLSKeyAndCertificateOfNode(nodeId).isEmpty()) {
            try {
                LOG.info("No TLS certificate found. Generating self-signed certificate.");
                TLSKeyAndCertificate tls = generateTLSCertificate(DEFAULT_TLS_SUBJECT_DN, 12);
                setTLSKeyAndCertificateOfNode(nodeId, tls);
            } catch (CryptoOperationException e) {
                throw new CryptoInitializationException("Could not generate TLS certificate.", e);
            }
        }
        if (withRetentionCleaning) {
            Executors.newSingleThreadScheduledExecutor(
                    new ThreadFactoryBuilder()
                            .setNameFormat("crypto-retentionclean-%d")
                            .setDaemon(true)
                            .build()
            ).scheduleAtFixedRate(this::retentionCleanKeys, 0, 1, TimeUnit.MINUTES);
        }
    }
    private PGPKeys generatePGPKeys() throws PGPException, IOException, NoSuchAlgorithmException, NoSuchProviderException {
        try (ByteArrayOutputStream privateOut = new ByteArrayOutputStream();
             ByteArrayOutputStream publicOut = new ByteArrayOutputStream()) {
            KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance("RSA", "BC");
            keyPairGenerator.initialize(4096);
            KeyPair pair = keyPairGenerator.generateKeyPair();
            PGPDigestCalculator shaCalc = new JcaPGPDigestCalculatorProviderBuilder()
                    .build()
                    .get(HashAlgorithmTags.SHA1);
            PGPKeyPair keyPair = new JcaPGPKeyPair(PGPPublicKey.RSA_GENERAL, pair, new Date());
            PGPSecretKey privateKey = new PGPSecretKey(
                    PGPSignature.DEFAULT_CERTIFICATION,
                    keyPair,
                    "nzyme-pgp",
                    shaCalc,
                    null,
                    null,
                    new JcaPGPContentSignerBuilder(
                            keyPair.getPublicKey().getAlgorithm(),
                            HashAlgorithmTags.SHA256),
                    new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, shaCalc)
                            .setProvider("BC")
                            .build("nzyme".toCharArray())
            );
            // Write private key.
            privateKey.encode(privateOut);
            // Write public key.
            PGPPublicKey key = privateKey.getPublicKey();
            key.encode(publicOut);
            return PGPKeys.create(
                    privateOut.toByteArray(),
                    publicOut.toByteArray()
            );
        }
    }
    public TLSKeyAndCertificate generateTLSCertificate(String subjectDN, int validityMonths) throws CryptoOperationException {
        SecureRandom random = new SecureRandom();
        DateTime now = new DateTime();
        Date startDate = now.toDate();
        Date endDate = now.plusMonths(validityMonths).toDate();
        KeyPair keyPair;
        try {
            KeyPairGenerator keypairGen = KeyPairGenerator.getInstance("RSA", "BC");
            keypairGen.initialize(2048, random);
            keyPair = keypairGen.generateKeyPair();
        } catch (NoSuchAlgorithmException | NoSuchProviderException e) {
            throw new CryptoOperationException("Could not initialize key pair generator.", e);
        }
        X500Name dnName = new X500Name(subjectDN);
        BigInteger certSerialNumber = new BigInteger(Long.toString(now.getMillis()));
        String signatureAlgorithm = "SHA256WithRSA";
        ContentSigner contentSigner;
        try {
            contentSigner = new JcaContentSignerBuilder(signatureAlgorithm).build(keyPair.getPrivate());
        } catch (OperatorCreationException e) {
            throw new CryptoOperationException("Could not initialize content signer.", e);
        }
        JcaX509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(
                dnName,
                certSerialNumber,
                startDate,
                endDate,
                dnName,
                keyPair.getPublic()
        );
        try {
            certBuilder.addExtension(new ASN1ObjectIdentifier("2.5.29.19"), true, new BasicConstraints(true));
        } catch (CertIOException e) {
            throw new CryptoOperationException("Could not add extension.", e);
        }
        try {
            X509Certificate certificate = new JcaX509CertificateConverter().setProvider(this.bcProvider)
                    .getCertificate(certBuilder.build(contentSigner));
            // Create a list of only one cert. We don't have a chain for self-signed certs.
            ArrayList<X509Certificate> certificates = Lists.newArrayList();
            certificates.add(certificate);
            return TLSKeyAndCertificate.create(
                    nzyme.getNodeManager().getLocalNodeId(),
                    TLSSourceType.GENERATED_SELF_SIGNED,
                    certificates,
                    keyPair.getPrivate(),
                    TLSUtils.calculateTLSCertificateFingerprint(certificate),
                    new DateTime(certificate.getNotBefore()),
                    new DateTime(certificate.getNotAfter())
            );
        } catch (CertificateException | NoSuchAlgorithmException e) {
            throw new RuntimeException(e);
        }
    }
    public byte[] encryptWithClusterKey(byte[] value) throws CryptoOperationException {
        File publicKeyLocation = Paths.get(cryptoDirectoryConfig.toString(), PGP_PUBLIC_KEY_FILE_NAME).toFile();
        try {
            return encrypt(value, readPublicKey(publicKeyLocation));
        } catch (IOException | PGPException e) {
            throw new CryptoOperationException("Cannot encrypt value.", e);
        }
    }
    public byte[] encrypt(byte[] value, PGPPublicKey publicKey) throws CryptoOperationException {
        try(ByteArrayOutputStream out = new ByteArrayOutputStream(); ByteArrayOutputStream literalData = new ByteArrayOutputStream();){
            Timer.Context timer = encryptionTimer.time();
            // Write header and literal data.
            PGPLiteralDataGenerator literalDataGenerator = new PGPLiteralDataGenerator();
            OutputStream literalOut = literalDataGenerator.open(literalData, PGPLiteralData.BINARY, "nzymepgp", value.length, DateTime.now().toDate());
            literalOut.write(value);
            byte[] bytes = literalData.toByteArray();
            literalDataGenerator.close();
            PGPEncryptedDataGenerator encGen = new PGPEncryptedDataGenerator(
                    new JcePGPDataEncryptorBuilder(PGPEncryptedData.AES_256)
                            .setWithIntegrityPacket(true)
                            .setSecureRandom(new SecureRandom())
                            .setProvider("BC")
            );
            encGen.addMethod(new JcePublicKeyKeyEncryptionMethodGenerator(publicKey).setProvider("BC"));
            OutputStream enc = encGen.open(out, bytes.length);
            enc.write(bytes);
            enc.close();
            timer.stop();
            return out.toByteArray();
        } catch (PGPException | IOException e) {
            throw new CryptoOperationException("Cannot encrypt value.", e);
        }
    }
    public byte[] decryptWithClusterKey(byte[] value) throws CryptoOperationException {
        File privateKeyLocation = Paths.get(cryptoDirectoryConfig.toString(), PGP_PRIVATE_KEY_FILE_NAME).toFile();
        try(InputStream keyIn = new FileInputStream(privateKeyLocation)) {
            return decrypt(value, keyIn);
        } catch (CryptoOperationException | IOException e) {
            throw new CryptoOperationException("Cannot decrypt value.", e);
        }
    }
    public byte[] decrypt(byte[] value, InputStream keyInput) throws CryptoOperationException {
        try(InputStream dataIn = PGPUtil.getDecoderStream(new ByteArrayInputStream(value))) {
            Timer.Context timer = decryptionTimer.time();
            JcaPGPObjectFactory pgpF = new JcaPGPObjectFactory(dataIn);
            PGPEncryptedDataList enc;
            // The first object might be a PGP marker packet.
            Object o = pgpF.nextObject();
            if (o instanceof PGPEncryptedDataList) {
                enc = (PGPEncryptedDataList) o;
            } else {
                enc = (PGPEncryptedDataList) pgpF.nextObject();
            }
            // Find the secret key.
            Iterator<PGPEncryptedData> it = enc.getEncryptedDataObjects();
            PGPPrivateKey sKey = null;
            PGPPublicKeyEncryptedData pbe = null;
            PGPSecretKeyRingCollection pgpSec = new PGPSecretKeyRingCollection(
                    PGPUtil.getDecoderStream(keyInput), new JcaKeyFingerprintCalculator()
            );
            while (sKey == null && it.hasNext()) {
                pbe = (PGPPublicKeyEncryptedData) it.next();
                sKey = findSecretKey(pgpSec, pbe.getKeyID());
            }
            if (sKey == null) {
                throw new IllegalArgumentException("Secret key for message not found.");
            }
            InputStream clear = pbe.getDataStream(
                    new JcePublicKeyDataDecryptorFactoryBuilder()
                            .setProvider("BC")
                            .build(sKey)
            );
            JcaPGPObjectFactory plainFact = new JcaPGPObjectFactory(clear);
            Object message = plainFact.nextObject();
            clear.close();
            if (message instanceof PGPCompressedData) {
                PGPCompressedData cData = (PGPCompressedData) message;
                JcaPGPObjectFactory pgpFact = new JcaPGPObjectFactory(cData.getDataStream());
                message = pgpFact.nextObject();
            }
            ByteArrayOutputStream data = new ByteArrayOutputStream();
            if (message instanceof PGPLiteralData) {
                PGPLiteralData ld = (PGPLiteralData) message;
                InputStream unc = ld.getInputStream();
                Streams.pipeAll(unc, data, 8192);
                unc.close();
            } else {
                throw new PGPException("Data type unknown: " + message.getClass().getCanonicalName());
            }
            if (pbe.isIntegrityProtected() && !pbe.verify()) {
                throw new CryptoOperationException("PGP data integrity check failed.");
            }
            data.close();
            timer.stop();
            return data.toByteArray();
        } catch(IOException | PGPException | IllegalArgumentException e) {
            throw new CryptoOperationException("Cannot decrypt value.", e);
        }
    }
    public List<PGPKeyFingerprint> getPGPKeysByNode() {
        return database.withHandle(handle ->
                handle.createQuery("SELECT node_name, node_id, key_signature, created_at " +
                        "FROM crypto_keys WHERE key_type = :key_type ORDER BY node_name")
                        .bind("key_type", KeyType.PGP)
                        .mapTo(PGPKeyFingerprint.class)
                        .list()
        );
    }
    public String getLocalPGPKeyFingerprint() {
        return database.withHandle(handle ->
                handle.createQuery("SELECT key_signature FROM crypto_keys " +
                                "WHERE key_type = :key_type AND node_id = :node_id")
                        .bind("key_type", KeyType.PGP)
                        .bind("node_id", nodeId)
                        .mapTo(String.class)
                        .one()
        );
    }
    public boolean allPGPKeysEqualAcrossCluster() {
        Set<String> uniqueFingerprints = Sets.newHashSet();
        for (PGPKeyFingerprint fp : getPGPKeysByNode()) {
            uniqueFingerprints.add(fp.fingerprint());
        }
        return uniqueFingerprints.size() == 1;
    }
    public List<TLSKeyAndCertificate> getTLSCertificateByNode() {
        List<TLSKeyAndCertificateEntry> entries = database.withHandle(handle ->
                handle.createQuery("SELECT node_id, certificate, source_type, key, valid_from, expires_at " +
                                "FROM crypto_tls_certificates ORDER BY node_id DESC")
                        .mapTo(TLSKeyAndCertificateEntry.class)
                        .list()
        );
        List<TLSKeyAndCertificate> result = Lists.newArrayList();
        for (TLSKeyAndCertificateEntry entry : entries) {
            try {
                result.add(tlsKeyAndCertificateEntryToObject(entry));
            } catch (CertificateException | NoSuchAlgorithmException | InvalidKeySpecException | TLSUtils.PEMParserException e) {
                LOG.error("Could not build TLS certificate from database. Skipping.", e);
            }
        }
        return result;
    }
    public Optional<TLSKeyAndCertificate> getTLSCertificateOfNode(UUID nodeId) {
        Optional<TLSKeyAndCertificateEntry> entry = database.withHandle(handle ->
                handle.createQuery("SELECT node_id, certificate, source_type, key, valid_from, expires_at " +
                                "FROM crypto_tls_certificates WHERE node_id = :node_id")
                        .bind("node_id", nodeId)
                        .mapTo(TLSKeyAndCertificateEntry.class)
                        .findOne()
        );
        if (entry.isEmpty()) {
            return Optional.empty();
        }
        try {
            return Optional.of(tlsKeyAndCertificateEntryToObject(entry.get()));
        } catch (CertificateException | NoSuchAlgorithmException | InvalidKeySpecException | TLSUtils.PEMParserException e) {
            throw new RuntimeException("Could not build TLS certificate from database.", e);
        }
    }
    private List<TLSWildcardKeyAndCertificateEntry> getTLSWildcardCertificateEntries() {
        return database.withHandle(handle ->
                handle.createQuery("SELECT id, node_matcher, certificate, key, valid_from, expires_at, source_type " +
                                "FROM crypto_tls_certificates_wildcard ORDER BY node_matcher DESC")
                        .mapTo(TLSWildcardKeyAndCertificateEntry.class)
                        .list()
        );
    }
    public List<TLSWildcardKeyAndCertificate> getTLSWildcardCertificates() {
        List<TLSWildcardKeyAndCertificateEntry> entries = getTLSWildcardCertificateEntries();
        List<TLSWildcardKeyAndCertificate> result = Lists.newArrayList();
        for (TLSWildcardKeyAndCertificateEntry entry : entries) {
            try {
                result.add(tlsWildcardKeyAndCertificateEntryToObject(entry));
            } catch (TLSUtils.PEMParserException | CertificateException | NoSuchAlgorithmException |
                     InvalidKeySpecException e) {
                throw new RuntimeException("Could not build TLS wildcard certificate from database.");
            }
        }
        return result;
    }
    public Optional<TLSWildcardKeyAndCertificate> getTLSWildcardCertificate(long id) {
        Optional<TLSWildcardKeyAndCertificateEntry> entry = database.withHandle(handle ->
                handle.createQuery("SELECT id, node_matcher, certificate, key, valid_from, expires_at, source_type " +
                        "FROM crypto_tls_certificates_wildcard WHERE id = :id")
                        .bind("id", id)
                        .mapTo(TLSWildcardKeyAndCertificateEntry.class)
                        .findOne()
        );
        if (entry.isEmpty()) {
            return Optional.empty();
        }
        try {
            return Optional.of(tlsWildcardKeyAndCertificateEntryToObject(entry.get()));
        } catch (CertificateException | NoSuchAlgorithmException | InvalidKeySpecException |
                 TLSUtils.PEMParserException e) {
            throw new RuntimeException("Could not build TLS wildcard certificate from database.");
        }
    }
    public Map<UUID, TLSKeyAndCertificate> getTLSWildcardCertificatesForMatchingNodes() {
        List<TLSWildcardKeyAndCertificateEntry> entries = getTLSWildcardCertificateEntries();
        Map<UUID, TLSKeyAndCertificate> result = new TreeMap<>();
        List<Node> nodes = nzyme.getNodeManager().getNodes();
        for (TLSWildcardKeyAndCertificateEntry entry : entries) {
            // Find all matching nodes for this wildcard entry.
            for (Node node : nodes) {
                if (node.name().matches(entry.nodeMatcher())) {
                    try {
                        result.put(node.uuid(), tlsWildcardKeyAndCertificateEntryToNodeCertificate(entry, node));
                    } catch (TLSUtils.PEMParserException | NoSuchAlgorithmException | CertificateException |
                             InvalidKeySpecException e) {
                        throw new RuntimeException("Could not build TLS wildcard node certificate from database.");
                    }
                }
            }
        }
        return result;
    }
    public KeyStoreBootstrapResult bootstrapTLSKeyStore() {
        try {
            Optional<TLSKeyAndCertificate> diskCert = loadTLSCertificateFromDisk();
            TLSKeyAndCertificate tls;
            if (diskCert.isPresent()) {
                Optional<TLSKeyAndCertificate> existingCert = findTLSKeyAndCertificateOfNode(nodeId);
                tls = diskCert.get();
                if (existingCert.isPresent()) {
                    updateTLSCertificateOfNode(nodeId, tls);
                } else {
                    setTLSKeyAndCertificateOfNode(nodeId, tls);
                }
            } else {
                // Check if there is this node matches a wildcard cert.
                Map<UUID, TLSKeyAndCertificate> matchingNodes = getTLSWildcardCertificatesForMatchingNodes();
                TLSKeyAndCertificate wildcardTls = matchingNodes.get(nzyme.getNodeInformation().id());
                if (wildcardTls != null) {
                    // Wildcard
                    tls = wildcardTls;
                } else {
                    Optional<TLSKeyAndCertificate> tlsData = findTLSKeyAndCertificateOfNode(nodeId);
                    if (tlsData.isEmpty()) {
                        throw new RuntimeException("No TLS certificate data of this node found in database.");
                    }
                    tls = tlsData.get();
                }
            }
            List<Certificate> certChain = Lists.newArrayList();
            certChain.addAll(tls.certificates());
            KeyStore keyStore = KeyStore.getInstance(KeyStore.getDefaultType());
            keyStore.load(null, null);
            keyStore.setKeyEntry("key", tls.key(), "".toCharArray(), certChain.toArray(new Certificate[certChain.size()]));
            try(ByteArrayOutputStream ksStream = new ByteArrayOutputStream()) {
                keyStore.store(ksStream, "".toCharArray());
                return KeyStoreBootstrapResult.create(ksStream.toByteArray(), tls);
            }
        } catch(Exception e) {
            throw new RuntimeException("Could not build TLS key store.", e);
        }
    }
    private Optional<TLSKeyAndCertificate> loadTLSCertificateFromDisk() {
        File certFile = Paths.get(cryptoDirectoryConfig.toString(), TLS_CERTIFICATE_FILE_NAME).toFile();
        File keyFile = Paths.get(cryptoDirectoryConfig.toString(), TLS_KEY_FILE_NAME).toFile();
        if (certFile.exists() && keyFile.exists()) {
            try (FileInputStream certFileS = new FileInputStream(certFile);
                 FileInputStream keyFileS = new FileInputStream(keyFile)) {
                return Optional.of(
                        TLSUtils.readTLSKeyAndCertificateFromInputStreams(nodeId, TLSSourceType.FILE_LOADED, certFileS, keyFileS)
                );
            } catch (Exception e) {
                throw new RuntimeException("Could not read TLS certificate from disk.", e);
            }
        } else {
            return Optional.empty();
        }
    }
    public void updateTLSCertificateOfNode(UUID nodeId, TLSKeyAndCertificate tls) {
        String certificate;
        String key;
        try {
            certificate = TLSUtils.serializeCertificateChain(tls.certificates());
            key = BaseEncoding.base64().encode(tls.key().getEncoded());
        } catch(Exception e) {
            throw new RuntimeException("Could not encode TLS data.", e);
        }
        // We are double-encoding some things here to avoid confusion later on. It's base64, encrypted, base64 again for storage.
        String encryptedCertificate, encryptedKey;
        try {
            encryptedCertificate = BaseEncoding.base64().encode(encryptWithClusterKey(certificate.getBytes()));
            encryptedKey = BaseEncoding.base64().encode(encryptWithClusterKey(key.getBytes()));
        } catch(CryptoOperationException e) {
            throw new RuntimeException("Could not encrypt TLS certificate/key for database storage.", e);
        }
        nzyme.getDatabase().useHandle(handle ->
            handle.createUpdate("UPDATE crypto_tls_certificates SET certificate = :certificate, key = :key, " +
                            "source_type = :source_type, valid_from = :valid_from, expires_at = :expires_at " +
                            "WHERE node_id = :node_id")
                    .bind("certificate", encryptedCertificate)
                    .bind("key", encryptedKey)
                    .bind("source_type", tls.sourceType().name())
                    .bind("valid_from", tls.validFrom())
                    .bind("expires_at", tls.expiresAt())
                    .bind("node_id", nodeId)
                    .execute()
        );
    }
    public void writeTLSWildcardCertificate(TLSWildcardKeyAndCertificate tls) {
        String certificate;
        String key;
        try {
            certificate = TLSUtils.serializeCertificateChain(tls.certificates());
            key = BaseEncoding.base64().encode(tls.key().getEncoded());
        } catch(Exception e) {
            throw new RuntimeException("Could not encode TLS data.", e);
        }
        if (tls.nodeMatcher().trim().isEmpty()) {
            throw new RuntimeException("Node matcher is empty.");
        }
        // We are double-encoding some things here to avoid confusion later on. It's base64, encrypted, base64 again for storage.
        String encryptedCertificate, encryptedKey;
        try {
            encryptedCertificate = BaseEncoding.base64().encode(encryptWithClusterKey(certificate.getBytes()));
            encryptedKey = BaseEncoding.base64().encode(encryptWithClusterKey(key.getBytes()));
        } catch(CryptoOperationException e) {
            throw new RuntimeException("Could not encrypt TLS certificate/key for database storage.", e);
        }
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("INSERT INTO crypto_tls_certificates_wildcard(node_matcher, certificate, key, " +
                                "valid_from, expires_at, source_type) VALUES(:node_matcher, :certificate, :key, :valid_from, " +
                                ":expires_at, :source_type)")
                        .bind("node_matcher", tls.nodeMatcher())
                        .bind("certificate", encryptedCertificate)
                        .bind("key", encryptedKey)
                        .bind("source_type", tls.sourceType().name())
                        .bind("valid_from", tls.validFrom())
                        .bind("expires_at", tls.expiresAt())
                        .execute()
        );
    }
    public void replaceTLSWildcardCertificate(long certificateId, TLSWildcardKeyAndCertificate newCert) {
        String certificate;
        String key;
        try {
            certificate = TLSUtils.serializeCertificateChain(newCert.certificates());
            key = BaseEncoding.base64().encode(newCert.key().getEncoded());
        } catch(Exception e) {
            throw new RuntimeException("Could not encode TLS data.", e);
        }
        if (newCert.nodeMatcher().trim().isEmpty()) {
            throw new RuntimeException("Node matcher is empty.");
        }
        // We are double-encoding some things here to avoid confusion later on. It's base64, encrypted, base64 again for storage.
        String encryptedCertificate, encryptedKey;
        try {
            encryptedCertificate = BaseEncoding.base64().encode(encryptWithClusterKey(certificate.getBytes()));
            encryptedKey = BaseEncoding.base64().encode(encryptWithClusterKey(key.getBytes()));
        } catch(CryptoOperationException e) {
            throw new RuntimeException("Could not encrypt TLS certificate/key for database storage.", e);
        }
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("UPDATE crypto_tls_certificates_wildcard SET node_matcher = :node_matcher, " +
                        "certificate = :certificate, key = :key, valid_from = :valid_from, expires_at = :expires_at, " +
                        "source_type = :source_type WHERE id = :certificate_id")
                        .bind("node_matcher", newCert.nodeMatcher())
                        .bind("certificate", encryptedCertificate)
                        .bind("key", encryptedKey)
                        .bind("source_type", newCert.sourceType().name())
                        .bind("valid_from", newCert.validFrom())
                        .bind("expires_at", newCert.expiresAt())
                        .bind("certificate_id", certificateId)
                        .execute()
        );
    }
    public void updateTLSWildcardCertificateNodeMatcher(long certificateId, String nodeMatcher) {
        if (nodeMatcher.trim().isEmpty()) {
            throw new RuntimeException("Node matcher is empty.");
        }
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("UPDATE crypto_tls_certificates_wildcard SET node_matcher = :node_matcher " +
                                "WHERE id = :certificate_id")
                        .bind("node_matcher", nodeMatcher)
                        .bind("certificate_id", certificateId)
                        .execute()
        );
    }
    public void deleteTLSWildcardCertificate(long certificateId) {
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("DELETE FROM crypto_tls_certificates_wildcard WHERE id = :certificate_id")
                        .bind("certificate_id", certificateId)
                        .execute()
        );
    }
    public PGPKeys getNodeLocalPGPKeys() {
        return nodeLocalPGPKeys;
    }
    public static PGPPublicKey readPublicKey(File file) throws IOException, PGPException {
        try(InputStream keyIn = new BufferedInputStream(new FileInputStream(file))) {
            return readPublicKey(keyIn);
        }
    }
    public static PGPPublicKey readPublicKey(byte[] bytes) throws IOException, PGPException {
        try(InputStream keyIn = new BufferedInputStream(new ByteArrayInputStream(bytes))) {
            return readPublicKey(keyIn);
        }
    }
    public static PGPPublicKey readPublicKey(InputStream input) throws IOException, PGPException {
        PGPPublicKeyRingCollection pgpPub = new PGPPublicKeyRingCollection(PGPUtil.getDecoderStream(input), new JcaKeyFingerprintCalculator());
        Iterator keyRingIter = pgpPub.getKeyRings();
        while (keyRingIter.hasNext()) {
            PGPPublicKeyRing keyRing = (PGPPublicKeyRing)keyRingIter.next();
            Iterator keyIter = keyRing.getPublicKeys();
            while (keyIter.hasNext()) {
                PGPPublicKey key = (PGPPublicKey)keyIter.next();
                if (key.isEncryptionKey()) {
                    return key;
                }
            }
        }
        throw new IllegalArgumentException("Can't find encryption key in key ring.");
    }
    public boolean isPGPKeySyncEnabled() {
        return nzyme.getDatabaseCoreRegistry().getValue(CryptoRegistryKeys.PGP_KEY_SYNC_ENABLED.key())
                .map(s -> s.equals("true"))
                .orElse(Boolean.parseBoolean(CryptoRegistryKeys.PGP_KEY_SYNC_ENABLED.defaultValue().get()));
    }
    private PGPPrivateKey findSecretKey(PGPSecretKeyRingCollection pgpSec, long keyID) throws PGPException {
        PGPSecretKey pgpSecKey = pgpSec.getSecretKey(keyID);
        if (pgpSecKey == null) {
            return null;
        }
        return pgpSecKey.extractPrivateKey(
                new JcePBESecretKeyDecryptorBuilder()
                        .setProvider("BC")
                        .build("nzyme".toCharArray())
        );
    }
    private Optional<TLSKeyAndCertificate> findTLSKeyAndCertificateOfNode(UUID nodeId) {
        Optional<TLSKeyAndCertificateEntry> entry = nzyme.getDatabase().withHandle(handle ->
                handle.createQuery("SELECT node_id, certificate, key, source_type, valid_from, expires_at " +
                                "FROM crypto_tls_certificates WHERE node_id = :node_id")
                        .bind("node_id", nodeId)
                        .mapTo(TLSKeyAndCertificateEntry.class)
                        .findFirst()
        );
        if (entry.isEmpty()) {
            return Optional.empty();
        } else {
            try {
                return Optional.of(tlsKeyAndCertificateEntryToObject(entry.get()));
            } catch(Exception e) {
                throw new RuntimeException("Could not read TLS data.", e);
            }
        }
    }
    private TLSKeyAndCertificate tlsKeyAndCertificateEntryToObject(TLSKeyAndCertificateEntry entry)
            throws CertificateException, NoSuchAlgorithmException, InvalidKeySpecException, TLSUtils.PEMParserException {
        String decryptedCertificate, decryptedKey;
        try {
            decryptedCertificate = new String(decryptWithClusterKey(entry.certificate().getBytes()));
            decryptedKey = new String(decryptWithClusterKey(entry.key().getBytes()));
        } catch(CryptoOperationException e) {
            throw new RuntimeException("Could not decrypt TLS certificate/key.", e);
        }
        List<X509Certificate> certificates = TLSUtils.deSerializeCertificateChain(decryptedCertificate);
        X509Certificate firstCertificate = certificates.get(0);
        PrivateKey key = TLSUtils.deserializeKey(decryptedKey);
        return TLSKeyAndCertificate.create(
                entry.nodeId(),
                entry.sourceType(),
                certificates,
                key,
                TLSUtils.calculateTLSCertificateFingerprint(firstCertificate),
                new DateTime(firstCertificate.getNotBefore()),
                new DateTime(firstCertificate.getNotAfter())
        );
    }
    private TLSWildcardKeyAndCertificate tlsWildcardKeyAndCertificateEntryToObject(TLSWildcardKeyAndCertificateEntry entry)
            throws CertificateException, NoSuchAlgorithmException, InvalidKeySpecException, TLSUtils.PEMParserException {
        String decryptedCertificate, decryptedKey;
        try {
            decryptedCertificate = new String(decryptWithClusterKey(entry.certificate().getBytes()));
            decryptedKey = new String(decryptWithClusterKey(entry.key().getBytes()));
        } catch(CryptoOperationException e) {
            throw new RuntimeException("Could not decrypt TLS certificate/key.", e);
        }
        List<X509Certificate> certificates = TLSUtils.deSerializeCertificateChain(decryptedCertificate);
        X509Certificate firstCertificate = certificates.get(0);
        PrivateKey key = TLSUtils.deserializeKey(decryptedKey);
        return TLSWildcardKeyAndCertificate.create(
                entry.id(),
                entry.nodeMatcher(),
                entry.sourceType(),
                certificates,
                key,
                TLSUtils.calculateTLSCertificateFingerprint(firstCertificate),
                new DateTime(firstCertificate.getNotBefore()),
                new DateTime(firstCertificate.getNotAfter())
        );
    }
    private TLSKeyAndCertificate tlsWildcardKeyAndCertificateEntryToNodeCertificate(TLSWildcardKeyAndCertificateEntry entry, Node node)
            throws CertificateException, NoSuchAlgorithmException, InvalidKeySpecException, TLSUtils.PEMParserException {
        String decryptedCertificate, decryptedKey;
        try {
            decryptedCertificate = new String(decryptWithClusterKey(entry.certificate().getBytes()));
            decryptedKey = new String(decryptWithClusterKey(entry.key().getBytes()));
        } catch(CryptoOperationException e) {
            throw new RuntimeException("Could not decrypt TLS certificate/key.", e);
        }
        List<X509Certificate> certificates = TLSUtils.deSerializeCertificateChain(decryptedCertificate);
        X509Certificate firstCertificate = certificates.get(0);
        PrivateKey key = TLSUtils.deserializeKey(decryptedKey);
        return TLSKeyAndCertificate.create(
                node.uuid(),
                entry.sourceType(),
                certificates,
                key,
                TLSUtils.calculateTLSCertificateFingerprint(firstCertificate),
                new DateTime(firstCertificate.getNotBefore()),
                new DateTime(firstCertificate.getNotAfter())
        );
    }
    private void setTLSKeyAndCertificateOfNode(UUID nodeId, TLSKeyAndCertificate tls) {
        String certificate;
        String key;
        try {
            certificate = TLSUtils.serializeCertificateChain(tls.certificates());
            key = BaseEncoding.base64().encode(tls.key().getEncoded());
        } catch(Exception e) {
            throw new RuntimeException("Could not encode TLS data.", e);
        }
        // We are double-encoding some things here to avoid confusion later on. It's base64, encrypted, base64 again for storage.
        String encryptedCertificate, encryptedKey;
        try {
            encryptedCertificate = BaseEncoding.base64().encode(encryptWithClusterKey(certificate.getBytes()));
            encryptedKey = BaseEncoding.base64().encode(encryptWithClusterKey(key.getBytes()));
        } catch(CryptoOperationException e) {
            throw new RuntimeException("Could not encrypt TLS certificate/key for database storage.", e);
        }
        nzyme.getDatabase().useHandle(handle ->
                handle.createUpdate("INSERT INTO crypto_tls_certificates(node_id, certificate, key, source_type, " +
                                "valid_from, expires_at) VALUES(:node_id, :certificate, :key, :source_type, " +
                                ":valid_from, :expires_at)")
                        .bind("node_id", nodeId)
                        .bind("certificate", encryptedCertificate)
                        .bind("key", encryptedKey)
                        .bind("source_type", tls.sourceType().name())
                        .bind("valid_from", tls.validFrom())
                        .bind("expires_at", tls.expiresAt())
                        .execute()
        );
    }
    private void retentionCleanKeys() {
        List<UUID> activeNodeIds = Lists.newArrayList();
        for (Node node : nzyme.getNodeManager().getNodes()) {
            if (node.lastSeen().isAfter(DateTime.now().minusMinutes(2))) {
                activeNodeIds.add(node.uuid());
            }
        }
        for (PGPKeyFingerprint fingerprint : getPGPKeysByNode()) {
            if (!activeNodeIds.contains(fingerprint.nodeId())) {
                LOG.info("Retention cleaning keys of inactive node [{}/{}].",
                        fingerprint.nodeName(), fingerprint.nodeId());
                nzyme.getDatabase().useHandle(handle ->
                        handle.createUpdate("DELETE FROM crypto_keys WHERE node_id = :node_id")
                                .bind("node_id", fingerprint.nodeId())
                                .execute()
                );
            }
        }
    }
    public static final class CryptoInitializationException extends Throwable {
        public CryptoInitializationException(String msg) {
            super(msg);
        }
        public CryptoInitializationException(String msg, Throwable e) {
            super(msg, e);
        }
    }
    public static final class CryptoOperationException extends Throwable {
        public CryptoOperationException(String msg) {
            super(msg);
        }
        public CryptoOperationException(String msg, Throwable e) {
            super(msg, e);
        }
    }
}
package app.nzyme.core.database;
import app.nzyme.core.bluetooth.db.BluetoothDeviceEntryMapper;
import app.nzyme.core.bluetooth.db.BluetoothDeviceSummaryMapper;
import app.nzyme.core.configuration.node.NodeConfiguration;
import app.nzyme.core.context.db.MacAddressContextEntryMapper;
import app.nzyme.core.context.db.MacAddressTransparentContextEntryMapper;
import app.nzyme.core.crypto.database.TLSKeyAndCertificateEntryMapper;
import app.nzyme.core.crypto.database.TLSWildcardKeyAndCertificateEntryMapper;
import app.nzyme.core.database.generic.NumberBucketAggregationResultMapper;
import app.nzyme.core.detection.alerts.db.DetectionAlertAttributeEntryMapper;
import app.nzyme.core.detection.alerts.db.DetectionAlertEntryMapper;
import app.nzyme.core.detection.alerts.db.DetectionAlertTimelineEntryMapper;
import app.nzyme.core.distributed.database.NodeEntryMapper;
import app.nzyme.core.distributed.database.metrics.GaugeHistogramBucketMapper;
import app.nzyme.core.distributed.database.metrics.TimerSnapshotMapper;
import app.nzyme.core.distributed.messaging.postgres.PostgresMessageEntryMapper;
import app.nzyme.core.distributed.tasksqueue.postgres.PostgresTasksQueueEntryMapper;
import app.nzyme.core.dot11.db.*;
import app.nzyme.core.dot11.db.monitoring.*;
import app.nzyme.core.dot11.db.monitoring.probereq.MonitoredProbeRequestEntryMapper;
import app.nzyme.core.dot11.tracks.db.TrackDetectorConfigMapper;
import app.nzyme.core.ethernet.dns.db.*;
import app.nzyme.core.ethernet.socks.db.SocksTunnelEntryMapper;
import app.nzyme.core.ethernet.ssh.db.SSHSessionEntryMapper;
import app.nzyme.core.ethernet.tcp.db.TcpSessionEntryMapper;
import app.nzyme.core.events.db.EventActionEntryMapper;
import app.nzyme.core.events.db.EventEntryMapper;
import app.nzyme.core.events.db.SubscriptionEntryMapper;
import app.nzyme.core.floorplans.db.TenantLocationEntryMapper;
import app.nzyme.core.floorplans.db.TenantLocationFloorEntryMapper;
import app.nzyme.core.monitoring.TimerEntryMapper;
import app.nzyme.core.monitoring.health.db.IndicatorStatusMapper;
import app.nzyme.core.registry.RegistryEntryMapper;
import app.nzyme.core.security.authentication.db.OrganizationEntryMapper;
import app.nzyme.core.security.authentication.db.TapPermissionEntryMapper;
import app.nzyme.core.security.authentication.db.TenantEntryMapper;
import app.nzyme.core.security.authentication.db.UserEntryMapper;
import app.nzyme.core.security.sessions.db.SessionEntryMapper;
import app.nzyme.core.security.sessions.db.SessionEntryWithUserDetailsMapper;
import app.nzyme.core.shared.db.GenericIntegerHistogramEntryMapper;
import app.nzyme.core.shared.db.TapBasedSignalStrengthResultMapper;
import app.nzyme.core.taps.Tap;
import app.nzyme.core.taps.db.metrics.Dot11FrequencyAndChannelWidthEntryMapper;
import app.nzyme.core.taps.db.metrics.TapMetricsTimerMapper;
import app.nzyme.plugin.Database;
import app.nzyme.core.crypto.database.PGPKeyFingerprintMapper;
import app.nzyme.core.taps.db.*;
import app.nzyme.core.taps.db.metrics.TapMetricsAggregationMapper;
import app.nzyme.core.taps.db.metrics.TapMetricsGaugeMapper;
import com.google.common.collect.Lists;
import jakarta.annotation.Nullable;
import liquibase.*;
import liquibase.database.DatabaseFactory;
import liquibase.database.jvm.JdbcConnection;
import liquibase.exception.LiquibaseException;
import liquibase.resource.ClassLoaderResourceAccessor;
import liquibase.ui.LoggerUIService;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.jdbi.v3.core.ConnectionException;
import org.jdbi.v3.core.HandleCallback;
import org.jdbi.v3.core.HandleConsumer;
import org.jdbi.v3.core.Jdbi;
import org.jdbi.v3.core.statement.SqlLogger;
import org.jdbi.v3.core.statement.StatementContext;
import org.jdbi.v3.jodatime2.JodaTimePlugin;
import org.jdbi.v3.postgres.PostgresPlugin;
import org.joda.time.DateTime;
import java.sql.Timestamp;
import java.time.temporal.ChronoUnit;
import java.util.List;
import java.util.Map;
public class DatabaseImpl implements Database {
    private static final Logger LOG = LogManager.getLogger(DatabaseImpl.class);
    private final NodeConfiguration configuration;
    private Jdbi jdbi;
    public DatabaseImpl(NodeConfiguration configuration) {
        this.configuration = configuration;
    }
    public void initialize() throws LiquibaseException {
        // TODO use reflection here at some point.
        this.jdbi = Jdbi.create("jdbc:" + configuration.databasePath())
                .installPlugin(new PostgresPlugin())
                .installPlugin(new JodaTimePlugin())
                .registerRowMapper(new TapMapper())
                .registerRowMapper(new BusMapper())
                .registerRowMapper(new ChannelMapper())
                .registerRowMapper(new CaptureMapper())
                .registerRowMapper(new TapMetricsGaugeMapper())
                .registerRowMapper(new TapMetricsAggregationMapper())
                .registerRowMapper(new DNSStatisticsBucketMapper())
                .registerRowMapper(new DNSTrafficSummaryMapper())
                .registerRowMapper(new DNSPairSummaryMapper())
                .registerRowMapper(new PGPKeyFingerprintMapper())
                .registerRowMapper(new NodeEntryMapper())
                .registerRowMapper(new GaugeHistogramBucketMapper())
                .registerRowMapper(new TimerSnapshotMapper())
                .registerRowMapper(new IndicatorStatusMapper())
                .registerRowMapper(new TLSKeyAndCertificateEntryMapper())
                .registerRowMapper(new TLSWildcardKeyAndCertificateEntryMapper())
                .registerRowMapper(new PostgresMessageEntryMapper())
                .registerRowMapper(new PostgresTasksQueueEntryMapper())
                .registerRowMapper(new OrganizationEntryMapper())
                .registerRowMapper(new TenantEntryMapper())
                .registerRowMapper(new UserEntryMapper())
                .registerRowMapper(new TapPermissionEntryMapper())
                .registerRowMapper(new SessionEntryMapper())
                .registerRowMapper(new SessionEntryWithUserDetailsMapper())
                .registerRowMapper(new RegistryEntryMapper())
                .registerRowMapper(new EventEntryMapper())
                .registerRowMapper(new EventActionEntryMapper())
                .registerRowMapper(new SubscriptionEntryMapper())
                .registerRowMapper(new BSSIDSummaryMapper())
                .registerRowMapper(new SSIDChannelDetailsMapper())
                .registerRowMapper(new BSSIDAndSSIDCountHistogramEntryMapper())
                .registerRowMapper(new SSIDDetailsMapper())
                .registerRowMapper(new Dot11AdvertisementHistogramEntryMapper())
                .registerRowMapper(new SignalTrackHistogramEntryMapper())
                .registerRowMapper(new ActiveChannelMapper())
                .registerRowMapper(new ConnectedClientDetailsMapper())
                .registerRowMapper(new DisconnectedClientDetailsMapper())
                .registerRowMapper(new ClientHistogramEntryMapper())
                .registerRowMapper(new ClientActivityHistogramEntryMapper())
                .registerRowMapper(new FirstLastSeenTupleMapper())
                .registerRowMapper(new MonitoredSSIDMapper())
                .registerRowMapper(new MonitoredBSSIDMapper())
                .registerRowMapper(new MonitoredFingerprintMapper())
                .registerRowMapper(new MonitoredChannelMapper())
                .registerRowMapper(new MonitoredSecuritySuiteMapper())
                .registerRowMapper(new BSSIDWithTapMapper())
                .registerRowMapper(new DetectionAlertEntryMapper())
                .registerRowMapper(new DetectionAlertAttributeEntryMapper())
                .registerRowMapper(new DetectionAlertTimelineEntryMapper())
                .registerRowMapper(new TrackDetectorConfigMapper())
                .registerRowMapper(new CustomBanditDescriptionMapper())
                .registerRowMapper(new DiscoHistogramEntryMapper())
                .registerRowMapper(new CustomBanditDescriptionMapper())
                .registerRowMapper(new BSSIDFrameCountMapper())
                .registerRowMapper(new BSSIDPairFrameCountMapper())
                .registerRowMapper(new MacAddressContextEntryMapper())
                .registerRowMapper(new TapBasedSignalStrengthResultMapper())
                .registerRowMapper(new RestrictedSSIDSubstringMapper())
                .registerRowMapper(new ClientSignalStrengthResultMapper())
                .registerRowMapper(new TenantLocationEntryMapper())
                .registerRowMapper(new TenantLocationFloorEntryMapper())
                .registerRowMapper(new TapBasedSignalStrengthResultHistogramEntryMapper())
                .registerRowMapper(new TapMetricsTimerMapper())
                .registerRowMapper(new Dot11FrequencyAndChannelWidthEntryMapper())
                .registerRowMapper(new TcpSessionEntryMapper())
                .registerRowMapper(new DNSEntropyLogEntryMapper())
                .registerRowMapper(new DNSLogEntryMapper())
                .registerRowMapper(new SocksTunnelEntryMapper())
                .registerRowMapper(new SSHSessionEntryMapper())
                .registerRowMapper(new NumberBucketAggregationResultMapper())
                .registerRowMapper(new TimerEntryMapper())
                .registerRowMapper(new BluetoothDeviceEntryMapper())
                .registerRowMapper(new BluetoothDeviceSummaryMapper())
                .registerRowMapper(new GenericIntegerHistogramEntryMapper())
                .registerRowMapper(new MonitoredProbeRequestEntryMapper())
                .registerRowMapper(new MacAddressTransparentContextEntryMapper())
                .registerRowMapper(new SSIDWithOrganizationAndTenantMapper())
                .registerRowMapper(new Dot11KnownNetworkMapper())
                .registerRowMapper(new Dot11KnownClientMapper());
        if (configuration.slowQueryLogThreshold().isPresent()) {
            LOG.info("Slow query log enabled with threshold <{}ms>.", configuration.slowQueryLogThreshold().get());
            this.jdbi.setSqlLogger(new SqlLogger() {
                @Override
                public void logAfterExecution(StatementContext context) {
                    if (context.getElapsedTime(ChronoUnit.MILLIS) > configuration.slowQueryLogThreshold().get()) {
                        LOG.info("Slow query: <{}ms> [{}]",
                                context.getElapsedTime(ChronoUnit.MILLIS), context.getParsedSql().getSql());
                    }
                }
            });
        }
        // Try to establish connection, retry if connection fails.
        JdbcConnection connection;
        while (true) {
            try {
                connection = new JdbcConnection(jdbi.open().getConnection());
                break;
            } catch (ConnectionException e) {
                LOG.warn("Could not connect to PostgreSQL. Retrying.", e);
                try {
                    Thread.sleep(5000);
                } catch (InterruptedException ex) {
                    throw new RuntimeException(ex);
                }
            }
        }
        Liquibase liquibase = null;
        try {
            liquibase.database.Database database = DatabaseFactory.getInstance().findCorrectDatabaseImplementation(connection);
            liquibase = new liquibase.Liquibase("db/migrations.xml", new ClassLoaderResourceAccessor(), database);
            routeLiquibaseLogging(liquibase);
            if (!liquibase.listUnrunChangeSets(new Contexts(), new LabelExpression()).isEmpty()) {
                throw new RuntimeException("There are un-run database changesets. Please run migrations.");
            }
        } finally {
            if (liquibase != null) {
                liquibase.close();
            }
            if (!connection.isClosed()) {
                connection.close();
            }
        }
    }
    public void migrate() throws LiquibaseException {
        Jdbi migrationJdbi = Jdbi.create("jdbc:" + configuration.databasePath())
                .installPlugin(new PostgresPlugin());
        JdbcConnection migrationConnection;
        // Try to establish connection, retry if connection fails.
        while (true) {
            try {
                migrationConnection = new JdbcConnection(migrationJdbi.open().getConnection());
                break;
            } catch (ConnectionException e) {
                LOG.warn("Could not connect to PostgreSQL. Retrying.", e);
                try {
                    Thread.sleep(5000);
                } catch (InterruptedException ex) {
                    throw new RuntimeException(ex);
                }
            }
        }
        Liquibase liquibase = null;
        try {
            LOG.info("Running database migrations.");
            liquibase.database.Database database = DatabaseFactory.getInstance()
                    .findCorrectDatabaseImplementation(migrationConnection);
            liquibase = new liquibase.Liquibase(
                    "db/migrations.xml", new ClassLoaderResourceAccessor(), database
            );
            routeLiquibaseLogging(liquibase);
            liquibase.update(new Contexts(), new LabelExpression());
            LOG.info("All database migrations complete.");
        } finally {
            if (liquibase != null) {
                liquibase.close();
            }
            if (!migrationConnection.isClosed()) {
                migrationConnection.close();
            }
        }
    }
    public long getTotalSize() {
        return withHandle(handle ->
                handle.createQuery("SELECT pg_database_size(current_database())")
                .mapTo(Long.class)
                .one());
    }
    public long getTableSize(String tableName) {
        return withHandle(handle ->
                handle.createQuery("SELECT pg_total_relation_size(:table)")
                        .bind("table", tableName)
                        .mapTo(Long.class)
                        .one());
    }
    public List<DataTableInformation> getTablesOfDataCategory(DataCategory category) {
        List<DataTableInformation> tables = Lists.newArrayList();
        switch (category) {
            case DOT11 -> {
                tables.add(new DataTableInformation(
                        "dot11_bssids",
                        "SELECT COUNT(*) FROM dot11_bssids WHERE tap_uuid IN (<taps>)",
                        "DELETE FROM dot11_bssids WHERE created_at < :since AND tap_uuid IN (<taps>)"
                ));
                tables.add(new DataTableInformation(
                        "dot11_fingerprints",
                        "SELECT (SELECT COUNT(*) FROM dot11_fingerprints LEFT JOIN dot11_bssids ON dot11_bssids.id = dot11_fingerprints.bssid_id WHERE dot11_bssids.tap_uuid IN (<taps>)) + (SELECT COUNT(*) FROM dot11_fingerprints LEFT JOIN dot11_ssids ON dot11_ssids.id = dot11_fingerprints.ssid_id WHERE dot11_ssids.tap_uuid IN (<taps>))",
                        null
                ));
                tables.add(new DataTableInformation(
                        "dot11_bssid_clients",
                        "SELECT COUNT(*) FROM dot11_bssid_clients LEFT JOIN dot11_bssids ON dot11_bssids.id = dot11_bssid_clients.bssid_id WHERE dot11_bssids.tap_uuid IN (<taps>)",
                        null
                ));
                tables.add(new DataTableInformation(
                        "dot11_ssids",
                        "SELECT COUNT(*) FROM dot11_ssids WHERE tap_uuid IN (<taps>)",
                        null
                ));
                tables.add(new DataTableInformation(
                        "dot11_ssid_settings",
                        "SELECT COUNT(*) FROM dot11_ssid_settings LEFT JOIN dot11_ssids ON dot11_ssids.id = dot11_ssid_settings.ssid_id WHERE dot11_ssids.tap_uuid IN (<taps>)",
                        null
                ));
                tables.add(new DataTableInformation(
                        "dot11_infrastructure_types",
                        "SELECT COUNT(*) FROM dot11_infrastructure_types LEFT JOIN dot11_ssids ON dot11_ssids.id = dot11_infrastructure_types.ssid_id WHERE dot11_ssids.tap_uuid IN (<taps>)",
                        null
                ));
                tables.add(new DataTableInformation(
                        "dot11_rates",
                        "SELECT COUNT(*) FROM dot11_rates LEFT JOIN dot11_ssids ON dot11_ssids.id = dot11_rates.ssid_id WHERE dot11_ssids.tap_uuid IN (<taps>)",
                        null
                ));
                tables.add(new DataTableInformation(
                        "dot11_channel_histograms",
                        "SELECT COUNT(*) FROM dot11_channel_histograms LEFT JOIN dot11_ssids ON dot11_ssids.id = dot11_channel_histograms.ssid_id WHERE dot11_ssids.tap_uuid IN (<taps>)",
                        null
                ));
                tables.add(new DataTableInformation(
                        "dot11_channels",
                        "SELECT COUNT(*) FROM dot11_channels LEFT JOIN dot11_ssids ON dot11_ssids.id = dot11_channels.ssid_id WHERE dot11_ssids.tap_uuid IN (<taps>)",
                        null
                ));
                tables.add(new DataTableInformation(
                        "dot11_disco_activity",
                        "SELECT COUNT(*) FROM dot11_disco_activity WHERE tap_uuid IN (<taps>)",
                        "DELETE FROM dot11_disco_activity WHERE created_at < :since AND tap_uuid IN (<taps>)"
                ));
                tables.add(new DataTableInformation(
                        "dot11_disco_activity_receivers",
                        "SELECT COUNT(*) FROM dot11_disco_activity_receivers LEFT JOIN dot11_disco_activity ON dot11_disco_activity.id = dot11_disco_activity_receivers.disco_activity_id WHERE dot11_disco_activity.tap_uuid IN (<taps>)",
                        null
                ));
                tables.add(new DataTableInformation(
                        "dot11_clients",
                        "SELECT COUNT(*) FROM dot11_clients WHERE tap_uuid IN (<taps>)",
                        "DELETE FROM dot11_clients WHERE created_at < :since AND tap_uuid IN (<taps>)"
                ));
                tables.add(new DataTableInformation(
                        "dot11_client_probereq_ssids",
                        "SELECT COUNT(*) FROM dot11_client_probereq_ssids WHERE tap_uuid IN (<taps>)",
                        null
                ));
            }
            case BLUETOOTH -> {
                tables.add(new DataTableInformation(
                        "bluetooth_devices",
                        "SELECT COUNT(*) FROM bluetooth_devices WHERE tap_uuid IN (<taps>)",
                        "DELETE FROM bluetooth_devices WHERE created_at < :since AND tap_uuid IN (<taps>)"
                ));
            }
            case ETHERNET_L4 -> {
                tables.add(new DataTableInformation(
                        "l4_sessions",
                        "SELECT COUNT(*) FROM l4_sessions WHERE tap_uuid IN (<taps>)",
                        "DELETE FROM l4_sessions WHERE created_at < :since AND tap_uuid IN (<taps>)"
                ));
                tables.add(new DataTableInformation(
                        "ssh_sessions",
                        "SELECT COUNT(*) FROM ssh_sessions LEFT JOIN l4_sessions ON l4_sessions.session_key = ssh_sessions.tcp_session_key WHERE l4_sessions.tap_uuid IN (<taps>)",
                        "DELETE FROM ssh_sessions WHERE created_at < :since AND tap_uuid IN (<taps>)"
                ));
                tables.add(new DataTableInformation(
                        "socks_tunnels",
                        "SELECT COUNT(*) FROM socks_tunnels LEFT JOIN l4_sessions ON l4_sessions.session_key = socks_tunnels.tcp_session_key WHERE l4_sessions.tap_uuid IN (<taps>)",
                        "DELETE FROM socks_tunnels WHERE created_at < :since AND tap_uuid IN (<taps>)"
                ));
            }
            case ETHERNET_DNS -> {
                tables.add(new DataTableInformation(
                        "dns_log",
                        "SELECT COUNT(*) FROM dns_log WHERE tap_uuid IN (<taps>)",
                        "DELETE FROM dns_log WHERE created_at < :since AND tap_uuid IN (<taps>)"
                ));
                tables.add(new DataTableInformation(
                        "dns_entropy_log",
                        "SELECT COUNT(*) FROM dns_entropy_log WHERE tap_uuid IN (<taps>)",
                        "DELETE FROM dns_entropy_log WHERE created_at < :since AND tap_uuid IN (<taps>)"
                ));
                tables.add(new DataTableInformation(
                        "dns_pairs",
                        "SELECT COUNT(*) FROM dns_pairs WHERE tap_uuid IN (<taps>)",
                        "DELETE FROM dns_pairs WHERE created_at < :since AND tap_uuid IN (<taps>)"
                ));
                tables.add(new DataTableInformation(
                        "dns_statistics",
                        "SELECT COUNT(*) FROM dns_statistics WHERE tap_uuid IN (<taps>)",
                        "DELETE FROM dns_statistics WHERE created_at < :since AND tap_uuid IN (<taps>)"
                ));
            }
        }
        return tables;
    }
    @Override
    public DateTime getDatabaseClock() {
        Timestamp now = withHandle(handle ->
                handle.createQuery("SELECT NOW()")
                        .mapTo(Timestamp.class)
                        .one()
        );
        return new DateTime(now);
    }
    public <R, X extends Exception> R withHandle(HandleCallback<R, X> callback) throws X {
        return jdbi.withHandle(callback);
    }
    public <X extends Exception> void useHandle(final HandleConsumer<X> callback) throws X {
        jdbi.useHandle(callback);
    }
    private void routeLiquibaseLogging(Liquibase liquibase) {
        try {
            liquibase.setShowSummaryOutput(UpdateSummaryOutputEnum.LOG);
            Scope.enter(Map.of(Scope.Attr.ui.name(), new NullUIService()));
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }
    private static class NullUIService extends LoggerUIService {
        @Override
        public void sendMessage(String message) {
            LOG.info(message);
        }
        @Override
        public void sendErrorMessage(String message, Throwable exception) {
            LOG.error(message, exception);
        }
    }
}
package app.nzyme.core.tables.ssh;
import app.nzyme.core.NzymeNode;
import app.nzyme.core.ethernet.EthernetRegistryKeys;
import app.nzyme.core.rest.resources.taps.reports.tables.ssh.SshSessionReport;
import app.nzyme.core.rest.resources.taps.reports.tables.ssh.SshSessionsReport;
import app.nzyme.core.tables.DataTable;
import app.nzyme.core.tables.TablesService;
import app.nzyme.core.util.MetricNames;
import app.nzyme.core.util.Tools;
import com.codahale.metrics.Timer;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.jdbi.v3.core.Handle;
import org.jdbi.v3.core.statement.PreparedBatch;
import org.joda.time.DateTime;
import java.util.List;
import java.util.Optional;
import java.util.UUID;
public class SSHTable implements DataTable {
    private static final Logger LOG = LogManager.getLogger(SSHTable.class);
    private final TablesService tablesService;
    private final Timer totalReportTimer;
    public SSHTable(TablesService tablesService) {
        this.tablesService = tablesService;
        this.totalReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.SSH_TOTAL_REPORT_PROCESSING_TIMER);
    }
    public void handleReport(UUID tapUuid, DateTime timestamp, SshSessionsReport report) {
        tablesService.getNzyme().getDatabase().useHandle(handle -> {
            try(Timer.Context ignored = totalReportTimer.time()) {
                writeSessions(handle, tapUuid, report.sessions());
            }
        });
    }
    private void writeSessions(Handle handle, UUID tapUuid, List<SshSessionReport> sessions) {
        PreparedBatch insertBatch = handle.prepareBatch("INSERT INTO ssh_sessions(uuid, tap_uuid, " +
                "tcp_session_key, client_version_version, client_version_software, client_version_comments, " +
                "server_version_version, server_version_software, server_version_comments, connection_status, " +
                "tunneled_bytes, established_at, terminated_at, most_recent_segment_time, updated_at, created_at) " +
                "VALUES(:uuid, :tap_uuid, :tcp_session_key, :client_version_version, :client_version_software, " +
                ":client_version_comments, :server_version_version, :server_version_software, " +
                ":server_version_comments, :connection_status, :tunneled_bytes, :established_at, :terminated_at, " +
                ":most_recent_segment_time, NOW(), NOW())");
        PreparedBatch updateBatch = handle.prepareBatch("UPDATE ssh_sessions " +
                "SET connection_status = :connection_status, tunneled_bytes = :tunneled_bytes, " +
                "terminated_at = :terminated_at, most_recent_segment_time = :most_recent_segment_time, " +
                "updated_at = NOW() WHERE id = :id");
        for (SshSessionReport session : sessions) {
            String tcpSessionKey = Tools.buildTcpSessionKey(
                    session.establishedAt(),
                    session.sourceAddress(),
                    session.destinationAddress(),
                    session.sourcePort(),
                    session.destinationPort());
            Optional<Long> existingSession = handle.createQuery("SELECT id FROM ssh_sessions " +
                            "WHERE tcp_session_key = :tcp_session_key AND established_at = :established_at " +
                            "AND tap_uuid = :tap_uuid AND connection_status = :connection_status")
                    .bind("tcp_session_key", tcpSessionKey)
                    .bind("established_at", session.establishedAt())
                    .bind("tap_uuid", tapUuid)
                    .bind("connection_status", "Active")
                    .bind("most_recent_segment_time", session.mostRecentSegmentTime())
                    .mapTo(Long.class)
                    .findOne();
            if (existingSession.isEmpty()) {
                insertBatch
                        .bind("uuid", UUID.randomUUID())
                        .bind("tap_uuid", tapUuid)
                        .bind("tcp_session_key", tcpSessionKey)
                        .bind("client_version_version", session.clientVersion().version())
                        .bind("client_version_software", session.clientVersion().software())
                        .bind("client_version_comments", session.clientVersion().comments())
                        .bind("server_version_version", session.serverVersion().version())
                        .bind("server_version_software", session.serverVersion().software())
                        .bind("server_version_comments", session.serverVersion().comments())
                        .bind("connection_status", session.connectionStatus())
                        .bind("tunneled_bytes", session.tunneledBytes())
                        .bind("established_at", session.establishedAt())
                        .bind("terminated_at", session.terminatedAt())
                        .bind("most_recent_segment_time", session.mostRecentSegmentTime())
                        .add();
            } else {
                // Update existing open SSH session.
                updateBatch
                        .bind("connection_status", session.connectionStatus())
                        .bind("tunneled_bytes", session.tunneledBytes())
                        .bind("terminated_at", session.terminatedAt())
                        .bind("most_recent_segment_time", session.mostRecentSegmentTime())
                        .bind("id", existingSession)
                        .add();
            }
        }
        insertBatch.execute();
        updateBatch.execute();
    }
    @Override
    public void retentionClean() {
        NzymeNode nzyme = tablesService.getNzyme();
        int l4RetentionDays = Integer.parseInt(nzyme.getDatabaseCoreRegistry()
                .getValue(EthernetRegistryKeys.L4_RETENTION_TIME_DAYS.key())
                .orElse(EthernetRegistryKeys.L4_RETENTION_TIME_DAYS.defaultValue().orElse("MISSING"))
        );
        DateTime l4CutOff = DateTime.now().minusDays(l4RetentionDays);
        LOG.info("SSH (TCP/L4) data retention: <{}> days / Delete data older than <{}>.",
                l4RetentionDays, l4CutOff);
    }
}
package app.nzyme.core.tables.bluetooth;
import app.nzyme.core.NzymeNode;
import app.nzyme.core.bluetooth.db.BluetoothServiceUuidJson;
import app.nzyme.core.rest.resources.taps.reports.tables.bluetooth.BluetoothDeviceReport;
import app.nzyme.core.rest.resources.taps.reports.tables.bluetooth.BluetoothDevicesReport;
import app.nzyme.core.rest.responses.bluetooth.BluetoothRegistryKeys;
import app.nzyme.core.tables.DataTable;
import app.nzyme.core.tables.TablesService;
import app.nzyme.core.util.MetricNames;
import com.codahale.metrics.Timer;
import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.google.common.collect.Lists;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.jdbi.v3.core.Handle;
import org.jdbi.v3.core.statement.PreparedBatch;
import org.joda.time.DateTime;
import java.util.List;
import java.util.UUID;
public class BluetoothTable implements DataTable {
    private static final Logger LOG = LogManager.getLogger(BluetoothTable.class);
    private final TablesService tablesService;
    private final Timer totalReportTimer;
    private final ObjectMapper om;
    public BluetoothTable(TablesService tablesService) {
        this.tablesService = tablesService;
        this.om = new ObjectMapper();
        this.totalReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.BLUETOOTH_TOTAL_REPORT_PROCESSING_TIMER);
    }
    public void handleReport(UUID tapUuid, DateTime timestamp, BluetoothDevicesReport report) {
        tablesService.getNzyme().getDatabase().useHandle(handle -> {
            try(Timer.Context ignored = totalReportTimer.time()) {
                writeDevices(handle, tapUuid, report.devices());
            }
        });
    }
    private void writeDevices(Handle handle, UUID tapUuid, List<BluetoothDeviceReport> devices) {
        PreparedBatch batch = handle.prepareBatch("INSERT INTO bluetooth_devices(uuid, tap_uuid, mac, alias, " +
                "device, transport, name, rssi, company_id, class_number, appearance, modalias, tx_power, " +
                "manufacturer_data, uuids, service_data, tags, last_seen, created_at) VALUES(:uuid, :tap_uuid, :mac, " +
                ":alias, :device, :transport, :name, :rssi, :company_id, :class_number, :appearance, :modalias, " +
                ":tx_power, :manufacturer_data, :uuids, :service_data, :tags::jsonb, :last_seen, NOW())");
        for (BluetoothDeviceReport device : devices) {
            List<BluetoothServiceUuidJson> serviceUuids = Lists.newArrayList();
            if (device.uuids() != null) {
                for (String uuid : device.uuids()) {
                    try {
                        serviceUuids.add(BluetoothServiceUuidJson.create(
                                uuid,
                                tablesService.getNzyme().getBluetoothSigService()
                                        .lookupServiceUuid(extract16BitUuid(uuid))
                                        .orElse(null)
                        ));
                    } catch(InvalidBluetoothUuidException e) {
                        LOG.debug("Could not build Bluetooth Service UUID from UUID [{}] for MAC [{}]. " +
                                "Skipping.", uuid, device.mac(), e);
                    }
                }
            }
            String uuids = null;
            String serviceData = null;
            try {
                // Service UUIDs.
                if (!serviceUuids.isEmpty()) {
                    uuids = om.writeValueAsString(serviceUuids);
                }
                serviceData = om.writeValueAsString(device.serviceData());
            } catch (JsonProcessingException e) {
                LOG.warn("Could not serialize Bluetooth device data. Skipping attributes.", e);
            }
            if (device.rssi() == null || device.rssi() == 0) {
                /*
                 * Sometimes devices are reported as a 0 RSSI. Those are usually currently paired devices.
                 */
                continue;
            }
            String tags;
            if (device.tags() != null) {
                try {
                    tags = om.writeValueAsString(device.tags());
                } catch (JsonProcessingException e) {
                    LOG.error("Could not write reported tags of Bluetooth device [{}] to JSON. Skipping tags.",
                            device.mac(), e);
                    tags = null;
                }
            } else {
                tags = null;
            }
            batch
                    .bind("uuid", UUID.randomUUID())
                    .bind("tap_uuid", tapUuid)
                    .bind("mac", device.mac())
                    .bind("alias", device.alias())
                    .bind("device", device.device())
                    .bind("transport", device.transport())
                    .bind("name", device.name())
                    .bind("rssi", device.rssi())
                    .bind("company_id", device.companyId())
                    .bind("class_number", device.classNumber())
                    .bind("appearance", device.appearance())
                    .bind("modalias", device.modalias())
                    .bind("tx_power", device.txPower())
                    .bind("manufacturer_data", device.manufacturerData())
                    .bind("uuids", uuids)
                    .bind("service_data", serviceData)
                    .bind("tags", tags)
                    .bind("last_seen", device.lastSeen())
                    .add();
        }
        batch.execute();
    }
    private static String extract16BitUuid(String uuidStr) throws InvalidBluetoothUuidException {
        if (uuidStr == null || uuidStr.isEmpty()) {
            throw new InvalidBluetoothUuidException("UUID is null or empty");
        }
        uuidStr = uuidStr.toUpperCase();
        // Confirm it's a valid UUID
        try {
            UUID.fromString(uuidStr);
        } catch (IllegalArgumentException e) {
            throw new InvalidBluetoothUuidException("Not a valid UUID");
        }
        // Extract the first 4 characters from the UUID string (the 16-bit UUID part)
        return uuidStr.substring(0, 8).replace("0000", "0x");
    }
    @Override
    public void retentionClean() {
        NzymeNode nzyme = tablesService.getNzyme();
        int bluetoothRetentionDays = Integer.parseInt(nzyme.getDatabaseCoreRegistry()
                .getValue(BluetoothRegistryKeys.BLUETOOTH_RETENTION_TIME_DAYS.key())
                .orElse(BluetoothRegistryKeys.BLUETOOTH_RETENTION_TIME_DAYS.defaultValue().orElse("MISSING"))
        );
        DateTime bluetoothCutoff = DateTime.now().minusDays(bluetoothRetentionDays);
        LOG.info("Bluetooth data retention: <{}> days / Delete data older than <{}>.",
                bluetoothRetentionDays, bluetoothCutoff);
    }
    public static final class InvalidBluetoothUuidException extends Exception {
        public InvalidBluetoothUuidException(String msg) {
            super(msg);
        }
    }
}
package app.nzyme.core.bluetooth.sig;
import app.nzyme.core.NzymeNode;
import app.nzyme.core.connect.ConnectRegistryKeys;
import app.nzyme.core.util.MetricNames;
import com.codahale.metrics.MetricRegistry;
import com.codahale.metrics.Timer;
import com.fasterxml.jackson.databind.DeserializationFeature;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.google.common.collect.Maps;
import com.google.common.net.HttpHeaders;
import com.google.common.util.concurrent.ThreadFactoryBuilder;
import okhttp3.HttpUrl;
import okhttp3.OkHttpClient;
import okhttp3.Request;
import okhttp3.Response;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import java.util.Map;
import java.util.Optional;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.ReentrantLock;
public class BluetoothSigService {
    private static final Logger LOG = LogManager.getLogger(BluetoothSigService.class);
    private final NzymeNode nzyme;
    private final Timer companyIdLookupTimer;
    private final Timer serviceUuidLookupTimer;
    private final ScheduledExecutorService refresher;
    private final ReentrantLock lock = new ReentrantLock();
    private Map<Integer, String> companyIds;
    private Map<String, String> serviceUuids;
    // Can be disabled if Connect is not set up or BT SIG data source is not enabled in Connect.
    private boolean isEnabled = false;
    public BluetoothSigService(NzymeNode nzyme) {
        this.nzyme = nzyme;
        this.companyIdLookupTimer = nzyme.getMetrics()
                .timer(MetricRegistry.name(MetricNames.BTSIG_CID_LOOKUP_TIMING));
        this.serviceUuidLookupTimer = nzyme.getMetrics()
                .timer(MetricRegistry.name(MetricNames.BTSIG_SUUID_LOOKUP_TIMING));
        // Reload on configuration change.
        nzyme.getRegistryChangeMonitor()
                .onChange("core", ConnectRegistryKeys.CONNECT_API_KEY.key(), this::reload);
        nzyme.getRegistryChangeMonitor()
                .onChange("core", ConnectRegistryKeys.CONNECT_ENABLED.key(), this::reload);
        // Reload if provided services by Connect change.
        nzyme.getRegistryChangeMonitor()
                .onChange("core", ConnectRegistryKeys.PROVIDED_SERVICES.key(), this::reload);
        refresher = Executors.newSingleThreadScheduledExecutor(
                new ThreadFactoryBuilder()
                        .setDaemon(true)
                        .setNameFormat("btsig-refresher-%d")
                        .build()
        );
        refresher.scheduleAtFixedRate(this::reload, 1, 1, TimeUnit.HOURS);
    }
    private void reload() {
        // Reload with new registry settings.
        initialize();
    }
    public void initialize() {
        // IMPORTANT: This method will also be called on configuration changes.
        this.isEnabled = nzyme.getConnect().isEnabled();
        if (!this.isEnabled) {
            return;
        }
        lock.lock();
        try {
            Optional<Map<Integer, String>> companyIds = fetchCompanyIdsFromConnect();
            Optional<Map<String, String>> serviceUuids = fetchServiceUuidsFromConnect();
            // Check if BT SIG data was disabled in Connect for this cluster. (It's enough to check for one type)
            if (companyIds.isEmpty()) {
                this.isEnabled = false;
                return;
            }
            this.companyIds = companyIds.get();
            this.serviceUuids = serviceUuids.get();
            this.isEnabled = true;
        } catch (Exception e) {
            LOG.error("Could not download Bluetooth SIG data from Connect.", e);
            this.isEnabled = false;
        } finally {
            lock.unlock();
        }
    }
    public Optional<String> lookupCompanyId(int companyId) {
        if (!isEnabled) {
            return Optional.empty();
        }
        try(Timer.Context ignored = companyIdLookupTimer.time()) {
            lock.lock();
            try {
                String cid = companyIds.get(companyId);
                return cid == null ? Optional.empty() : Optional.of(cid);
            } finally {
                lock.unlock();
            }
        }
    }
    public Optional<String> lookupServiceUuid(String uuid) {
        if (!isEnabled) {
            return Optional.empty();
        }
        try(Timer.Context ignored = serviceUuidLookupTimer.time()) {
            lock.lock();
            try {
                String name = serviceUuids.get(uuid);
                return name == null ? Optional.empty() : Optional.of(name);
            } finally {
                lock.unlock();
            }
        }
    }
    private Optional<Map<Integer, String>> fetchCompanyIdsFromConnect() {
        LOG.debug("Loading new Bluetooth SIG Company IDs from Connect.");
        try {
            OkHttpClient c = new OkHttpClient.Builder()
                    .connectTimeout(60, TimeUnit.SECONDS)
                    .writeTimeout(15, TimeUnit.SECONDS)
                    .readTimeout(5, TimeUnit.MINUTES)
                    .followRedirects(true)
                    .build();
            HttpUrl url = HttpUrl.get(nzyme.getConnect().getApiUri())
                    .newBuilder()
                    .addPathSegment("data")
                    .addPathSegment("bluetooth")
                    .addPathSegment("companyids")
                    .build();
            Response response = c.newCall(new Request.Builder()
                    .addHeader("User-Agent", "nzyme")
                    .get()
                    .url(url)
                    .addHeader(HttpHeaders.AUTHORIZATION, "Bearer " + nzyme.getConnect().getApiKey())
                    .addHeader("Content-Type", "application/json")
                    .addHeader(HttpHeaders.USER_AGENT, "nzyme-node")
                    .build()
            ).execute();
            try (response) {
                if (!response.isSuccessful()) {
                    if (response.code() == 403) {
                        // BG SIG data disabled in Connect for this cluster.
                        return Optional.empty();
                    }
                    throw new RuntimeException("Expected HTTP 200 or 403 but got HTTP " + response.code());
                }
                if (response.body() == null) {
                    throw new RuntimeException("Empty response.");
                }
                LOG.debug("Bluetooth SIG Company ID data download from Connect complete.");
                ObjectMapper om = new ObjectMapper();
                om.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
                om.configure(DeserializationFeature.FAIL_ON_IGNORED_PROPERTIES, false);
                ConnectCompanyIdListResponse ids = om.readValue(response.body().bytes(), ConnectCompanyIdListResponse.class);
                Map<Integer, String> table = Maps.newHashMap();
                for (ConnectCompanyIdResponse id : ids.companyIds()) {
                    table.put(id.companyId(), id.name());
                }
                return Optional.of(table);
            }
        } catch (Exception e) {
            LOG.error("Could not download SIG Company ID data from Connect.", e);
            return Optional.empty();
        }
    }
    private Optional<Map<String, String>> fetchServiceUuidsFromConnect() {
        LOG.debug("Loading new Bluetooth SIG service UUIDs from Connect.");
        try {
            OkHttpClient c = new OkHttpClient.Builder()
                    .connectTimeout(60, TimeUnit.SECONDS)
                    .writeTimeout(15, TimeUnit.SECONDS)
                    .readTimeout(5, TimeUnit.MINUTES)
                    .followRedirects(true)
                    .build();
            HttpUrl url = HttpUrl.get(nzyme.getConnect().getApiUri())
                    .newBuilder()
                    .addPathSegment("data")
                    .addPathSegment("bluetooth")
                    .addPathSegment("serviceuuids")
                    .build();
            Response response = c.newCall(new Request.Builder()
                    .addHeader("User-Agent", "nzyme")
                    .get()
                    .url(url)
                    .addHeader(HttpHeaders.AUTHORIZATION, "Bearer " + nzyme.getConnect().getApiKey())
                    .addHeader("Content-Type", "application/json")
                    .addHeader(HttpHeaders.USER_AGENT, "nzyme-node")
                    .build()
            ).execute();
            try (response) {
                if (!response.isSuccessful()) {
                    if (response.code() == 403) {
                        // BG SIG data disabled in Connect for this cluster.
                        return Optional.empty();
                    }
                    throw new RuntimeException("Expected HTTP 200 or 403 but got HTTP " + response.code());
                }
                if (response.body() == null) {
                    throw new RuntimeException("Empty response.");
                }
                LOG.debug("Bluetooth SIG service UUID data download from Connect complete.");
                ObjectMapper om = new ObjectMapper();
                om.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
                om.configure(DeserializationFeature.FAIL_ON_IGNORED_PROPERTIES, false);
                ConnectServiceUuidListResponse ids = om.readValue(response.body().bytes(), ConnectServiceUuidListResponse.class);
                Map<String, String> table = Maps.newHashMap();
                for (ConnectServiceUuidResponse id : ids.serviceUuids()) {
                    table.put(id.uuid(), id.name());
                }
                return Optional.of(table);
            }
        } catch (Exception e) {
            LOG.error("Could not download SIG service UUID data from Connect.", e);
            return Optional.empty();
        }
    }
}
package app.nzyme.core.tables.dot11;
import app.nzyme.core.NzymeNode;
import app.nzyme.core.detection.alerts.DetectionType;
import app.nzyme.core.dot11.Dot11;
import app.nzyme.core.dot11.Dot11RegistryKeys;
import app.nzyme.core.dot11.db.monitoring.*;
import app.nzyme.core.dot11.bandits.Dot11BanditDescription;
import app.nzyme.core.dot11.bandits.Dot11Bandits;
import app.nzyme.core.dot11.db.monitoring.probereq.MonitoredProbeRequestEntry;
import app.nzyme.core.rest.resources.taps.reports.tables.dot11.*;
import app.nzyme.core.tables.DataTable;
import app.nzyme.core.tables.TablesService;
import app.nzyme.core.tables.dot11.monitoring.PreLoadedMonitoredBSSID;
import app.nzyme.core.tables.dot11.monitoring.PreLoadedMonitoredSSID;
import app.nzyme.core.taps.Tap;
import app.nzyme.core.util.MetricNames;
import app.nzyme.core.util.Tools;
import app.nzyme.plugin.Subsystem;
import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.google.common.base.Joiner;
import com.google.common.collect.Lists;
import com.google.common.collect.Maps;
import info.debatty.java.stringsimilarity.JaroWinkler;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.jdbi.v3.core.Handle;
import org.jdbi.v3.core.statement.PreparedBatch;
import org.joda.time.DateTime;
import com.codahale.metrics.Timer;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.UUID;
import java.util.concurrent.CountDownLatch;
import java.util.stream.Collectors;
public class Dot11Table implements DataTable {
    private static final Logger LOG = LogManager.getLogger(Dot11Table.class);
    private final TablesService tablesService;
    private final ObjectMapper om;
    private final Timer totalReportTimer;
    private final Timer bssidReportTimer;
    private final Timer clientsReportTimer;
    private final Timer discoReportTimer;
    private final Timer alertTimer;
    public Dot11Table(TablesService tablesService) {
        this.tablesService = tablesService;
        this.om = new ObjectMapper();
        this.totalReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.DOT11_TOTAL_REPORT_PROCESSING_TIMER);
        this.bssidReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.DOT11_BSSID_REPORT_PROCESSING_TIMER);
        this.clientsReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.DOT11_CLIENTS_REPORT_PROCESSING_TIMER);
        this.discoReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.DOT11_DISCO_REPORT_PROCESSING_TIMER);
        this.alertTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.DOT11_ALERT_PROCESSING_TIMER);
    }
    public void handleReport(UUID tapUuid, DateTime timestamp, Dot11TablesReport report) {
        try (Timer.Context ignored = totalReportTimer.time()) {
            Optional<Tap> tap = tablesService.getNzyme().getTapManager().findTap(tapUuid);
            if (tap.isEmpty()) {
                LOG.warn("Not handling report of unknown tap [{}].", tapUuid);
                return;
            }
            try (Timer.Context ignored2 = bssidReportTimer.time()) {
                writeBSSIDs(tap.get(), timestamp, report.bssids(), tap.get().organizationId(), tap.get().tenantId());
            }
            try (Timer.Context ignored2 = clientsReportTimer.time()) {
                writeClients(tap.get(), timestamp, report.clients());
            }
            try (Timer.Context ignored2 = discoReportTimer.time()) {
                writeDisco(tap.get(), timestamp, report.disco());
            }
            try (Timer.Context ignored2 = alertTimer.time()) {
                handleAlerts(tap.get(), report.alerts());
            }
        }
    }
    private void writeClients(Tap tap, DateTime timestamp, Map<String, Dot11ClientReport> clients) {
        Map<String, MonitoredProbeRequestEntry> monitoredProbeRequests = tablesService.getNzyme().getDot11()
                .findAllMonitoredProbeRequests(tap.organizationId(), tap.tenantId(), Integer.MAX_VALUE, 0)
                .stream()
                .collect(Collectors.toMap(MonitoredProbeRequestEntry::ssid, entry -> entry));
        for (Map.Entry<String, Dot11ClientReport> entry : clients.entrySet()) {
            String clientMac = entry.getKey();
            Dot11ClientReport report = entry.getValue();
            long clientDatabaseId = tablesService.getNzyme().getDatabase().withHandle(handle ->
                    handle.createQuery("INSERT INTO dot11_clients(tap_uuid, client_mac, client_mac_is_randomized, " +
                                    "wildcard_probe_requests, signal_strength_average, signal_strength_max, " +
                                    "signal_strength_min, created_at) VALUES(:tap_uuid, :client_mac, " +
                                    ":client_mac_is_randomized, :wildcard_probe_requests, :signal_strength_average, " +
                                    ":signal_strength_max, :signal_strength_min, :created_at) RETURNING id")
                            .bind("tap_uuid", tap.uuid())
                            .bind("client_mac", clientMac)
                            .bind("client_mac_is_randomized", Tools.macAddressIsRandomized(clientMac))
                            .bind("wildcard_probe_requests", report.wildcardProbeRequests())
                            .bind("signal_strength_average", report.signalStrength().average())
                            .bind("signal_strength_min", report.signalStrength().min())
                            .bind("signal_strength_max", report.signalStrength().max())
                            .bind("created_at", timestamp)
                            .mapTo(Long.class)
                            .one()
            );
            tablesService.getNzyme().getDatabase().useHandle(handle -> {
                PreparedBatch batch = handle.prepareBatch(
                        "INSERT INTO dot11_client_probereq_ssids(client_id, ssid, frame_count, tap_uuid) " +
                                "VALUES(:client_id, :ssid, :frame_count, :tap_uuid)"
                );
                for (Map.Entry<String, Long> pr : report.probeRequestSSIDs().entrySet()) {
                    String ssid = Tools.sanitizeSSID(pr.getKey());
                    // Check if we are monitoring for this probe request SSID and raise alert if so.
                    if (monitoredProbeRequests.containsKey(ssid)) {
                        // Raise alert.
                        Map<String, String> attributes = Maps.newHashMap();
                        attributes.put("ssid", ssid);
                        attributes.put("client_mac", clientMac);
                        tablesService.getNzyme().getDetectionAlertService().raiseAlert(
                                tap.organizationId(),
                                tap.tenantId(),
                                null,
                                tap.uuid(),
                                DetectionType.DOT11_PROBEREQ,
                                Subsystem.DOT11,
                                "Monitored probe request for SSID \"" + ssid + "\" detected in range.",
                                attributes,
                                new String[]{"ssid"},
                                report.signalStrength().average()
                        );
                    }
                    batch.bind("client_id", clientDatabaseId)
                            .bind("ssid", ssid)
                            .bind("frame_count", pr.getValue())
                            .bind("tap_uuid", tap.uuid())
                            .add();
                }
                batch.execute();
            });
        }
    }
    public void writeBSSIDs(Tap tap, DateTime timestamp,
                            Map<String, Dot11BSSIDReport> bssids,
                            UUID organizationId,
                            UUID tenantId) {
        // Collect all monitored SSIDs and their attributes.
        Map<String, PreLoadedMonitoredSSID> monitoredSSIDs = Maps.newHashMap();
        List<String> monitoredSSIDNames = Lists.newArrayList();
        NzymeNode nzyme = tablesService.getNzyme();
        nzyme.getDatabase().useHandle(handle -> {
            for (MonitoredSSID s : nzyme.getDot11().findAllMonitoredSSIDs(tap.organizationId(), tap.tenantId())) {
                if (!s.isEnabled()) {
                    continue;
                }
                monitoredSSIDNames.add(s.ssid());
                Map<String, PreLoadedMonitoredBSSID> preLoadedBSSIDs = Maps.newHashMap();
                for (MonitoredBSSID b : nzyme.getDot11().findMonitoredBSSIDsOfMonitoredNetwork(s.id())) {
                    List<String> fingerprints = Lists.newArrayList();
                    for (MonitoredFingerprint f : nzyme.getDot11().findMonitoredFingerprintsOfMonitoredBSSID(b.id())) {
                        fingerprints.add(f.fingerprint());
                    }
                    preLoadedBSSIDs.put(b.bssid(), PreLoadedMonitoredBSSID.create(b.bssid(), fingerprints));
                }
                List<Integer> preLoadedChannels = Lists.newArrayList();
                for (MonitoredChannel c : nzyme.getDot11().findMonitoredChannelsOfMonitoredNetwork(s.id())) {
                    preLoadedChannels.add((int) c.frequency());
                }
                List<String> preLoadedSecuritySuites = Lists.newArrayList();
                for (MonitoredSecuritySuite ss : nzyme.getDot11().findMonitoredSecuritySuitesOfMonitoredNetwork(s.id())) {
                    preLoadedSecuritySuites.add(ss.securitySuite());
                }
                monitoredSSIDs.put(s.ssid(), PreLoadedMonitoredSSID.create(
                        s.id(),
                        s.uuid(),
                        s.ssid(),
                        preLoadedBSSIDs,
                        preLoadedChannels,
                        preLoadedSecuritySuites,
                        s.enabledUnexpectedBSSID(),
                        s.enabledUnexpectedChannel(),
                        s.enabledUnexpectedSecuritySuites(),
                        s.enabledUnexpectedFingerprint(),
                        s.enabledUnexpectedSignalTracks(),
                        s.enabledSimilarLookingSSID(),
                        s.enabledSSIDSubstring(),
                        s.detectionConfigSimilarLookingSSIDThreshold()
                ));
            }
            // Load all bandits.
            List<Dot11BanditDescription> bandits = Lists.newArrayList(Dot11Bandits.BUILT_IN);
            for (CustomBanditDescription bandit : nzyme.getDot11()
                    .findAllCustomBandits(organizationId, tenantId, Integer.MAX_VALUE, 0)) {
                List<String> fingerprints = nzyme.getDot11().findFingerprintsOfCustomBandit(bandit.id());
                bandits.add(Dot11BanditDescription.create(
                        bandit.uuid().toString(),
                        true,
                        bandit.name(),
                        bandit.description(),
                        fingerprints
                ));
            }
            List<SSIDProcessingTask> ssidProcessingTasks = Lists.newArrayList();
            for (Map.Entry<String, Dot11BSSIDReport> entry : bssids.entrySet()) {
                String bssid = entry.getKey();
                Dot11BSSIDReport report = entry.getValue();
                long bssidDatabaseId = handle.createQuery(
                        "INSERT INTO dot11_bssids(tap_uuid, bssid, oui, " +
                                "signal_strength_average, signal_strength_max, signal_strength_min, " +
                                "hidden_ssid_frames, created_at) VALUES(:tap_uuid, :bssid, NULL, " +
                                ":signal_strength_average, :signal_strength_max, :signal_strength_min, " +
                                ":hidden_ssid_frames, :created_at) RETURNING id")
                        .bind("tap_uuid", tap.uuid())
                        .bind("bssid", bssid)
                        .bind("signal_strength_average", report.signalStrength().average())
                        .bind("signal_strength_max", report.signalStrength().max())
                        .bind("signal_strength_min", report.signalStrength().min())
                        .bind("hidden_ssid_frames", report.hiddenSSIDFrames())
                        .bind("created_at", timestamp)
                        .mapTo(Long.class)
                        .one();
                // BSSID Fingerprints.
                PreparedBatch fingerprintBatch = handle.prepareBatch(
                        "INSERT INTO dot11_fingerprints(fingerprint, bssid_id) " +
                                "VALUES(:fingerprint, :bssid_id)");
                for (String fingerprint : report.fingerprints()) {
                    fingerprintBatch
                            .bind("fingerprint", fingerprint)
                            .bind("bssid_id", bssidDatabaseId)
                            .add();
                    // Is this a known bandit fingerprint?
                    for (Dot11BanditDescription bandit : bandits) {
                        if (bandit.fingerprints() != null && bandit.fingerprints().contains(fingerprint)) {
                            Map<String, String> attributes = Maps.newHashMap();
                            attributes.put("fingerprint", fingerprint);
                            attributes.put("bssid", bssid);
                            attributes.put("tap_uuid", tap.uuid().toString());
                            attributes.put("bandit_name", bandit.name());
                            attributes.put("bandit_description", bandit.description());
                            attributes.put("bandit_is_custom", String.valueOf(bandit.isCustom()));
                            tablesService.getNzyme().getDetectionAlertService().raiseAlert(
                                    tap.organizationId(),
                                    tap.tenantId(),
                                    null,
                                    tap.uuid(),
                                    DetectionType.DOT11_BANDIT_CONTACT,
                                    Subsystem.DOT11,
                                    "Bandit \"" + bandit.name() + "\" advertising BSSID \"" + bssid + "\" " +
                                            "detected in range.",
                                    attributes,
                                    new String[]{"bssid", "fingerprint", "bandit_is_custom"},
                                    report.signalStrength().average()
                            );
                        }
                    }
                }
                fingerprintBatch.execute();
                // BSSID Clients.
                PreparedBatch bssidClientsBatch = handle.prepareBatch(
                        "INSERT INTO dot11_bssid_clients(bssid_id, client_mac, tx_frames, " +
                                "tx_bytes, rx_frames, rx_bytes, signal_strength_average, " +
                                "signal_strength_min, signal_strength_max) VALUES(:bssid_id, :client_mac, " +
                                ":tx_frames, :tx_bytes, :rx_frames, :rx_bytes, :signal_strength_average, " +
                                ":signal_strength_min, :signal_strength_max)");
                for (Map.Entry<String, Dot11ClientStatisticsReport> client : report.clients().entrySet()) {
                    String mac = client.getKey();
                    Dot11ClientStatisticsReport stats = client.getValue();
                    if (!bssid.equals(mac)) { // Don't record BSSID itself.
                        bssidClientsBatch
                                .bind("bssid_id", bssidDatabaseId)
                                .bind("client_mac", mac)
                                .bind("tx_frames", stats.txFrames())
                                .bind("tx_bytes", stats.txBytes())
                                .bind("rx_frames", stats.rxFrames())
                                .bind("rx_bytes", stats.rxBytes())
                                .bind("signal_strength_average", stats.signalStrength().average())
                                .bind("signal_strength_min", stats.signalStrength().average())
                                .bind("signal_strength_max", stats.signalStrength().average())
                                .add();
                    }
                }
                bssidClientsBatch.execute();
                // Pre-process all SSIDs.
                for (Map.Entry<String, Dot11AdvertisedNetworkReport> ssidEntry : report.advertisedNetworks().entrySet()) {
                    ssidProcessingTasks.add(SSIDProcessingTask.create(
                            bssid, ssidEntry.getKey(), ssidEntry.getValue(), bssidDatabaseId, tap, timestamp
                    ));
                }
            }
            // Write all SSIDs.
            CountDownLatch latch = new CountDownLatch(ssidProcessingTasks.size());
            for (SSIDProcessingTask ssidProcessingTask : ssidProcessingTasks) {
                tablesService.getProcessorPool().submit(() -> {
                    writeSSID(nzyme, handle, monitoredSSIDNames, monitoredSSIDs, ssidProcessingTask);
                    latch.countDown();
                });
            }
            // Wait for SSID processing to finish.
            try {
                latch.await();
            } catch (InterruptedException e) {
                LOG.error("SSID writer process interrupted.", e);
            }
        });
    }
    private void writeSSID(NzymeNode nzyme,
                           Handle handle,
                           List<String> monitoredSSIDNames,
                           Map<String, PreLoadedMonitoredSSID> monitoredSSIDs,
                           SSIDProcessingTask task) {
        try {
            // Replace all non-printable characters.
            final String ssid = Tools.sanitizeSSID(task.ssid());
            /*
             * If all characters were sanitized away, this is a hidden SSID.
             * (some access points build hidden SSIDs this way)
             */
            if (ssid.isEmpty()) {
                return;
            }
            Long ssidDatabaseId = handle.createQuery(
                    "INSERT INTO dot11_ssids(bssid_id, tap_uuid, ssid, bssid, " +
                            "signal_strength_average, signal_strength_max, signal_strength_min, " +
                            "beacon_advertisements, proberesp_advertisements, created_at) " +
                            "VALUES(:bssid_id, :tap_uuid, :ssid, :bssid, :signal_strength_average, " +
                            ":signal_strength_max, :signal_strength_min, :beacon_advertisements, " +
                            ":proberesp_advertisements, :created_at) RETURNING *")
                    .bind("bssid_id", task.bssidDatabaseId())
                    .bind("tap_uuid", task.tap().uuid())
                    .bind("ssid", ssid)
                    .bind("bssid", task.bssid())
                    .bind("signal_strength_average", task.ssidReport().signalStrength().average())
                    .bind("signal_strength_max", task.ssidReport().signalStrength().max())
                    .bind("signal_strength_min", task.ssidReport().signalStrength().min())
                    .bind("beacon_advertisements", task.ssidReport().beaconAdvertisements())
                    .bind("proberesp_advertisements", task.ssidReport().probeResponseAdvertisements())
                    .bind("created_at", task.timestamp())
                    .mapTo(Long.class)
                    .one();
            // WPS settings.
            PreparedBatch wpsBatch = handle.prepareBatch(
                    "INSERT INTO dot11_ssid_settings(ssid_id, attribute, value) " +
                            "VALUES(:ssid_id, 'has_wps', :value)");
            for (boolean hasWps : task.ssidReport().wps()) {
                wpsBatch.bind("ssid_id", ssidDatabaseId).bind("value", String.valueOf(hasWps)).add();
            }
            wpsBatch.execute();
            // Security protocols and suites.
            PreparedBatch noneSettingsBatch = handle.prepareBatch(
                    "INSERT INTO dot11_ssid_settings(ssid_id, attribute, value) " +
                            "VALUES(:ssid_id, 'security_protocol', NULL"); // We insert NULL to signal "NONE".
            PreparedBatch someSettingsBatch = handle.prepareBatch(
                    "INSERT INTO dot11_ssid_settings(ssid_id, attribute, value) " +
                            "VALUES(:ssid_id, 'security_protocol', :value)");
            PreparedBatch suitesBatch = handle.prepareBatch(
                    "INSERT INTO dot11_ssid_settings(ssid_id, attribute, value) " +
                            "VALUES(:ssid_id, 'security_suite', :value)");
            for (Dot11SecurityInformationReport sec : task.ssidReport().security()) {
                if (sec.protocols().isEmpty()) {
                    noneSettingsBatch.bind("ssid_id", ssidDatabaseId).add();
                } else {
                    for (String protocol : sec.protocols()) {
                        someSettingsBatch
                                .bind("ssid_id", ssidDatabaseId)
                                .bind("value", protocol)
                                .add();
                    }
                }
                Map<String, String> suiteMap = Maps.newHashMap();
                suiteMap.put("group_cipher", sec.suites().groupCipher());
                suiteMap.put("pairwise_ciphers",
                        Joiner.on(",").join(sec.suites().pairwiseCiphers()));
                suiteMap.put("key_management_modes",
                        Joiner.on(",").join(sec.suites().keyManagementModes()));
                suiteMap.put("pmf_mode", sec.pmf());
                try {
                    suitesBatch
                            .bind("ssid_id", ssidDatabaseId)
                            .bind("value", this.om.writeValueAsString(suiteMap))
                            .add();
                } catch(JsonProcessingException e) {
                    LOG.error("Could not serialize SSID <{}> security suites.", task.bssidDatabaseId(), e);
                }
            }
            noneSettingsBatch.execute();
            someSettingsBatch.execute();
            suitesBatch.execute();
            // SSID Fingerprints.
            PreparedBatch fingerprintsBatch = handle.prepareBatch(
                    "INSERT INTO dot11_fingerprints(fingerprint, ssid_id) " +
                            "VALUES(:fingerprint, :ssid_id)");
            for (String fingerprint : task.ssidReport().fingerprints()) {
                    fingerprintsBatch.bind("fingerprint", fingerprint)
                            .bind("ssid_id", ssidDatabaseId)
                            .add();
            }
            fingerprintsBatch.execute();
            // SSID Rates.
            PreparedBatch ratesBatch = handle.prepareBatch("INSERT INTO dot11_rates(rate, ssid_id) " +
                    "VALUES(:rate, :ssid_id)");
            for (Float rate : task.ssidReport().rates()) {
                ratesBatch.bind("rate", rate).bind("ssid_id", ssidDatabaseId).add();
            }
            ratesBatch.execute();
            // Channel Statistics.
            PreparedBatch statsBatch = handle.prepareBatch(
                    "INSERT INTO dot11_channels(ssid_id, frequency, " +
                            "frame_type, stats_bytes, stats_frames) VALUES(:ssid_id, " +
                            ":frequency, :frame_type, :stats_bytes, :stats_frames)");
            for (Map.Entry<Long, Map<String, Dot11ChannelStatisticsReport>> cs : task.ssidReport().channelStatistics().entrySet()) {
                long frequency = cs.getKey();
                for (Map.Entry<String, Dot11ChannelStatisticsReport> ft : cs.getValue().entrySet()) {
                    String frameType = ft.getKey();
                    Dot11ChannelStatisticsReport stats = ft.getValue();
                    statsBatch
                            .bind("ssid_id", ssidDatabaseId)
                            .bind("frequency", frequency)
                            .bind("frame_type", frameType.toLowerCase())
                            .bind("stats_bytes", stats.bytes())
                            .bind("stats_frames", stats.frames())
                            .add();
                }
            }
            statsBatch.execute();
            // Write channel signal histogram.
            PreparedBatch histoBatch = handle.prepareBatch(
                    "INSERT INTO dot11_channel_histograms(ssid_id, frequency, " +
                            "signal_strength, frame_count) VALUES(:ssid_id, :frequency, " +
                            ":signal_strength, :frame_count)");
            for (Map.Entry<Long, Map<Long, Long>> channel : task.ssidReport().signalHistogram().entrySet()) {
                long frequency = channel.getKey();
                for (Map.Entry<Long, Long> histo : channel.getValue().entrySet()) {
                    histoBatch
                            .bind("ssid_id", ssidDatabaseId)
                            .bind("frequency", frequency)
                            .bind("signal_strength", histo.getKey())
                            .bind("frame_count", histo.getValue())
                            .add();
                }
            }
            histoBatch.execute();
            // Infrastructure Types.
            PreparedBatch infraBatch = handle.prepareBatch(
                    "INSERT INTO dot11_infrastructure_types(infrastructure_type, " +
                            "ssid_id) VALUES(:infrastructure_type, :ssid_id)");
            for (String infrastructureType : task.ssidReport().infrastructureTypes()) {
                infraBatch
                        .bind("infrastructure_type", infrastructureType.toLowerCase())
                        .bind("ssid_id", ssidDatabaseId)
                        .add();
            }
            infraBatch.execute();
            /*
             * Check if this SSID is similar to any monitored SSIDs or includes a monitored substring. Skip
             * other monitored SSIDs because they are considered trusted.
             */
            JaroWinkler jaroWinkler = new JaroWinkler();
            for (PreLoadedMonitoredSSID monitoredSSID : monitoredSSIDs.values()) {
                if (!monitoredSSIDNames.contains(ssid)) {
                    // Similar looking SSIDs.
                    if (monitoredSSID.enabledSimilarLookingSSID()) {
                        double similarity = jaroWinkler
                                .similarity(monitoredSSID.ssid().toLowerCase(), ssid.toLowerCase()) * 100.0;
                        if (similarity > monitoredSSID.detectionConfigSimilarLookingSSIDThreshold()) {
                            Map<String, String> attributes = Maps.newHashMap();
                            attributes.put("similar_ssid", ssid);
                            attributes.put("similarity", String.valueOf(similarity));
                            attributes.put("similarity_threshold",
                                    String.valueOf(monitoredSSID.detectionConfigSimilarLookingSSIDThreshold()));
                            nzyme.getDetectionAlertService().raiseAlert(
                                    task.tap().organizationId(),
                                    task.tap().tenantId(),
                                    monitoredSSID.uuid(),
                                    task.tap().uuid(),
                                    DetectionType.DOT11_MONITOR_SIMILAR_LOOKING_SSID,
                                    Subsystem.DOT11,
                                    "SSID \"" + ssid + "\" looking similar to monitored network SSID " +
                                            "\"" + monitoredSSID.ssid() + "\"",
                                    attributes,
                                    new String[]{"similar_ssid"},
                                    task.ssidReport().signalStrength().average()
                            );
                        }
                    }
                    // Restricted substrings.
                    if (monitoredSSID.enabledSSIDSubstring()) {
                        // Pull all restricted substrings.
                        for (RestrictedSSIDSubstring rss :
                                nzyme.getDot11().findAllRestrictedSSIDSubstrings(monitoredSSID.id())) {
                            if (ssid.toLowerCase().contains(rss.substring().toLowerCase())) {
                                Map<String, String> attributes = Maps.newHashMap();
                                attributes.put("ssid", ssid);
                                attributes.put("restricted_substring", rss.substring());
                                nzyme.getDetectionAlertService().raiseAlert(
                                        task.tap().organizationId(),
                                        task.tap().tenantId(),
                                        monitoredSSID.uuid(),
                                        task.tap().uuid(),
                                        DetectionType.DOT11_MONITOR_SSID_SUBSTRING,
                                        Subsystem.DOT11,
                                        "SSID \"" + ssid + "\" contains restricted " +
                                                "substring \"" + rss.substring() + "\"",
                                        attributes,
                                        new String[]{"ssid", "restricted_substring"},
                                        task.ssidReport().signalStrength().average()
                                );
                            }
                        }
                    }
                }
            }
            // Network Monitoring / Alerting.
            PreLoadedMonitoredSSID monitoredSSID = monitoredSSIDs.get(ssid);
            if (monitoredSSID != null) {
                // This is a monitored SSID.
                PreLoadedMonitoredBSSID monitoredBSSID = monitoredSSID.bssids().get(task.bssid());
                if (monitoredBSSID == null) {
                    if (monitoredSSID.enabledUnexpectedBSSID()) {
                        // Unexpected BSSID.
                        Map<String, String> attributes = Maps.newHashMap();
                        attributes.put("bssid", task.bssid());
                        nzyme.getDetectionAlertService().raiseAlert(
                                task.tap().organizationId(),
                                task.tap().tenantId(),
                                monitoredSSID.uuid(),
                                task.tap().uuid(),
                                DetectionType.DOT11_MONITOR_BSSID,
                                Subsystem.DOT11,
                                "Monitored network \"" + monitoredSSID.ssid() + "\" advertised with " +
                                        "unexpected BSSID \"" + task.bssid() + "\"",
                                attributes,
                                new String[]{"bssid"},
                                task.ssidReport().signalStrength().average()
                        );
                    }
                } else {
                    // Expected BSSID. Compare fingerprints.
                    if (monitoredSSID.enabledUnexpectedFingerprint()) {
                        for (String observedFingerprint : task.ssidReport().fingerprints()) {
                            if (!monitoredBSSID.fingerprints().contains(observedFingerprint)) {
                                // Unexpected fingerprint.
                                Map<String, String> attributes = Maps.newHashMap();
                                attributes.put("bssid", task.bssid());
                                attributes.put("fingerprint", observedFingerprint);
                                nzyme.getDetectionAlertService().raiseAlert(
                                        task.tap().organizationId(),
                                        task.tap().tenantId(),
                                        monitoredSSID.uuid(),
                                        task.tap().uuid(),
                                        DetectionType.DOT11_MONITOR_FINGERPRINT,
                                        Subsystem.DOT11,
                                        "Monitored network \"" + monitoredSSID.ssid() + "\" advertised " +
                                                "with unexpected fingerprint \"" + observedFingerprint + "\".",
                                        attributes,
                                        new String[]{"bssid", "fingerprint"},
                                        task.ssidReport().signalStrength().average()
                                );
                            }
                        }
                    }
                }
                if (monitoredSSID.enabledUnexpectedChannel()) {
                    for (Long frequency : task.ssidReport().channelStatistics().keySet()) {
                        if (!monitoredSSID.channels().contains(frequency.intValue())) {
                            // Unexpected channel.
                            Map<String, String> attributes = Maps.newHashMap();
                            attributes.put("frequency", String.valueOf(frequency));
                            nzyme.getDetectionAlertService().raiseAlert(
                                    task.tap().organizationId(),
                                    task.tap().tenantId(),
                                    monitoredSSID.uuid(),
                                    task.tap().uuid(),
                                    DetectionType.DOT11_MONITOR_CHANNEL,
                                    Subsystem.DOT11,
                                    "Monitored network \"" + monitoredSSID.ssid() + "\" advertised on " +
                                            "unexpected frequency " + frequency + "MHz",
                                    attributes,
                                    new String[]{"frequency"},
                                    task.ssidReport().signalStrength().average()
                            );
                        }
                    }
                }
                if (monitoredSSID.enabledUnexpectedSecuritySuites()) {
                    for (Dot11SecurityInformationReport security : task.ssidReport().security()) {
                        String suite = Dot11.securitySuitesToIdentifier(security);
                        if (!monitoredSSID.securitySuites().contains(suite)) {
                            Map<String, String> attributes = Maps.newHashMap();
                            attributes.put("suite", suite);
                            nzyme.getDetectionAlertService().raiseAlert(
                                    task.tap().organizationId(),
                                    task.tap().tenantId(),
                                    monitoredSSID.uuid(),
                                    task.tap().uuid(),
                                    DetectionType.DOT11_MONITOR_SECURITY_SUITE,
                                    Subsystem.DOT11,
                                    "Monitored network \"" + monitoredSSID.ssid() + "\" advertised with " +
                                            "unexpected security suites \"" + suite + "\"",
                                    attributes,
                                    new String[]{"suite"},
                                    task.ssidReport().signalStrength().average()
                            );
                        }
                    }
                }
            }
        } catch(Exception e) {
            LOG.error("Could not write SSID.", e);
        }
    }
    private void writeDisco(Tap tap, DateTime timestamp, Dot11DiscoReport disco) {
        tablesService.getNzyme().getDatabase().useHandle(handle -> {
            for (Dot11DiscoTransmitterReport report : disco.deauthentication().values()) {
                writeDiscoReport(handle, tap, timestamp, Dot11.DiscoType.DEAUTHENTICATION, report);
            }
            for (Dot11DiscoTransmitterReport report : disco.disassociation().values()) {
                writeDiscoReport(handle, tap, timestamp, Dot11.DiscoType.DISASSOCIATION, report);
            }
        });
    }
    private void writeDiscoReport(Handle handle, Tap tap, DateTime timestamp, Dot11.DiscoType discoType, Dot11DiscoTransmitterReport report) {
        long activityId = handle.createQuery(
                "INSERT INTO dot11_disco_activity(tap_uuid, disco_type, bssid, sent_frames, " +
                        "created_at) VALUES(:tap_uuid, :disco_type, :bssid, :sent_frames, :created_at) " +
                        "RETURNING id")
                .bind("tap_uuid", tap.uuid())
                .bind("disco_type", discoType.getNumber())
                .bind("bssid", report.bssid())
                .bind("sent_frames", report.sentFrames())
                .bind("created_at", timestamp)
                .mapTo(Long.class)
                .one();
        PreparedBatch batch = handle.prepareBatch(
                "INSERT INTO dot11_disco_activity_receivers(disco_activity_id, bssid, received_frames)" +
                        " VALUES(:disco_activity_id, :bssid, :received_frames)"
        );
        for (Map.Entry<String, Long> receiver : report.receivers().entrySet()) {
                batch.bind("disco_activity_id", activityId)
                        .bind("bssid", receiver.getKey())
                        .bind("received_frames", receiver.getValue())
                        .add();
        }
        batch.execute();
    }
    private void handleAlerts(Tap tap, List<Dot11AlertReport> alerts) {
        for (Dot11AlertReport alert : alerts) {
            switch (alert.alertType()) {
                case PwnagotchiDetected:
                    Map<String, String> attributes = reportAlertAttributesToAlertAttributes(alert.attributes());
                    attributes.put("bandit_name", Dot11Bandits.CUSTOM_PWNAGOTCHI_NAME);
                    attributes.put("bandit_description", Dot11Bandits.CUSTOM_PWNAGOTCHI_DESCRIPTION);
                    tablesService.getNzyme().getDetectionAlertService().raiseAlert(
                            tap.organizationId(),
                            tap.tenantId(),
                            null,
                            tap.uuid(),
                            DetectionType.DOT11_BANDIT_CONTACT,
                            Subsystem.DOT11,
                            "Bandit \"Pwnagotchi\" with name \"" + attributes.get("name") + "\" detected in range.",
                            attributes,
                            new String[]{"identity"},
                            alert.signalStrength().floatValue()
                    );
                    break;
                default:
                    LOG.warn("Unknown tap alert type: [{}]. Skipping.", alert.alertType());
            }
        }
    }
    /*
     * This is somewhat over-complicated to allow Rust to populate maps with different types of values.
     * We are just calling .toString(), but that may change if we ever report more complex attributes.
     */
    private Map<String, String> reportAlertAttributesToAlertAttributes(
            Map<String, Map<Dot11AlertReport.AlertAttributeType, Object>> attributes) {
        Map<String, String> alertAttributes = Maps.newHashMap();
        for (Map.Entry<String, Map<Dot11AlertReport.AlertAttributeType, Object>> attr : attributes.entrySet()) {
            String key = attr.getKey();
            String value = null;
            for (Map.Entry<Dot11AlertReport.AlertAttributeType, Object> attrValue : attr.getValue().entrySet()) {
                switch (attrValue.getKey()) {
                    case Number:
                    case String:
                        value = attrValue.getValue().toString();
                        break;
                }
            }
            alertAttributes.put(key, value);
        }
        return alertAttributes;
    }
    @Override
    public void retentionClean() {
        NzymeNode nzyme = tablesService.getNzyme();
        int dot11RetentionDays = Integer.parseInt(nzyme.getDatabaseCoreRegistry()
                .getValue(Dot11RegistryKeys.DOT11_RETENTION_TIME_DAYS.key())
                .orElse(Dot11RegistryKeys.DOT11_RETENTION_TIME_DAYS.defaultValue().orElse("MISSING"))
        );
        DateTime dot11CutOff = DateTime.now().minusDays(dot11RetentionDays);
        LOG.info("802.11/WiFi data retention: <{}> days / Delete data older than <{}>.",
                dot11RetentionDays, dot11CutOff);
    }
}
package app.nzyme.core.tables.socks;
import app.nzyme.core.NzymeNode;
import app.nzyme.core.ethernet.EthernetRegistryKeys;
import app.nzyme.core.rest.resources.taps.reports.tables.socks.SocksTunnelReport;
import app.nzyme.core.rest.resources.taps.reports.tables.socks.SocksTunnelsReport;
import app.nzyme.core.tables.DataTable;
import app.nzyme.core.tables.TablesService;
import app.nzyme.core.util.MetricNames;
import app.nzyme.core.util.Tools;
import com.codahale.metrics.Timer;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.jdbi.v3.core.Handle;
import org.jdbi.v3.core.statement.PreparedBatch;
import org.joda.time.DateTime;
import java.util.List;
import java.util.Optional;
import java.util.UUID;
public class SOCKSTable implements DataTable {
    private static final Logger LOG = LogManager.getLogger(SOCKSTable.class);
    private final TablesService tablesService;
    private final Timer totalReportTimer;
    public SOCKSTable(TablesService tablesService) {
        this.tablesService = tablesService;
        this.totalReportTimer = tablesService.getNzyme().getMetrics()
                .timer(MetricNames.SOCKS_TOTAL_REPORT_PROCESSING_TIMER);
    }
    public void handleReport(UUID tapUuid, DateTime timestamp, SocksTunnelsReport report) {
        tablesService.getNzyme().getDatabase().useHandle(handle -> {
            try(Timer.Context ignored = totalReportTimer.time()) {
                writeTunnels(handle, tapUuid, report.tunnels());
            }
        });
    }
    private void writeTunnels(Handle handle, UUID tapUuid, List<SocksTunnelReport> tunnels) {
        PreparedBatch insertBatch = handle.prepareBatch("INSERT INTO socks_tunnels(uuid, tap_uuid, " +
                "tcp_session_key, socks_type, authentication_status, handshake_status, connection_status, " +
                "username, tunneled_bytes, tunneled_destination_address, tunneled_destination_host, " +
                "tunneled_destination_port, established_at, terminated_at, most_recent_segment_time, " +
                "updated_at, created_at) VALUES(:uuid, :tap_uuid, :tcp_session_key, :socks_type, " +
                ":authentication_status, :handshake_status, :connection_status, :username, :tunneled_bytes, " +
                ":tunneled_destination_address::inet, :tunneled_destination_host, :tunneled_destination_port, " +
                ":established_at, :terminated_at, :most_recent_segment_time, NOW(), NOW())");
        PreparedBatch updateBatch = handle.prepareBatch("UPDATE socks_tunnels SET " +
                "authentication_status = :authentication_status, handshake_status = :handshake_status, " +
                "connection_status = :connection_status, tunneled_bytes = :tunneled_bytes, " +
                "terminated_at = :terminated_at, most_recent_segment_time = :most_recent_segment_time, " +
                "updated_at = NOW() WHERE id = :id");
        for (SocksTunnelReport tunnel : tunnels) {
            String tcpSessionKey = Tools.buildTcpSessionKey(
                    tunnel.establishedAt(),
                    tunnel.sourceAddress(),
                    tunnel.destinationAddress(),
                    tunnel.sourcePort(),
                    tunnel.destinationPort());
            Optional<Long> existingTunnel = handle.createQuery("SELECT id FROM socks_tunnels " +
                            "WHERE tcp_session_key = :tcp_session_key AND established_at = :established_at " +
                            "AND tap_uuid = :tap_uuid AND connection_status = :connection_status")
                    .bind("tcp_session_key", tcpSessionKey)
                    .bind("established_at", tunnel.establishedAt())
                    .bind("tap_uuid", tapUuid)
                    .bind("connection_status", "Active")
                    .bind("most_recent_segment_time", tunnel.mostRecentSegmentTime())
                    .mapTo(Long.class)
                    .findOne();
            if (existingTunnel.isEmpty()) {
                insertBatch
                        .bind("uuid", UUID.randomUUID())
                        .bind("tap_uuid", tapUuid)
                        .bind("tcp_session_key", tcpSessionKey)
                        .bind("socks_type", tunnel.socksType())
                        .bind("authentication_status", tunnel.authenticationStatus())
                        .bind("handshake_status", tunnel.handshakeStatus())
                        .bind("connection_status", tunnel.connectionStatus())
                        .bind("username", tunnel.username())
                        .bind("tunneled_bytes", tunnel.tunneledBytes())
                        .bind("tunneled_destination_address", tunnel.tunneledDestinationAddress())
                        .bind("tunneled_destination_host", tunnel.tunneledDestinationHost())
                        .bind("tunneled_destination_port", tunnel.tunneledDestinationPort())
                        .bind("established_at", tunnel.establishedAt())
                        .bind("terminated_at", tunnel.terminatedAt())
                        .bind("most_recent_segment_time", tunnel.mostRecentSegmentTime())
                        .add();
            } else {
                // Update existing open tunnel.
                updateBatch
                        .bind("id", existingTunnel.get())
                        .bind("authentication_status", tunnel.authenticationStatus())
                        .bind("handshake_status", tunnel.handshakeStatus())
                        .bind("connection_status", tunnel.connectionStatus())
                        .bind("tunneled_bytes", tunnel.tunneledBytes())
                        .bind("terminated_at", tunnel.terminatedAt())
                        .bind("most_recent_segment_time", tunnel.mostRecentSegmentTime())
                        .add();
            }
        }
        insertBatch.execute();
        updateBatch.execute();
    }
    @Override
    public void retentionClean() {
        NzymeNode nzyme = tablesService.getNzyme();
        int l4RetentionDays = Integer.parseInt(nzyme.getDatabaseCoreRegistry()
                .getValue(EthernetRegistryKeys.L4_RETENTION_TIME_DAYS.key())
                .orElse(EthernetRegistryKeys.L4_RETENTION_TIME_DAYS.defaultValue().orElse("MISSING"))
        );
        DateTime l4CutOff = DateTime.now().minusDays(l4RetentionDays);
        LOG.info("SOCKS (TCP/L4) data retention: <{}> days / Delete data older than <{}>.",
                l4RetentionDays, l4CutOff);
    }
}